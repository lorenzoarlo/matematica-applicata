<!DOCTYPE html>
<html lang="IT">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="stylesheet" href="./../styles/style.css" />
    <link rel="stylesheet" href="./../styles/index-style.css" />
    <link rel="stylesheet" href="./../styles/main-index-page-style.css" />
    
        <link rel="stylesheet" href="./../styles/content-style.css" />
    
    <style>:root { --bg-clr: #E34234; --fg-clr: #262626; }</style>
    <meta name="application-name" content="Matematica applicata" />
    <meta name="apple-mobile-web-app-title" content="Matematica applicata" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="#E34234" />
    <link rel="apple-touch-icon" sizes="144x144" href="./../apple-icon-144x144.png">
    <link rel="icon" type="image/x-icon" href="./../favicon.ico">
    <link rel="icon" type="image/png" sizes="192x192" href="./../android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="96x96" href="./../favicon-96x96.png">
    <meta name="msapplication-TileColor" content="#E34234">
    <meta name="msapplication-TileImage" content="./../ms-icon-144x144.png">
    <link rel="manifest" href="./../manifest.json">
    <meta name="keywords" content="matematica applicata" />
    <meta name="description" content="Il seguente sito contiene gli appunti e le definizioni del corso 'Matematica applicata'.">
    <meta name="robots" content="index">
    <meta name="format-detection" content="telephone=no">
    <meta name="themeColor" content="#E34234">
    <script src="./../scripts/script.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-78NHLXDQD8"></script>
    <script defer async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <title>Matematica applicata - Inferenza statistica - Regressione </title>
</head>
<body>
    <div class="container">
        <header class="header-wrapper">
            <div class="title-wrapper">
                <span class="title">
                    Matematica applicata
                </span>
                <span class="subtitle">
                    by lorenzoarlo
                </span>
            </div>
            <span class="page-title">
                Inferenza statistica
            </span>
        </header>
        <aside class="sidebar">
            <h2 class="sidebar-title">Matematica applicata</h2>
            <div class="index-container">
                <ul class="parent-ul"><li class="section-li"><a href="../index.html" rel="nofollow">Indice</a></li><li class="section-li "><a href="../probabilità-discreta/calcolo-combinatorio.html" rel="nofollow">Probabilità discreta</a><ul><li class="subsection-li "><a href="../probabilità-discreta/calcolo-combinatorio.html" rel="nofollow">Calcolo combinatorio</a></li><li class="subsection-li "><a href="../probabilità-discreta/statistica.html" rel="nofollow">Statistica</a></li></ul></li><li class="section-li "><a href="../variabili-casuali/variabili-casuali-o-aleatorie.html" rel="nofollow">Variabili casuali</a><ul><li class="subsection-li "><a href="../variabili-casuali/variabili-casuali-o-aleatorie.html" rel="nofollow">Variabili casuali (o aleatorie)</a></li><li class="subsection-li "><a href="../variabili-casuali/coppia-di-variabili-casuali-discrete.html" rel="nofollow">Coppia di variabili casuali discrete</a></li><li class="subsection-li "><a href="../variabili-casuali/coppia-di-variabili-casuali-congiuntamente-continue.html" rel="nofollow">Coppia di variabili casuali congiuntamente continue</a></li><li class="subsection-li "><a href="../variabili-casuali/indipendenza-di-variabili-casuali.html" rel="nofollow">Indipendenza di variabili casuali</a></li><li class="subsection-li "><a href="../variabili-casuali/valore-atteso.html" rel="nofollow">Valore atteso</a></li><li class="subsection-li "><a href="../variabili-casuali/varianza.html" rel="nofollow">Varianza</a></li><li class="subsection-li "><a href="../variabili-casuali/covarianza.html" rel="nofollow">Covarianza</a></li><li class="subsection-li "><a href="../variabili-casuali/funzione-generatrice-di-momenti.html" rel="nofollow">Funzione generatrice di momenti</a></li><li class="subsection-li "><a href="../variabili-casuali/modelli-di-variabili-casuali-discrete.html" rel="nofollow">Modelli di variabili casuali discrete</a></li><li class="subsection-li "><a href="../variabili-casuali/modelli-di-variabili-casuali-continue.html" rel="nofollow">Modelli di variabili casuali continue</a></li><li class="subsection-li "><a href="../variabili-casuali/funzioni-di-variabili-casuali-continue.html" rel="nofollow">Funzioni di variabili casuali continue</a></li><li class="subsection-li "><a href="../variabili-casuali/processi-stocastici.html" rel="nofollow">Processi stocastici</a></li><li class="subsection-li "><a href="../variabili-casuali/legge-dei-grandi-numeri.html" rel="nofollow">Legge dei grandi numeri</a></li><li class="subsection-li "><a href="../variabili-casuali/teorema-del-limite-centrale.html" rel="nofollow">Teorema del limite centrale</a></li></ul></li><li class="section-li current">Inferenza statistica<ul><li class="subsection-li "><a href="concetti-introduttivi.html" rel="nofollow">Concetti introduttivi</a></li><li class="subsection-li "><a href="intervalli-di-confidenza.html" rel="nofollow">Intervalli di confidenza</a></li><li class="subsection-li current">Regressione<ul><li class="definition-li"><a href="#def3-14" rel="nofollow">Regressione</a></li><li class="definition-li"><a href="#def3-15" rel="nofollow">Regressione lineare</a></li><li class="definition-li"><a href="#def3-16" rel="nofollow">Regressione lineare semplice</a></li><li class="definition-li"><a href="#def3-17" rel="nofollow">Problemi di regressione lineare con il metodo dei minimi quadrati</a></li></ul></li></ul></li></ul>
            </div>
        </aside>
        <div class="sidebar-button" onclick="toggle_sidebar(this)" role="button" >
            keyboard_double_arrow_right
        </div>
        <section class="content-wrapper">
            <h1 class="section-title content-width">Regressione</h1>
            <article class="content-container content-width">
                <div class="definition environment" id="def3-14"><h2 class="environment-title">Definizione - Regressione</h2><div class="environment-body">     La <strong>regressione è una tecnica</strong> che consiste nel determinare la relazione tra le variabili casuali in ingresso <span class="math-span">\( (Z_1, Z_2, \ldots)\)</span> note e la variabile <span class="math-span">\( Y\)</span> in uscita (misurata). </div></div><div class="definition environment" id="def3-15"><h2 class="environment-title">Definizione - Regressione lineare</h2><div class="environment-body">     Nel caso in cui tra le variabile in ingresso e la variabile in uscita vi sia una <strong>relazione lineare</strong>, ovvero del tipo     <span class="math-block">\[         Y = \alpha + \beta_1 \cdot Z_1 + \beta_2 \cdot Z_2 + \ldots       \]</span>     in cui sono incogniti i coefficienti, ovvero <span class="math-span">\( \alpha, \beta_1, \beta_2\)</span>, si parla di <strong>regressione lineare</strong>.     <br/>     Il problema, in questo caso, consiste nello <strong>stimare tali coefficienti</strong> introducendo appropriati stimatori.     <br/>     Nel caso in cui si abbia <strong>un'unica variabile casuale in ingresso e in uscita</strong>, si parla di <strong>regressione lineare semplice</strong>. </div></div><div class="definition environment" id="def3-16"><h2 class="environment-title">Definizione - Regressione lineare semplice</h2><div class="environment-body">     Nel caso un sistema possa essere descritto dalla relazione     <span class="math-block">\[         Y = \alpha + \beta \cdot Z     \]</span>     si parla di regressione lineare semplice.     <br/>     Tuttavia, nella realtà, la misura (di <span class="math-span">\( Y\)</span>) è affetta da un errore di misura <span class="math-span">\( \varepsilon\)</span>.      Ciò che si osserva sarà quindi     <span class="math-block">\[         Y = \alpha + \beta \cdot Z + \varepsilon       \]</span>     Dal punto di vista pratico ciò corrisponde ad avere <strong>dati sperimentali</strong> che non sono posti su una retta (come dovrebbe essere considerando che la relazione tra le variabili è lineare), ma che <strong>costituiscono una nuvola di punti</strong>.     <br/>      Il problema è quindi capire quale è la retta che interpola meglio questi punti. </div></div><div class="definition environment" id="def3-17"><h2 class="environment-title">Definizione - Problemi di regressione lineare con il metodo dei minimi quadrati</h2><div class="environment-body">     Considerando un problema di regressione lineare semplice, si ha che al fine di stimare al meglio i coefficienti <span class="math-span">\( \alpha\)</span> e <span class="math-span">\( \beta\)</span>, è possibile utilizzare il metodo dei minimi quadrati.     <br/>     Definiamo quindi gli stimatori <span class="math-span">\( A\)</span> e <span class="math-span">\( B\)</span> rispettivamente per <span class="math-span">\( \alpha\)</span> e <span class="math-span">\( \beta\)</span>.     Considerando quindi che <span class="math-span">\( Z\)</span> che assumerà i valori fissati <span class="math-span">\( x_1, x_2, \ldots, x_n\)</span>, si ha che è possibile considerare i valori <span class="math-span">\( Y\)</span> teorici ad essi legati secondo la relazione      <span class="math-block">\[         A + B \cdot x_k      \]</span>     e paragonarli ai valori misurati, ovvero <span class="math-span">\( Y_1, Y_2, \ldots, Y_k\)</span>.     <br/>     Consideriamo quindi la distanza tra ogni punto sperimentale <span class="math-span">\( Y_k\)</span> e la retta generica <span class="math-span">\( A + B \cdot x_k\)</span>, calcolabile come la differenza     <span class="math-block">\[         \text{distanza} = Y_k - (A + B \cdot x_k)       \]</span>     Per evitare che la somma di tali "distanze" sia un valore nullo (in quanto la distanza potrebbe essere sia positiva che negativa), consideriamo la somma dei quadrati, ovvero     <span class="math-block">\[         SS = \sum_{k = 1}^n (Y_k - A - B \cdot x_k)^2      \]</span>     L'obiettivo è scegliere <span class="math-span">\( A\)</span> e <span class="math-span">\( B\)</span> in modo da minimizzare <span class="math-span">\( SS\)</span>.     <br/>     Per fare ciò imponiamo     <span class="math-block">\[         \left\{         \begin{array}{lcl}             \frac{\partial SS}{\partial A} &amp; = &amp; 0 \\             \frac{\partial SS}{\partial B} &amp; = &amp; 0          \end{array}           \right.     \]</span>     che equivale ad un <strong>problema di ricerca di massimi e minimi</strong>.      <br/>     Consideriamo quindi di risolvere la prima equazione, ovvero     <span class="math-block">\begin{aligned}         &amp;  \frac{\partial SS}{\partial A} = 0 &amp; \iff \\         &amp;  \frac{\partial}{\partial A} \left( \sum_{k = 1}^n (Y_k - A - B \cdot x_k)^2  \right) = 0 &amp; \iff \\         &amp;  -2 \cdot \sum_{k = 1}^n (Y_k - A - B \cdot x_k) = 0 &amp;     \end{aligned}</span>     che equivale alla condizione     <span class="math-block">\[         \sum_{k = 1}^n (Y_k - A - B \cdot x_k) = 0     \]</span>     Considerando invece la seconda equazione, avremo     <span class="math-block">\begin{aligned}         &amp;  \frac{\partial SS}{\partial B} = 0 &amp; \iff \\         &amp;  \frac{\partial}{\partial B} \left( \sum_{k = 1}^n (Y_k - A - B \cdot x_k)^2 \right) = 0 &amp; \iff \\         &amp;  -2 \cdot \sum_{k = 1}^n x_k \cdot (Y_k - A - B \cdot x_k) = 0 &amp; \iff \\         &amp;  -2 \cdot \sum_{k = 1}^n (Y_k \cdot x_k - A \cdot x_k - B \cdot (x_k)^2) = 0 &amp;     \end{aligned}</span>     che equivale alla condizione     <span class="math-block">\[         \sum_{k = 1}^n \left(Y_k \cdot x_k - A \cdot x_k - B \cdot (x_k)^2 \right) = 0     \]</span>     Riscrivendo il sistema iniziale, si ha che le condizioni da imporre sono le seguenti     <span class="math-block">\begin{aligned}         &amp; \left\{         \begin{array}{lcl}             \sum_{k = 1}^n (Y_k - A - B \cdot x_k) &amp; = &amp; 0 \\             \sum_{k = 1}^n (Y_k \cdot x_k - A \cdot x_k - B \cdot (x_k)^2) &amp; = &amp; 0          \end{array}           \right. &amp; \iff \\         &amp; \left\{         \begin{array}{lcl}             \sum_{k = 1}^n Y_k - n \cdot A - B \cdot \sum_{k = 1}^n  x_k &amp; = &amp; 0 \\             \sum_{k = 1}^n (Y_k \cdot x_k) - A \cdot \sum_{k = 1}^n  x_k - B \cdot \sum_{k = 1}^n (x_k)^2 &amp; = &amp; 0          \end{array}           \right. &amp;     \end{aligned}</span>     Per trovare le soluzioni di tale sistema, consideriamo la media aritmetica <span class="math-span">\( \overline{Y}\)</span> delle <span class="math-span">\( Y_k\)</span>, ovvero     <span class="math-block">\[         \overline{Y} = \frac{1}{n} \cdot \sum_{k = 1}^n Y_k       \]</span>     e la media aritmetica <span class="math-span">\( \overline{x}\)</span> delle <span class="math-span">\( x_k\)</span>, ovvero     <span class="math-block">\[         \overline{x} = \frac{1}{n} \cdot \sum_{k = 1}^n x_k         \]</span>     e calcoliamo     <ul class="list-container"><li class="list-item">per la prima equazione         <span class="math-block">\begin{aligned}             &amp; \sum_{k = 1}^n Y_k - n \cdot A - B \cdot \sum_{k = 1}^n  x_k = 0 &amp; \iff \\             &amp; n \cdot \overline{Y} - n \cdot A - B \cdot n \cdot \overline{x} = 0 &amp; \iff \\             &amp; A = \overline{Y} - B \cdot \overline{x} &amp;         \end{aligned}</span>         </li><li class="list-item">per la seconda equazione         <span class="math-block">\begin{aligned}             &amp; \sum_{k = 1}^n (Y_k \cdot x_k) - A \cdot \sum_{k = 1}^n  x_k - B \cdot \sum_{k = 1}^n (x_k)^2 = 0 &amp; \iff \\             &amp; \sum_{k = 1}^n (Y_k \cdot x_k) - A \cdot n \cdot \overline{x} - B \cdot \sum_{k = 1}^n (x_k)^2 = 0 &amp; \iff         \end{aligned}</span>         e sostituendo ad <span class="math-span">\( A\)</span> il valore ottenuto in precedenza, si procede         <span class="math-block">\begin{aligned}             &amp; \sum_{k = 1}^n (Y_k \cdot x_k) - (\overline{Y} - B \cdot \overline{x}) \cdot n \cdot \overline{x} - B \cdot \sum_{k = 1}^n (x_k)^2 = 0 &amp; \iff \\             &amp; \sum_{k = 1}^n (Y_k \cdot x_k) - \overline{Y} \cdot n \cdot \overline{x} + B \cdot n \cdot \left( \overline{x} \right)^2 - B \cdot \sum_{k = 1}^n (x_k)^2 = 0 &amp; \iff \\             &amp; B \cdot n \cdot \left( \overline{x} \right)^2 - B \cdot \sum_{k = 1}^n ( x_k )^2 = - \sum_{k = 1}^n (Y_k \cdot x_k) + \overline{Y} \cdot n \cdot \overline{x} &amp; \iff \\             &amp; B = \frac{\overline{Y} \cdot n \cdot \overline{x} - \sum_{k = 1}^n (Y_k \cdot x_k)}{ n \cdot \left( \overline{X} \right)^2 - \sum_{k = 1}^n ( x_k )^2 } &amp; \iff \\             &amp; B = \frac{\sum_{k = 1}^n \left( Y_k \cdot ( x_k - \overline{x} ) \right)}{\sum_{k = 1}^n ( x_k )^2 -  n \cdot \left( \overline{x} \right)^2 } &amp;         \end{aligned}</span>     </li></ul>     <div class="mynote environment"><h3 class="environment-title">Nota bene - Medie aritmetiche e non campionarie</h3><div class="environment-body">         È necessario notare che <span class="math-span">\( \overline{x}\)</span> e <span class="math-span">\( \overline{Y}\)</span> non sono medie campionarie, in quanto:         <ul class="list-container"><li class="list-item">i valori <span class="math-span">\( x_k\)</span> non sono variabili casuali ma valori scelti in maniera deterministica;             </li><li class="list-item">le variabili casuali <span class="math-span">\( Y_k\)</span> non appartengono alla stessa popolazione in quanto si ha che             <span class="math-block">\[                 Y_k \sim N(\alpha + \beta \cdot x_k, \sigma)               \]</span>              ovvero la media dipende da diversi valori <span class="math-span">\( x_k\)</span>.         </li></ul>     </div></div>     <h3 class="inner-title">Verificare la correttezza degli stimatori</h3>     Considerando che     <span class="math-block">\[         \begin{array}{ccl}             \sum_{k = 1}^n (x_k - \overline{x}) &amp; = &amp; \sum_{k = 1}^n x_k - \overbrace{n \cdot \overline{x}}^{\sum_{k = 1}^n x_k} \\             &amp; = &amp; \sum_{k = 1}^n x_k - \sum_{k = 1}^n x_k \\             &amp; = &amp; 0         \end{array}       \]</span>     calcoliamo il valore atteso di <span class="math-span">\( B\)</span>, ovvero     <span class="math-block">\[         \begin{array}{ccl}             E[B] &amp; = &amp; E\left[ \frac{\sum_{k = 1}^n \left( Y_k \cdot ( x_k - \overline{x} ) \right)}{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 } \right] \\              &amp; = &amp; \frac{1}{{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }} \cdot E\left[ \sum_{k = 1}^n \left( Y_k \cdot ( x_k - \overline{x} ) \right) \right] \\              &amp; = &amp; \frac{1}{{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }} \cdot \sum_{k = 1}^n \left( E\left[ Y_k \right] \cdot ( x_k - \overline{x} ) \right)  \\              &amp; = &amp; \frac{1}{{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }} \cdot \sum_{k = 1}^n \left( (\alpha + \beta \cdot x_k) \cdot ( x_k - \overline{x} ) \right)  \\              &amp; = &amp; \frac{1}{{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }} \cdot \sum_{k = 1}^n \left( \alpha \cdot ( x_k - \overline{x} ) \right) + \sum_{k = 1}^n \left( \beta \cdot x_k \cdot ( x_k - \overline{x} ) \right)  \\              &amp; = &amp; \frac{1}{{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }} \cdot \left( \underbrace{\alpha \cdot  \sum_{k = 1}^n ( x_k - \overline{x} )}_0 + \beta \cdot \sum_{k = 1}^n \left(  (x_k)^2 - \overline{x} \cdot x_k \right) \right)  \\             &amp; = &amp; \frac{\beta}{{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }} \cdot \sum_{k = 1}^n \left(  (x_k)^2 - \overline{x} \cdot x_k \right) \\             &amp; = &amp; \frac{\beta}{{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }} \cdot \left( \sum_{k = 1}^n (x_k)^2 - \overline{x} \cdot \sum_{k = 1}^n x_k \right) \\             &amp; = &amp; \frac{\beta}{{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }} \cdot \left( \sum_{k = 1}^n (x_k)^2 - (\overline{x})^2 \cdot n\right) \\             &amp; = &amp; \beta         \end{array}     \]</span>     Calcolando ora il valore atteso di <span class="math-span">\( A\)</span>, si ottiene      <span class="math-block">\[         \begin{array}{ccl}             E[A] &amp; = &amp; E\left[ \overline{Y} - B \cdot \overline{x} \right] \\             &amp; = &amp; E\left[ \overline{Y} \right] - \overline{x} \cdot E[B] \\             &amp; = &amp; E\left[ \frac{1}{n} \cdot \sum_{k = 1}^n Y_k \right] - \overline{x} \cdot \beta \\             &amp; = &amp; \frac{1}{n} \cdot E\left[ \sum_{k = 1}^n Y_k \right] - \overline{x} \cdot \beta \\              &amp; = &amp; \frac{1}{n} \cdot \sum_{k = 1}^n E\left[  Y_k \right] - \overline{x} \cdot \beta \\              &amp; = &amp; \frac{1}{n} \cdot \sum_{k = 1}^n (\alpha + \beta \cdot x_k) - \overline{x} \cdot \beta \\              &amp; = &amp; \frac{n \cdot \alpha}{n} + \beta \cdot \frac{1}{n} \cdot \sum_{k = 1}^n x_k - \overline{x} \cdot \beta \\              &amp; = &amp; \frac{n \cdot \alpha}{n} + \beta \cdot \overline{x} - \overline{x} \cdot \beta \\              &amp; = &amp; \alpha         \end{array}     \]</span>     Riassumendo, si ha quindi che <span class="math-span">\( A\)</span> e <span class="math-span">\( B\)</span> sono stimatori corretti, rispettivamente, per <span class="math-span">\( \alpha\)</span> e <span class="math-span">\( \beta\)</span>.     <h3 class="inner-title">Verificare l'efficienza di <span class="math-span">\( B\)</span></h3>     Considerando che     <span class="math-block">\[         \begin{array}{ccl}             \sum_{k = 1}^n (x_k - \overline{x})^2 &amp; = &amp; \sum_{k = 1}^n ((x_k)^2 - 2 \cdot x_k \cdot \overline{x} + (\overline{x})^2 ) \\             &amp; = &amp; \sum_{k = 1}^n (x_k)^2 - 2 \cdot \overline{x} \cdot \overbrace{\sum_{k = 1}^n x_k}^{n \cdot \overline{x}} + \overbrace{\sum_{k = 1}^n (\overline{x})^2}^{n \cdot (\overline{x})^2} \\             &amp; = &amp; \sum_{k = 1}^n (x_k)^2 - n \cdot (\overline{x})^2         \end{array}       \]</span>     e definendo il valore <span class="math-span">\( \sum_{k = 1}^n H_k\)</span> uguale a      <span class="math-block">\[         \sum_{k = 1}^n H_k = \frac{\sum_{k = 1}^n  ( x_k - \overline{x} )}{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 }     \]</span>     calcoliamo la varianza di <span class="math-span">\( B\)</span>, ovvero     <span class="math-block">\[         \begin{array}{ccl}             Var(B) &amp; = &amp; Var\left(  \frac{\sum_{k = 1}^n \left( Y_k \cdot ( x_k - \overline{x} ) \right)}{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 } \right) \\             &amp; = &amp; Var\left(  \sum_{k = 1}^n ( Y_k \cdot H_k)  \right) \\             &amp; \underset{\text{indip.}}{=} &amp; \sum_{k = 1}^n Var(Y_k \cdot H_k) \\             &amp; = &amp; \sum_{k = 1}^n \left( (H_k)^2 \cdot Var(Y_k) \right) \\             &amp; = &amp; \sum_{k = 1}^n \left( (H_k)^2 \cdot \sigma^2 \right) \\             &amp; = &amp; \sigma^2 \cdot \sum_{k = 1}^n (H_k)^2  \\             &amp; = &amp; \sigma^2 \cdot \frac{\overbrace{\sum_{k = 1}^n  ( x_k - \overline{x} )^2 }^{\sum_{k = 1}^n (x_k)^2 - n \cdot (\overline{x})^2}}{\left( \sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2 \right)^2} \\             &amp; = &amp; \frac{\sigma^2}{\sum_{j = 1}^n ( x_j )^2 -  n \cdot \left( \overline{x} \right)^2}         \end{array}       \]</span>     che verifica l'efficienza di <span class="math-span">\( B\)</span>, in quanto i valori <span class="math-span">\( x_j\)</span> al denominatore sono deterministici (permettendo quindi di "sceglierli" grandi e distanti a piacere).     <h3 class="inner-title">Distribuzione di <span class="math-span">\( B\)</span></h3>     Considerando lo stimatore <span class="math-span">\( B\)</span>     <span class="math-block">\[         B = \frac{\sum_{k = 1}^n \left( Y_k \cdot ( x_k - \overline{x} ) \right)}{\sum_{k = 1}^n ( x_k )^2 -  n \cdot \left( \overline{x} \right)^2 }     \]</span>     si ha che è combinazione lineare delle variabili <span class="math-span">\( Y_k\)</span> (che sono variabili casuali gaussiane e indipendenti) ed ha quindi la seguente distribuzione     <span class="math-block">\[         B \sim N\left(\beta, \sqrt{\frac{\sigma^2}{\sum_{k = 1}^n ( x_k )^2 -  n \cdot \left( \overline{x} \right)^2}} \right)       \]</span> </div></div>
            </article>
            <nav class="buttons-container content-width">
                <a class="navigation-button previous" href="intervalli-di-confidenza.html" rel="nofollow"><span>Intervalli di confidenza</span></a>
                
            </nav>
        </section>
        <div class="scroll-to-bottom-button" onclick="scroll_to_bottom()">
            <span class="material-symbols-outlined">
                keyboard_double_arrow_down
            </span>
        </div>
            <footer class="footer-wrapper">
                <div class="copyright-wrapper">
                    <span> &copy; Copyright 2024</span> /
                    <span>made by <a href="https://github.com/lorenzoarlo" rel="nofollow">lorenzoarlo</a></span>
                </div>
                /
                <div class="privacy-wrapper">
                    <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/" rel="nofollow">Pannello preferenze
                            cookie</a></span> /
                    <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/privacy-policy.html" rel="nofollow"
                            target="_blank">Privacy Policy</a></span>
                </div>
            </footer>
    </div>
</body>
</html>