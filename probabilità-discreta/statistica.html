<!DOCTYPE html>
<html lang="IT">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="stylesheet" href="./../styles/style.css" />
    <link rel="stylesheet" href="./../styles/index-style.css" />
    <link rel="stylesheet" href="./../styles/main-index-page-style.css" />
    
        <link rel="stylesheet" href="./../styles/content-style.css" />
    
    <style>:root { --bg-clr: #E34234; --fg-clr: #262626; }</style>
    <meta name="application-name" content="Matematica applicata" />
    <meta name="apple-mobile-web-app-title" content="Matematica applicata" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="#E34234" />
    <link rel="apple-touch-icon" sizes="144x144" href="./../apple-icon-144x144.png">
    <link rel="icon" type="image/x-icon" href="./../favicon.ico">
    <link rel="icon" type="image/png" sizes="192x192" href="./../android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="96x96" href="./../favicon-96x96.png">
    <meta name="msapplication-TileColor" content="#E34234">
    <meta name="msapplication-TileImage" content="./../ms-icon-144x144.png">
    <link rel="manifest" href="./../manifest.json">
    <meta name="keywords" content="matematica applicata" />
    <meta name="description" content="Il seguente sito contiene gli appunti e le definizioni del corso 'Matematica applicata'.">
    <meta name="robots" content="index">
    <meta name="format-detection" content="telephone=no">
    <meta name="themeColor" content="#E34234">
    <script src="./../scripts/script.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-78NHLXDQD8"></script>
    <script defer async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <title>Matematica applicata - Probabilità discreta - Statistica </title>
</head>
<body>
    <div class="container">
        <header class="header-wrapper">
            <div class="title-wrapper">
                <span class="title">
                    Matematica applicata
                </span>
                <span class="subtitle">
                    by lorenzoarlo
                </span>
            </div>
            <span class="page-title">
                Probabilità discreta
            </span>
        </header>
        <aside class="sidebar">
            <h2 class="sidebar-title">Matematica applicata</h2>
            <div class="index-container">
                <ul class="parent-ul"><li class="section-li"><a href="../index.html" rel="nofollow">Indice</a></li><li class="section-li current">Probabilità discreta<ul><li class="subsection-li "><a href="calcolo-combinatorio.html" rel="nofollow">Calcolo combinatorio</a></li><li class="subsection-li current">Statistica<ul><li class="definition-li"><a href="#def1-7" rel="nofollow">Spazio campione</a></li><li class="definition-li"><a href="#def1-8" rel="nofollow">Evento</a></li><li class="definition-li"><a href="#def1-9" rel="nofollow">Unione di eventi</a></li><li class="definition-li"><a href="#def1-10" rel="nofollow">Intersezione di eventi</a></li><li class="definition-li"><a href="#def1-11" rel="nofollow">Evento complementare</a></li><li class="definition-li"><a href="#def1-12" rel="nofollow">Definizione classica di probabilità</a></li><li class="definition-li"><a href="#def1-13" rel="nofollow">Definizione frequentista di probabilità</a></li><li class="definition-li"><a href="#def1-14" rel="nofollow">Definizione assiomatica di probabilità e assiomi di Kolmogorov</a></li><li class="myexample-li"><a href="#example2" rel="nofollow">"Paradosso" dei compleanni</a></li><li class="demonstration-li"><a href="#dem1-1" rel="nofollow">Probabilità dell'evento complementare (prima conseguenza degli assiomi di Kolmogorov)</a></li><li class="demonstration-li"><a href="#dem1-2" rel="nofollow">Probabilità dell'insieme vuoto (seconda conseguenza degli assiomi di Kolmogorov)</a></li><li class="demonstration-li"><a href="#dem1-3" rel="nofollow">Probabilità di un sotto-evento (terza conseguenza degli assiomi di Kolmogorov)</a></li><li class="demonstration-li"><a href="#dem1-4" rel="nofollow">Probabilità dell'unione di due eventi (quarta conseguenza degli assiomi di Kolmogorov)</a></li><li class="demonstration-li"><a href="#dem1-5" rel="nofollow">Complementare dell'intersezione di eventi</a></li><li class="demonstration-li"><a href="#dem1-6" rel="nofollow">Complementare dell'unione di eventi</a></li><li class="definition-li"><a href="#def1-15" rel="nofollow">Definizione classica di probabilità in termini assiomatici (spazio degli esiti equiprobabili)</a></li><li class="myexample-li"><a href="#example3" rel="nofollow">Probabilità di estrazione di una chiave al \( k\)-esimo tentativo (senza reinserimento)</a></li><li class="myexample-li"><a href="#example4" rel="nofollow">Probabilità di estrazione di una chiave al \( k\)-esimo tentativo (con reinserimento)</a></li><li class="myexample-li"><a href="#example5" rel="nofollow">Probabilità di sorteggio</a></li><li class="myexample-li"><a href="#example6" rel="nofollow">Probabilità di ottenere almeno una testa sul lancio di due monete</a></li><li class="definition-li"><a href="#def1-16" rel="nofollow">Probabilità dell'unione di tre eventi</a></li><li class="definition-li"><a href="#def1-17" rel="nofollow">Eventi indipendenti</a></li><li class="definition-li"><a href="#def1-18" rel="nofollow">Probabilità condizionata</a></li><li class="myexample-li"><a href="#example7" rel="nofollow">Probabilità condizionata</a></li><li class="definition-li"><a href="#def1-19" rel="nofollow">Probabilità condizionata nel caso di eventi indipendenti</a></li><li class="definition-li"><a href="#def1-20" rel="nofollow">Probabilità dell'intersezione di eventi dipendenti</a></li><li class="definition-li"><a href="#def1-21" rel="nofollow">Partizione dello spazio campione</a></li><li class="demonstration-li"><a href="#dem1-7" rel="nofollow">Teorema delle probabilità totali</a></li><li class="myexample-li"><a href="#example8" rel="nofollow">Teorema delle probabilità totali - Assicurazioni</a></li><li class="myexample-li"><a href="#example9" rel="nofollow">Teorema delle probabilità totali - Esami diagnostici e falsi positivi</a></li><li class="demonstration-li"><a href="#dem1-8" rel="nofollow">Relazione tra eventi disgiunti ed eventi indipendenti</a></li><li class="demonstration-li"><a href="#dem1-9" rel="nofollow">Teorema di Bayes</a></li><li class="myexample-li"><a href="#example10" rel="nofollow">Teorema di Bayes - "Paradosso" delle scatole di Bertrand</a></li><li class="definition-li"><a href="#def1-22" rel="nofollow">Problema della rovina del giocatore</a></li><li class="demonstration-li"><a href="#dem1-10" rel="nofollow">Indipendenza degli eventi complementari di eventi indipendenti</a></li><li class="definition-li"><a href="#def1-23" rel="nofollow">Problemi con dispositivi in serie e in parallelo</a></li></ul></li></ul></li><li class="section-li "><a href="../variabili-casuali/variabili-casuali-o-aleatorie.html" rel="nofollow">Variabili casuali</a><ul><li class="subsection-li "><a href="../variabili-casuali/variabili-casuali-o-aleatorie.html" rel="nofollow">Variabili casuali (o aleatorie)</a></li><li class="subsection-li "><a href="../variabili-casuali/coppia-di-variabili-casuali-discrete.html" rel="nofollow">Coppia di variabili casuali discrete</a></li><li class="subsection-li "><a href="../variabili-casuali/coppia-di-variabili-casuali-congiuntamente-continue.html" rel="nofollow">Coppia di variabili casuali congiuntamente continue</a></li><li class="subsection-li "><a href="../variabili-casuali/indipendenza-di-variabili-casuali.html" rel="nofollow">Indipendenza di variabili casuali</a></li><li class="subsection-li "><a href="../variabili-casuali/valore-atteso.html" rel="nofollow">Valore atteso</a></li><li class="subsection-li "><a href="../variabili-casuali/varianza.html" rel="nofollow">Varianza</a></li><li class="subsection-li "><a href="../variabili-casuali/covarianza.html" rel="nofollow">Covarianza</a></li><li class="subsection-li "><a href="../variabili-casuali/funzione-generatrice-di-momenti.html" rel="nofollow">Funzione generatrice di momenti</a></li><li class="subsection-li "><a href="../variabili-casuali/modelli-di-variabili-casuali-discrete.html" rel="nofollow">Modelli di variabili casuali discrete</a></li><li class="subsection-li "><a href="../variabili-casuali/modelli-di-variabili-casuali-continue.html" rel="nofollow">Modelli di variabili casuali continue</a></li><li class="subsection-li "><a href="../variabili-casuali/funzioni-di-variabili-casuali-continue.html" rel="nofollow">Funzioni di variabili casuali continue</a></li><li class="subsection-li "><a href="../variabili-casuali/processi-stocastici.html" rel="nofollow">Processi stocastici</a></li><li class="subsection-li "><a href="../variabili-casuali/legge-dei-grandi-numeri.html" rel="nofollow">Legge dei grandi numeri</a></li><li class="subsection-li "><a href="../variabili-casuali/teorema-del-limite-centrale.html" rel="nofollow">Teorema del limite centrale</a></li></ul></li><li class="section-li "><a href="../inferenza-statistica/concetti-introduttivi.html" rel="nofollow">Inferenza statistica</a><ul><li class="subsection-li "><a href="../inferenza-statistica/concetti-introduttivi.html" rel="nofollow">Concetti introduttivi</a></li><li class="subsection-li "><a href="../inferenza-statistica/intervalli-di-confidenza.html" rel="nofollow">Intervalli di confidenza</a></li><li class="subsection-li "><a href="../inferenza-statistica/regressione.html" rel="nofollow">Regressione</a></li></ul></li></ul>
            </div>
        </aside>
        <div class="sidebar-button" onclick="toggle_sidebar(this)" role="button" >
            keyboard_double_arrow_right
        </div>
        <section class="content-wrapper">
            <h1 class="section-title content-width">Statistica</h1>
            <article class="content-container content-width">
                <div class="definition environment" id="def1-7"><h2 class="environment-title">Definizione - Spazio campione</h2><div class="environment-body">     Lo <strong>spazio campione</strong> di un esperimento indica l'insieme di tutti gli esiti possibili per questo, ovvero     <span class="math-block">\[         S = \{ e_1, \ldots, e_n \}       \]</span>     Esso è indicato solitamente con <span class="math-span">\( S\)</span> (oppure <span class="math-span">\( \Omega\)</span>). </div></div><div class="definition environment" id="def1-8"><h2 class="environment-title">Definizione - Evento</h2><div class="environment-body">     Un evento è un <strong>sottoinsieme dello spazio campione</strong>.     <br/>     Si indica con una lettera maiuscola (diversa solitamente da <span class="math-span">\( P\)</span> e <span class="math-span">\( S\)</span>). </div></div><div class="definition environment" id="def1-9"><h2 class="environment-title">Definizione - Unione di eventi</h2><div class="environment-body">     Considerando due eventi <span class="math-span">\( E, F \subset S\)</span>, l'<strong>unione dei due eventi</strong> si indica con     <span class="math-block">\[         E \cup F       \]</span>     e comprende gli esiti appartenenti ad <strong>almeno uno</strong> dei due eventi. </div></div><div class="definition environment" id="def1-10"><h2 class="environment-title">Definizione - Intersezione di eventi</h2><div class="environment-body">     Considerando due eventi <span class="math-span">\( E, F \subset S\)</span>, l'<strong>intersezione dei due eventi</strong> si indica con     <span class="math-block">\[         E \cap F       \]</span>     e comprende gli esiti appartenenti ad <strong>entrambi</strong> gli eventi.     <br/>     Se <span class="math-span">\( E \cap F\)</span> non contiene esiti, esso si indica con l'insieme vuoto (<span class="math-span">\( \varnothing\)</span>) e i due eventi si dicono <strong>mutuamente esclusivi</strong> (o <strong>disgiunti</strong>). </div></div><div class="definition environment" id="def1-11"><h2 class="environment-title">Definizione - Evento complementare</h2><div class="environment-body">     Considerando un evento <span class="math-span">\( E \subset S\)</span>, l'<strong>evento complementare</strong> <span class="math-span">\( E^c\)</span> è uguale a     <span class="math-block">\[         E^c = S \setminus E     \]</span>     e comprende gli esiti dello spazio campione <span class="math-span">\( S\)</span> che non appartengono a <span class="math-span">\( E\)</span>.  </div></div><div class="definition environment" id="def1-12"><h2 class="environment-title">Definizione - Definizione classica di probabilità</h2><div class="environment-body">     Considerando uno spazio campione <span class="math-span">\( S\)</span> ed un evento <span class="math-span">\( E \subset S\)</span>, si associa all'evento <span class="math-span">\( E\)</span> <strong>un numero reale detto probabilità</strong> (indicato con <span class="math-span">\( P(E)\)</span>) uguale a     <span class="math-block">\[         P(E) = \frac{n^\circ \ \text{esiti in} \ E}{n^\circ \ \text{esiti in} \ S}       \]</span>     Tale definizione è valida tuttavia solo se <span class="math-span">\( S\)</span> è un insieme finito e se gli esiti sono equiprobabili.     <div class="mynote environment"><h3 class="environment-title">Nota bene - Matematicamente sbagliato</h3><div class="environment-body">         Tale definizione risulta essere matematicamente sbagliata, in quanto per definire la probabilità si utilizza la definizione stessa di probabilità (per il termine "equiprobabile").     </div></div> </div></div><div class="definition environment" id="def1-13"><h2 class="environment-title">Definizione - Definizione frequentista di probabilità</h2><div class="environment-body">     Considerando uno spazio campione <span class="math-span">\( S\)</span> ed un evento <span class="math-span">\( E \subset S\)</span>, si associa all'evento <span class="math-span">\( E\)</span> un numero reale detto <strong>probabilità</strong> (indicato con <span class="math-span">\( P(E)\)</span>) ottenuto ripetendo un esperimento per <span class="math-span">\( n\)</span> volte e calcolato come      <span class="math-block">\[         P(E) = \frac{n_E}{n}         \]</span>      dove <span class="math-span">\( n_E\)</span> è il numero di tentativi in cui <span class="math-span">\( E\)</span> è verificato. </div></div><div class="definition environment" id="def1-14"><h2 class="environment-title">Definizione - Definizione assiomatica di probabilità e assiomi di Kolmogorov</h2><div class="environment-body">     Considerando uno spazio campione <span class="math-span">\( S\)</span> ed un evento <span class="math-span">\( E \subset S\)</span>, si associa ad <span class="math-span">\( E\)</span> un numero reale <span class="math-span">\( P(E)\)</span> detto probabilità tale che:     <ul class="list-container"><li class="list-item"><strong>la probabilità dell'evento è un numero tra <span class="math-span">\( 0\)</span> e <span class="math-span">\( 1\)</span></strong> (<span class="math-span">\( P(E) \in [0, 1]\)</span>);         </li><li class="list-item"><strong>la probabilità dello spazio campione è <span class="math-span">\( 1\)</span></strong> (<span class="math-span">\( P(S) = 1\)</span>);         </li><li class="list-item">dati <span class="math-span">\( m\)</span> eventi <span class="math-span">\( E_1, \ldots, E_m \subset S\)</span> disgiunti (ovvero <span class="math-span">\( E_i \cap E_j = \varnothing\)</span>, se <span class="math-span">\( i \neq j\)</span>), si ha che         <span class="math-block">\[             P\left(\bigcup_{k = 1}^m E_k \right) = \sum_{k = 1}^m P(E_k)         \]</span>         ovvero, l'<strong>unione di più eventi disgiunti ha probabilità pari alla somma delle probabilità dei singoli eventi</strong>.     </li></ul> </div></div><div class="myexample environment" id="example2"><h2 class="environment-title">Esempio - "Paradosso" dei compleanni</h2><div class="environment-body collapsed">     Considerando <span class="math-span">\( n\)</span> individui nati in un anno non bisestile, qual è la probabilità che tutti siano nati in giorni diversi?     <br/>     Per risolvere questo problema, consideriamo l'evento <span class="math-span">\( C\)</span>     <span class="math-block">\[         C = \{ \text{tutti hanno date di compleanno differenti} \}      \]</span>     e ipotizzando che la possibilità di nascere in un certo giorno sia uguale per ogni giorno (ovvero vi è equiprobabilità), si ha che     <span class="math-block">\[         P(C) = \frac{n^\circ \ \text{esiti di} \ C}{n^\circ \ \text{esiti totali}}       \]</span>     È quindi possibile considerare tale problema come un'estrazione: immaginando di avere una sequenza di <span class="math-span">\( N\)</span> esperimenti, si ha che     <ul class="list-container"><li class="list-item">il numero di esiti di <span class="math-span">\( C\)</span> può essere trattato come una disposizione semplice (in quanto si vogliono giorni differenti) di <span class="math-span">\( 365\)</span> giorni di classe <span class="math-span">\( N\)</span>.          Si ha quindi che tale valore è uguale a         <span class="math-block">\[             n^\circ \ \text{esiti di} \ C = D_{365, N} = \frac{365!}{(365 - N)!}         \]</span>         </li><li class="list-item">il numero di esiti totali può essere visto come una disposizione con ripetizione di <span class="math-span">\( 365\)</span> oggetti di classe <span class="math-span">\( N\)</span>.          Si ha quindi che tale valore è uguale a          <span class="math-block">\[             n^\circ \ \text{esiti totali} = D^R_{365, N} = 365^N         \]</span>     </li></ul>     Sostituendo alla formula i relativi valori si ottiene quindi che     <span class="math-block">\[         P(C) = \frac{365!}{(365 - N)!} \cdot \frac{1}{365^N}     \]</span>     Andando a sostituire ad <span class="math-span">\( N\)</span> dei valori, è possibile capire perchè si indichi impropriamente tale problema come "paradosso", dato che al crescere di <span class="math-span">\( N\)</span> la probabilità diminuisce molto velocemente, infatti:     <ul class="list-container"><li class="list-item">considerando <span class="math-span">\( N = 23\)</span>, si ha che <span class="math-span">\( P(C) \approxeq 49 \%\)</span>;         </li><li class="list-item">considerando <span class="math-span">\( N = 30\)</span>, si ha che <span class="math-span">\( P(C) \approxeq 30 \%\)</span>;         </li><li class="list-item">considerando <span class="math-span">\( N = 50\)</span>, si ha che <span class="math-span">\( P(C) \approxeq 3 \%\)</span>.     </li></ul> </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="demonstration environment" id="dem1-1"><h2 class="environment-title">Dimostrazione - Probabilità dell'evento complementare (prima conseguenza degli assiomi di Kolmogorov)</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato uno spazio campione <span class="math-span">\( S\)</span> ed un evento <span class="math-span">\( E \subseteq S\)</span>, si ha che         <span class="math-block">\[             P(E^c) = 1 - P(E)           \]</span>         ovvero, <strong>la probabilità di un evento è pari alla differenza tra <span class="math-span">\( 1\)</span> e la probabilità dell'evento complementare</strong>.     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione, consideriamo che per definizione di evento complementare si ha che         <span class="math-block">\[             E^c \cap E = \varnothing \qquad \text{e che} \qquad E^c \cup E = S         \]</span>         Dato che, per il secondo assioma di Kolmogorov         <span class="math-block">\[             P(S) = P(E^c \cup E) = 1             \]</span>         e dato che <span class="math-span">\( E^c\)</span> ed <span class="math-span">\( E\)</span> sono disgiunti, si ha che per il terzo assioma di Kolmogorov         <span class="math-block">\[             P(E^c \cup E) = P(E^c) + P(E)         \]</span>         Riscrivendo quindi tali relazioni, si ha che         <span class="math-block">\begin{aligned}             &amp; P(E^c) + P(E) = 1 &amp; \iff \\             &amp; P(E^c) = 1 - P(E) &amp;          \end{aligned}</span>         che dimostra la proposizione.     </div></div> </div></div><div class="demonstration environment" id="dem1-2"><h2 class="environment-title">Dimostrazione - Probabilità dell'insieme vuoto (seconda conseguenza degli assiomi di Kolmogorov)</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato un evento <span class="math-span">\( E\)</span> privo di esiti (ovvero uguale all'insieme vuoto), si ha che         <span class="math-block">\[             P(\varnothing) = 0           \]</span>     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione, consideriamo che         <span class="math-block">\[             P(S) = 1             \]</span>         e che          <span class="math-block">\[             P(S^c) = P(\varnothing)           \]</span>         Dato inoltre che         <span class="math-block">\[             P(S^c) = 1 - P(S)         \]</span>         è semplice ottenere         <span class="math-block">\[             P(S^c) = 0 = P(\varnothing)         \]</span>         che dimostra la proposizione.     </div></div> </div></div><div class="demonstration environment" id="dem1-3"><h2 class="environment-title">Dimostrazione - Probabilità di un sotto-evento (terza conseguenza degli assiomi di Kolmogorov)</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato uno spazio campione <span class="math-span">\( S\)</span> e due eventi <span class="math-span">\( E, F \subset S\)</span> tali che <span class="math-span">\( E \subseteq F\)</span>, allora         <span class="math-block">\[             P(E) \leq P(F)           \]</span>      </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione, consideriamo gli esiti di <span class="math-span">\( F\)</span> non appartenenti ad <span class="math-span">\( E\)</span>, ovvero <span class="math-span">\( E^c \cap F\)</span>.          <br/>         È quindi possibile definire <span class="math-span">\( F\)</span> come         <span class="math-block">\[             F = E \cup (E^c \cap F)         \]</span>         ovvero è composto dagli elementi di <span class="math-span">\( E\)</span> e gli elementi di <span class="math-span">\( F\)</span> che non appartengono ad <span class="math-span">\( E\)</span>.         <br/>         Inoltre, si ha che gli eventi <span class="math-span">\( E\)</span> ed <span class="math-span">\( E^c \cap F\)</span> sono disgiunti e, per il terzo assioma di Kolmogorov, vale         <span class="math-block">\[             P(E \cup (E^c \cap F)) = P(E) + P(E^c \cap F)         \]</span>         Notiamo inoltre che, per il primo assioma di Kolmogorov, una qualsiasi probabilità deve essere <span class="math-span">\( \geq 0\)</span>, e quindi anche         <span class="math-block">\[             P(E^c \cap F) \geq 0         \]</span>         ciò significa che nella relazione sopracitata, si ha obbligatoriamente         <span class="math-block">\[             \overbrace{P(E \cup (E^c \cap F))}^{P(F)} = P(E) + \overbrace{P(E^c \cap F)}^{\geq 0}             \quad \implies \quad             P(F) \geq P(E)         \]</span>         che dimostra la proposizione.     </div></div> </div></div><div class="demonstration environment" id="dem1-4"><h2 class="environment-title">Dimostrazione - Probabilità dell'unione di due eventi (quarta conseguenza degli assiomi di Kolmogorov)</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato uno spazio campione <span class="math-span">\( S\)</span> e due eventi <span class="math-span">\( E, F \subset S\)</span> , si ha che         <span class="math-block">\[             P(E \cup F) = P(E) + P(F) - P(E \cap F)         \]</span>      </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione, definiamo i seguenti eventi:         <ul class="list-container"><li class="list-item"><span class="math-span">\( A_1 = E \cap F^c\)</span>, ovvero gli esiti di <span class="math-span">\( E\)</span> ma non appartenenti ad <span class="math-span">\( F\)</span>;             </li><li class="list-item"><span class="math-span">\( A_2 = E \cap F\)</span>, ovvero gli esiti in comune tra <span class="math-span">\( E\)</span> ed <span class="math-span">\( F\)</span>;             </li><li class="list-item"><span class="math-span">\( A_3 = E^c \cap F\)</span>, ovvero gli esiti di <span class="math-span">\( F\)</span> ma non appartenenti ad <span class="math-span">\( E\)</span>.         </li></ul>         Si ha quindi che         <span class="math-block">\[             \begin{array}{lcl}                 E = A_1 \cup A_2 &amp; \implies &amp; P(E) = P(A_1) + P(A_2) \\                 F = A_2 \cup A_3 &amp; \implies &amp; P(F) = P(A_2) + P(A_3)             \end{array}           \]</span>         Considerando quindi <span class="math-span">\( E \cup F\)</span> in funzione degli eventi <span class="math-span">\( A_i\)</span>, si avrebbe         <span class="math-block">\[             E \cup F = A_1 \cup A_2 \cup A_3           \]</span>         che implica (dato che sono eventi disgiunti)         <span class="math-block">\[             P(E \cup F) = P(A_1) + P(A_2) + P(A_3)           \]</span>         Considerando tutto ciò, si ha che          <span class="math-block">\[             \begin{array}{lcl}                 P(E) + P(F) - P(E \cap F) &amp; = &amp; \overbrace{P(A_1) + P(A_2)}^{P(E)} + \overbrace{P(A_2) + P(A_3)}^{P(F)} - \overbrace{P(A_2)}^{P(E \cap F)} \\                 &amp; = &amp;  P(A_1) + P(A_2) + P(A_3)  \\                 &amp; = &amp; P(E \cup F)             \end{array}           \]</span>         che dimostra la proposizione.     </div></div> </div></div><div class="demonstration environment" id="dem1-5"><h2 class="environment-title">Dimostrazione - Complementare dell'intersezione di eventi</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato uno spazio campione <span class="math-span">\( S\)</span> e due eventi <span class="math-span">\( E, F \subset S\)</span>, si ha che il complementare dell'intersezione di due eventi è l'unione dei due eventi complementari, ovvero         <span class="math-block">\[             (E \cap F)^c = (E^c \cup F^c)           \]</span>     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare ciò, consideriamo la rappresentazione grafica dei due eventi         <div class="image-environment"><div class="image-wrapper spaced-60"><img alt="Immagine" src="../resources/intersezione-eventi.png"/></div></div>         e consideriamo il suo complementare:         <div class="image-environment"><div class="image-wrapper spaced-60"><img alt="Immagine" src="../resources/complementare-intersezione.png"/></div></div>         Consideriamo ora il complementare di <span class="math-span">\( E\)</span>         <div class="image-environment"><div class="image-wrapper spaced-60"><img alt="Immagine" src="../resources/complementare-e.png"/></div></div>         e il complementare di <span class="math-span">\( F\)</span>         <div class="image-environment"><div class="image-wrapper spaced-60"><img alt="Immagine" src="../resources/complementare-f.png"/></div></div>         si ha che l'unione dei due eventi complementari è esattamente il complementare dell'intersezione.     </div></div> </div></div><div class="demonstration environment" id="dem1-6"><h2 class="environment-title">Dimostrazione - Complementare dell'unione di eventi</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato uno spazio campione <span class="math-span">\( S\)</span> e due eventi <span class="math-span">\( E, F \subset S\)</span>, si ha che il complementare dell'unione di due eventi è l'intersezione dei due eventi complementari, ovvero         <span class="math-block">\[             (E \cup F)^c = (E^c \cap F^c)           \]</span>     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare ciò, consideriamo la rappresentazione grafica dei due eventi         <div class="image-environment"><div class="image-wrapper spaced-60"><img alt="Immagine" src="../resources/unione-eventi.png"/></div></div>         e consideriamo il suo complementare:         <div class="image-environment"><div class="image-wrapper spaced-60"><img alt="Immagine" src="../resources/complementare-unione.png"/></div></div>         Consideriamo ora il complementare di <span class="math-span">\( E\)</span>         <div class="image-environment"><div class="image-wrapper spaced-60"><img alt="Immagine" src="../resources/complementare-e.png"/></div></div>         e il complementare di <span class="math-span">\( F\)</span>         <div class="image-environment"><div class="image-wrapper spaced-60"><img alt="Immagine" src="../resources/complementare-f.png"/></div></div>         si ha che l'intersezione dei due eventi complementari è esattamente il complementare dell'unione.     </div></div> </div></div><div class="definition environment" id="def1-15"><h2 class="environment-title">Definizione - Definizione classica di probabilità in termini assiomatici (spazio degli esiti equiprobabili)</h2><div class="environment-body">     Considerando uno spazio campione <span class="math-span">\( S\)</span> contenente <span class="math-span">\( n\)</span> esiti equiprobabili, ovvero     <span class="math-block">\[         S = \{ e_1, \ldots, e_n \} \ : \ P(e_1) = \ldots = P(e_n)         \]</span>     si ha che lo spazio campione è l'unione di tutti gli eventi disgiunti e per definizione di esito     <span class="math-block">\[         S = \bigcup_{j = 1}^{n} e_j \qquad \text{con} \          e_i \cap e_j = \varnothing \quad \text{se} \quad i \neq j     \]</span>     si ha che     <span class="math-block">\begin{aligned}         &amp; P(S) = 1 &amp; \iff \\          &amp; P\left( \bigcup_{j = 1}^{n} e_j \right) = 1 &amp; \iff \\         &amp; \sum_{j = 1}^n P(e_j) = 1 &amp; \iff     \end{aligned}</span>     e dato che sono equiprobabili, possiamo denominare la probabilità degli esiti come <span class="math-span">\( p\)</span>, andando ad ottenere     <span class="math-block">\begin{aligned}         &amp; \sum_{j = 1}^n p = 1 &amp; \iff \\         &amp; n \cdot p = 1 &amp; \iff \\         &amp; p = \frac{1}{n} &amp;     \end{aligned}</span>     che <span class="math-span">\( p = \frac{1}{n}\)</span>.     <br/>     Consideriamo quindi un qualsiasi evento <span class="math-span">\( E \subseteq S\)</span> composto da <span class="math-span">\( k\)</span> esiti (con <span class="math-span">\( k \leq n\)</span>), ovvero     <span class="math-block">\[         E = \{ e_1, \ldots, e_k \} \quad \text{con} \ k \leq n        \]</span>     e tenendo conto delle considerazioni fatte per <span class="math-span">\( S\)</span> anche per <span class="math-span">\( E\)</span>, si ottiene     <span class="math-block">\begin{aligned}         &amp; P(E) = P\left( \bigcup_{j = 1}^{k} e_j \right) &amp; \iff \\         &amp; P(E) = \sum_{j = 1}^k P(e_j) &amp; \iff \\         &amp; P(E) = \sum_{j = 1}^k p &amp; \iff     \end{aligned}</span>     è ora, dato il risultato precedente <span class="math-span">\( p = \frac{1}{n}\)</span>, è possibile ottenere     <span class="math-block">\begin{aligned}         &amp; P(E) = \sum_{j = 1}^k \frac{1}{n} &amp; \iff \\         &amp; P(E) = k \cdot \frac{1}{n} = \frac{k}{n} &amp;     \end{aligned}</span>     che è equivalente alla definizione classica di probabilità, in quanto <span class="math-span">\( n\)</span> è il numero di esiti totali (ovvero gli esiti di <span class="math-span">\( S\)</span>), mentre <span class="math-span">\( k\)</span> è il numero di esiti dell'evento <span class="math-span">\( E\)</span>. </div></div><div class="myexample environment" id="example3"><h2 class="environment-title">Esempio - Probabilità di estrazione di una chiave al <span class="math-span">\( k\)</span>-esimo tentativo (senza reinserimento)</h2><div class="environment-body collapsed">     Date <span class="math-span">\( n\)</span> chiavi in una scatola di cui una sola apre la porta.      Nel caso si provassero le chiavi una alla volta (scegliendole casualmente) senza reinserirle, qual è la probabilità di aprire la porta in <span class="math-span">\( k\)</span> tentativi (con <span class="math-span">\( 1 \leq k \leq n\)</span>)?     <br/>     Andando per casi, consideriamo l'evento     <span class="math-block">\[         E_k = \{ \text{peschi la chiave corretta al} \ k \text{-esimo tentativo} \}       \]</span>     Consideriamo quindi:     <ul class="list-container"><li class="list-item">il caso <span class="math-span">\( E_1\)</span>, allora si ha che         <span class="math-block">\[             P(E_1) = \frac{n^\circ \ \text{esiti favorevoli}}{n^\circ \ \text{esiti totali}} = \frac{1}{n}           \]</span>         </li><li class="list-item">il caso <span class="math-span">\( E_2\)</span>, comporta che:         <ul class="list-container"><li class="list-item">gli esiti favorevoli a questo evento (ovvero di pescare la chiave al secondo tentativo) sono <span class="math-span">\( (n - 1) \cdot 1\)</span> (in quanto si considera per il primo tentativo la possibilità di non pescarla (ovvero <span class="math-span">\( n - 1\)</span>), e per il secondo tentativo il valore <span class="math-span">\( 1\)</span>).              </li><li class="list-item">gli esiti totali saranno invece dati da <span class="math-span">\( n \cdot (n - 1)\)</span> in quanto non si reinserisce la chiave.          </li></ul>         La probabilità sarà quindi data da         <span class="math-block">\[             P(E_2) = \frac{n^\circ \ \text{esiti favorevoli}}{n^\circ \ \text{esiti totali}} = \frac{(n - 1) \cdot 1}{n \cdot (n - 1)} = \frac{1}{n}           \]</span>     </li></ul>     Generalizzando al caso <span class="math-span">\( k\)</span>     <span class="math-block">\[         P(E_k) = \frac{(n - 1) \cdot \ldots \cdot (n - (k - 1)) \cdot 1}{n \cdot (n - 1) \cdot \ldots \cdot (n - (k - 1))} = \frac{1}{n}       \]</span>      si ha quindi che la probabilità di <span class="math-span">\( P(E_k)\)</span> è <span class="math-span">\( \frac{1}{n}\)</span>. </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="myexample environment" id="example4"><h2 class="environment-title">Esempio - Probabilità di estrazione di una chiave al <span class="math-span">\( k\)</span>-esimo tentativo (con reinserimento)</h2><div class="environment-body collapsed">     Date <span class="math-span">\( n\)</span> chiavi in una scatola di cui una sola apre la porta.      Nel caso si provassero le chiavi una alla volta (scegliendole casualmente) reinserendole, qual è la probabilità di aprire la porta in <span class="math-span">\( k\)</span> tentativi (con <span class="math-span">\( k \geq 1\)</span>)?     <br/>     Andando per casi, consideriamo l'evento     <span class="math-block">\[         E_k = \{ \text{peschi la chiave corretta al} \ k \text{-esimo tentativo} \}       \]</span>     Consideriamo quindi:     <ul class="list-container"><li class="list-item">il caso <span class="math-span">\( E_1\)</span>, allora si ha che         <span class="math-block">\[             P(E_1) = \frac{n^\circ \ \text{esiti favorevoli}}{n^\circ \ \text{esiti totali}} = \frac{1}{n}           \]</span>         </li><li class="list-item">il caso <span class="math-span">\( E_2\)</span>, comporta che:         <ul class="list-container"><li class="list-item">gli esiti favorevoli a questo evento (ovvero di pescare la chiave al secondo tentativo) sono <span class="math-span">\( (n - 1) \cdot 1\)</span> (in quanto si considera per il primo tentativo la possibilità di non pescarla (ovvero <span class="math-span">\( n - 1\)</span>), e per il secondo tentativo il valore <span class="math-span">\( 1\)</span>).              </li><li class="list-item">gli esiti totali saranno invece dati da <span class="math-span">\( n \cdot n\)</span> in quanto non si scarta alcuna chiave.         </li></ul>         La probabilità sarà quindi data da         <span class="math-block">\[             P(E_2) = \frac{n^\circ \ \text{esiti favorevoli}}{n^\circ \ \text{esiti totali}} = \frac{(n - 1) \cdot 1}{n \cdot n} = \frac{n - 1}{n^2}           \]</span>     </li></ul>     Generalizzando al caso <span class="math-span">\( k\)</span>, si ha che ad ogni tentativo si hanno <span class="math-span">\( n - 1\)</span> possibilità di non pescare la chiave corretta ad eccezione dell'ultimo tentativo, in cui si ha un solo esito favorevole e quindi     <span class="math-block">\[         P(E_k) = \frac{(n - 1)^{k - 1} \cdot 1}{n^k}       \]</span>      si ha quindi che la probabilità di <span class="math-span">\( P(E_k)\)</span> è <span class="math-span">\( \frac{(n - 1)^{k - 1}}{n^k}\)</span>. </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="myexample environment" id="example5"><h2 class="environment-title">Esempio - Probabilità di sorteggio</h2><div class="environment-body collapsed">     Considerando un gruppo di sei uomini e nove donne, qual è la probabilità che sorteggiando cinque persone il gruppo sia formato da tre uomini e due donne?     <br/>     Si ha quindi l'evento     <span class="math-block">\[         E = \{ \text{sono estratti} \ 3 \ \text{uomini e} \ 2 \ \text{donne} \}       \]</span>     e per trovare <span class="math-span">\( P(E)\)</span> è necessario calcolare:     <ul class="list-container"><li class="list-item">il numero di esiti favorevoli, considerabile come le combinazioni di tre uomini su sei e di due donne su nove, ovvero         <span class="math-block">\[             C_{6,3} \cdot C_{9, 2} =  \frac{6!}{(6 - 3!) \cdot 3!} \cdot \frac{9!}{(9 - 2!) \cdot 2!} = \frac{5 \cdot 4 \cdot 9 \cdot 8}{2}         \]</span>                  </li><li class="list-item">il numero di esiti totali, considerabile come tutte le possibili combinazioni di cinque oggetti su quindici, ovvero         <span class="math-block">\[             C_{15, 5} = \frac{D_{15, 5}}{P_5} = \frac{15!}{(15 - 5)!} \cdot \frac{1}{5!} = \frac{15!}{10! \cdot 5!}           \]</span>     </li></ul>     Si ha quindi che <span class="math-span">\( P(E)\)</span> è uguale a     <span class="math-block">\[         P(E) = \frac{5 \cdot 4 \cdot 9 \cdot 8}{2} \cdot \frac{10! \cdot 5!}{15!} \approxeq 0.24     \]</span> </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="myexample environment" id="example6"><h2 class="environment-title">Esempio - Probabilità di ottenere almeno una testa sul lancio di due monete</h2><div class="environment-body collapsed">     Considerando di lanciare due monete regolari, qual è la probabilità che almeno una delle due sia testa?     <br/>     Considerando quindi l'evento      <span class="math-block">\[         E = \{ \text{una delle due monete vale testa} \}       \]</span>     si ha che per trovare <span class="math-span">\( P(E)\)</span> è sufficiente considerare l'esito negativo "<i>entrambe le monete valgono croce</i>" la cui probabilità è <span class="math-span">\( \frac{1}{4}\)</span> e calcolare la probabilità dell'evento complementare, ovvero     <span class="math-block">\[         P(E) = 1 - \frac{1}{4} = \frac{3}{4}       \]</span> </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="definition environment" id="def1-16"><h2 class="environment-title">Definizione - Probabilità dell'unione di tre eventi</h2><div class="environment-body">     Dato uno spazio campione <span class="math-span">\( S\)</span> e tre eventi <span class="math-span">\( E, F, G \subseteq S\)</span>, si ha che     <span class="math-block">\[         \begin{array}{cclc}             P(E \cup F \cup G) &amp; = &amp; P(E) + P(F) + P(G) &amp; + \\              &amp; - &amp; P(E \cap F) - P(E \cap G) - P(F \cap G) &amp; + \\             &amp; + &amp; P(E \cap F \cap G) &amp;         \end{array}     \]</span>  </div></div><div class="definition environment" id="def1-17"><h2 class="environment-title">Definizione - Eventi indipendenti</h2><div class="environment-body">     Dato uno spazio campione <span class="math-span">\( S\)</span> e due eventi <span class="math-span">\( E, F \subset S\)</span>, essi si dicono indipendenti se      <span class="math-block">\[         P(E \cap F) = P(E) \cdot P(F)       \]</span>     Nel caso l'uguaglianza non fosse rispettata, ovvero      <span class="math-block">\[         P(E \cap F) \neq P(E) \cdot P(F)     \]</span>     i due eventi si dicono <strong>dipendenti</strong>.     <h3 class="inner-title"><span class="math-span">\( n\)</span> eventi indipendenti</h3>     Considerando <span class="math-span">\( n\)</span> eventi <span class="math-span">\( E_1, \ldots, E_n \subset S\)</span>, essi si dicono indipendenti se      <span class="math-block">\begin{aligned}        &amp; P\left( \bigcap_{k = 1}^n E_k \right) = \prod_{k = 1}^{n} P(E_k) &amp; \\        &amp; P\left( \bigcap_{k = 1}^{n - 1} E_k \right) = \prod_{k = 1}^{n - 1} P(E_k) &amp; \\        &amp; \vdots &amp; \\        &amp; P\left( \bigcap_{k = 1}^{2} E_k \right) = \prod_{k = 1}^{2} P(E_k) &amp;      \end{aligned}</span>     ovvero che l'intersezione di qualsiasi evento (o più), sia uguale al prodotto delle probabilità.     <div class="mynote environment"><h3 class="environment-title">Nota bene - Caso <span class="math-span">\( n = 3\)</span></h3><div class="environment-body">         Consideriamo di <span class="math-span">\( 3\)</span> eventi <span class="math-span">\( E, F, G \subset S\)</span>, si ha che tali eventi sono indipendenti se         <span class="math-block">\[             \begin{array}{lcl}                 P(E \cap F \cap G) &amp; = &amp; P(E) \cdot P(F) \cdot P(G) \\                 P(E \cap F) &amp; = &amp; P(E) \cdot P(F) \\                 P(E \cap G) &amp; = &amp; P(E) \cdot P(G) \\                 P(F \cap G) &amp; = &amp; P(F) \cdot P(G)             \end{array}             \]</span>     </div></div> </div></div><div class="definition environment" id="def1-18"><h2 class="environment-title">Definizione - Probabilità condizionata</h2><div class="environment-body">     Dato uno spazio campione <span class="math-span">\( S\)</span> e due eventi <span class="math-span">\( E, F \subseteq S\)</span> con <span class="math-span">\( P(F) \neq 0\)</span>, si dice <strong>probabilità <span class="math-span">\( E\)</span> condizionata da <span class="math-span">\( F\)</span></strong>     <span class="math-block">\[         P(E \mid F) = \frac{P(E \cap F)}{P(F)}       \]</span>     e si indica la probabilità di <span class="math-span">\( E\)</span> ipotizzando che <span class="math-span">\( F\)</span> si sia verificato.   </div></div><div class="myexample environment" id="example7"><h2 class="environment-title">Esempio - Probabilità condizionata</h2><div class="environment-body collapsed">     Consideriamo il lancio di un dado cubico equilibrato e gli eventi     <span class="math-block">\[         \begin{array}{ccl}             E &amp; = &amp; \text{"Uscita di un numero pari"} \\             F &amp; = &amp; \text{"Uscita di un numero minore di $6$"}         \end{array}         \]</span>     calcolare <span class="math-span">\( P(E \mid F)\)</span>, ovvero la probabilità che esca un numero pari dato il fatto che è uscito un numero minore di <span class="math-span">\( 6\)</span>.     <br/>     In questo caso, considerando la formula di probabilità condizionata     <span class="math-block">\[         P(E \mid F) = \frac{P(E \cap F)}{P(F)}     \]</span>     è possibile calcolare     <ul class="list-container"><li class="list-item"><span class="math-span">\( P(E \cap F)\)</span>, ovvero         <span class="math-block">\[             P(E \cap F) = \frac{\text{numeri pari e minori di $6$}}{\text{numeri totali}} = \frac{\left| \{ 2, 4 \} \right|}{\left| \{ 1, 2, 3, 4, 5, 6 \} \right|} = \frac{2}{6} = \frac{1}{3}         \]</span>         </li><li class="list-item"><span class="math-span">\( P(F)\)</span>, ovvero         <span class="math-block">\[             P(F) = \frac{\text{numeri minori di $6$}}{\text{numeri totali}} = \frac{\left| \{ 1, 2, 3, 4, 5 \} \right|}{\left| \{ 1, 2, 3, 4, 5, 6 \} \right|} = \frac{5}{6}           \]</span>     </li></ul>     da cui     <span class="math-block">\[         P(E \mid F) = \frac{\frac{1}{3}}{\frac{5}{6}} = \frac{2}{5}     \]</span>     <div class="mynote environment"><h3 class="environment-title">Nota bene - In altre parole</h3><div class="environment-body">         Praticamente, quando si calcola la probabilità condizionata, non si fa altro che ridurre il numero di esiti totali da cui estrarre (nel caso precedente non si è fatto altro che diminuire da <span class="math-span">\( 6\)</span> (esiti di <span class="math-span">\( S\)</span>) a <span class="math-span">\( 5\)</span> (esiti di <span class="math-span">\( F\)</span>)).     </div></div> </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="definition environment" id="def1-19"><h2 class="environment-title">Definizione - Probabilità condizionata nel caso di eventi indipendenti</h2><div class="environment-body">     Considerando uno spazio campione <span class="math-span">\( S\)</span> e due eventi indipendenti <span class="math-span">\( E, F \subset S\)</span>, si ha che (ipotizzando <span class="math-span">\( P(F) \neq 0\)</span>)     <span class="math-block">\[         P(E \mid F) = \frac{P(E \cap F)}{P(F)} = \frac{P(E) \cdot P(F)}{P(F)} = P(E)     \]</span>     e che (ipotizzando <span class="math-span">\( P(E) \neq 0\)</span>)     <span class="math-block">\[         P(F \mid E) = \frac{P(F \cap E)}{P(E)} = \frac{P(F) \cdot P(E)}{P(E)} = P(F)     \]</span>  </div></div><div class="definition environment" id="def1-20"><h2 class="environment-title">Definizione - Probabilità dell'intersezione di eventi dipendenti</h2><div class="environment-body">     Considerando uno spazio campione <span class="math-span">\( S\)</span> e due eventi dipendenti <span class="math-span">\( E, F \subset S\)</span>, si ha che     <span class="math-block">\[         P(E \cap F) = P(E \mid F) \cdot P(F) = P(F \mid E) \cdot P(E)         \]</span> </div></div><div class="definition environment" id="def1-21"><h2 class="environment-title">Definizione - Partizione dello spazio campione</h2><div class="environment-body">     Dato uno spazio campione <span class="math-span">\( S\)</span>, si dice <strong>partizione di <span class="math-span">\( S\)</span></strong> l'<strong>insieme degli eventi</strong>     <span class="math-block">\[         \{ H_1, \ldots, H_n \} \qquad \text{con} \ n \in \mathbb{N}     \]</span>     tali che     <ul class="list-container"><li class="list-item">sono <strong>disgiunti</strong>, ovvero <span class="math-span">\( H_i \cap H_j = \varnothing\)</span> se <span class="math-span">\( i \neq j\)</span>;         </li><li class="list-item">l'<strong>unione degli eventi è l'intero spazio campione</strong>, ovvero <span class="math-span">\( \displaystyle \bigcup_{k = 1}^n H_k = S\)</span>.     </li></ul>     In questo caso, si ha che tali eventi sono detti <strong>ipotesi</strong>. </div></div><div class="demonstration environment" id="dem1-7"><h2 class="environment-title">Dimostrazione - Teorema delle probabilità totali</h2><div class="environment-body">     Dato il teorema     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato uno spazio campione <span class="math-span">\( S\)</span>, un evento <span class="math-span">\( E \subseteq S\)</span> e una partizione di <span class="math-span">\( S\)</span> <span class="math-span">\( \{ H_1, \ldots, H_n \}\)</span>, allora si ha che         <span class="math-block">\[             P(E) =  \sum_{k = 1}^{n} P(E \mid H_k) \cdot P(H_k)         \]</span>     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questo teorema consideriamo che lo spazio campione è <strong>risultato dell'unione delle diverse ipotesi</strong>.         <br/>          Ipotizzando un evento <span class="math-span">\( E\)</span>, si ha che tale evento comprende esiti appartenenti a diverse ipotesi, ovvero         <span class="math-block">\begin{aligned}             &amp; E = (E \cap H_1) \cup (E \cap H_2) \cup \ldots \cup (E \cap H_n) &amp; \iff         \end{aligned}</span>         Dato che le ipotesi sono disgiunte (<span class="math-span">\( H_i \cap H_j = \varnothing\)</span> se <span class="math-span">\( i \neq j\)</span>), si ha che vale anche         <span class="math-block">\begin{aligned}             &amp; (E \cap H_i) \cap (E \cap H_j) = \varnothing \qquad \text{se} \ i \neq j &amp; \iff                     \end{aligned}</span>         si ha quindi (dato che sono insiemi disgiunti) che         <span class="math-block">\begin{aligned}             &amp; P(E) = P((E \cap H_1) \cup (E \cap H_2) \cup \ldots \cup (E \cap H_n)) &amp; \iff         \end{aligned}</span>         e per il terzo assioma di Kolmogorov, si ha che         <span class="math-block">\begin{aligned}             &amp; P(E) = \sum_{k = 1}^n P(E \cap H_k) &amp; \iff          \end{aligned}</span>         Ora, considerando la formula della probabilità dell'intersezione di eventi dipendenti, si ha che         <span class="math-block">\begin{aligned}             &amp; P(E) = \sum_{k = 1}^n P(E \mid H_k) \cdot P(H_k) &amp;         \end{aligned}</span>         che è esattamente la formula di probabilità totali.     </div></div> </div></div><div class="myexample environment" id="example8"><h2 class="environment-title">Esempio - Teorema delle probabilità totali - Assicurazioni</h2><div class="environment-body collapsed">     Una compagnia di assicurazioni prevede tre categorie di clienti per l'RCA:     <ul class="list-container"><li class="list-item">i clienti a basso rischio (con una probabilità di incidente annuale pari a <span class="math-span">\( 0.05\)</span>);         </li><li class="list-item">i clienti a medio rischio (con una probabilità di incidente annuale pari a <span class="math-span">\( 0.15\)</span>);         </li><li class="list-item">i clienti a alto rischio (con una probabilità di incidente annuale pari a <span class="math-span">\( 0.30\)</span>).     </li></ul>     Dalle ultime statistiche, si sa che     <ul class="list-container"><li class="list-item">il <span class="math-span">\( 20\%\)</span> è a basso rischio;         </li><li class="list-item">il <span class="math-span">\( 50\%\)</span> è a medio rischio;         </li><li class="list-item">il <span class="math-span">\( 30\%\)</span> è ad alto rischio.     </li></ul>     Qual è la probabilità che un nuovo cliente non abbia incidenti il primo anno (ovvero una generica persona non classificata)?     <br/>     Per risolvere tale problema, consideriamo una partizione <span class="math-span">\( \{ H_1, H_2, H_3 \}\)</span> dello spazio campione dei clienti, ovvero     <ul class="list-container"><li class="list-item"><span class="math-span">\( H_1 = \)</span> "clienti a basso rischio" e si ha che <span class="math-span">\( P(H_1) = 0.2\)</span>;         </li><li class="list-item"><span class="math-span">\( H_2 = \)</span> "clienti a medio rischio" e si ha che <span class="math-span">\( P(H_2) = 0.5\)</span>;         </li><li class="list-item"><span class="math-span">\( H_3 = \)</span> "clienti ad alto rischio" e si ha che <span class="math-span">\( P(H_3) = 0.3\)</span>;     </li></ul>     Si vuole sapere qual è la probabilità in generale che una persona non compia incidenti, ovvero     <span class="math-block">\[         N = \text{"Non fare incidenti in un anno"}       \]</span>     che è il complementare dell'evento     <span class="math-block">\[         X = \text{"Fare almeno un incidente in un anno"}       \]</span>     di cui conosciamo la probabilità condizionata, ovvero     <ul class="list-container"><li class="list-item">se si è clienti a basso rischio, la probabilità di fare un incidente è <span class="math-span">\( 0.05\)</span>, ovvero         <span class="math-block">\[             P(X \mid H_1) = 0.05         \]</span>         </li><li class="list-item">se si è clienti a medio rischio, la probabilità di fare un incidente è <span class="math-span">\( 0.15\)</span>, ovvero         <span class="math-block">\[             P(X \mid H_2) = 0.15         \]</span>         </li><li class="list-item">se si è clienti ad alto rischio, la probabilità di fare un incidente è <span class="math-span">\( 0.3\)</span>, ovvero         <span class="math-block">\[             P(X \mid H_3) = 0.3         \]</span>     </li></ul>     Grazie al teorema delle probabilità totali, è quindi possibile calcolare <span class="math-span">\( P(X)\)</span>, in quanto     <span class="math-block">\[         \begin{array}{cll}             P(X) &amp; = &amp; P(X \mid H_1) \cdot P(H_1) + P(X \mid H_2) \cdot P(H_2) + P(X \mid H_3) \cdot P(H_3)  \\             &amp; = &amp; 0.05 \cdot 0.2 + 0.15 \cdot 0.5 + 0.3 \cdot 0.2 \\             &amp; = &amp; 0.175         \end{array}     \]</span>     È ora semplice calcolare <span class="math-span">\( P(N)\)</span>, ovvero     <span class="math-block">\[         \begin{array}{cll}             P(N) &amp; = &amp; 1 - P(X) \\             &amp; = &amp; 1 - 0.175 = 0.825          \end{array}       \]</span> </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="myexample environment" id="example9"><h2 class="environment-title">Esempio - Teorema delle probabilità totali - Esami diagnostici e falsi positivi</h2><div class="environment-body collapsed">     Considerando un esame diagnostico efficace al <span class="math-span">\( 70\%\)</span> (ovvero che rileverà una patologia nel <span class="math-span">\( 70\%\)</span> dei malati). I falsi positivi (coloro che sono rilevati ma che non sono malati) sono il <span class="math-span">\( 2\%\)</span>.     Sapendo che l'incidenza della patologia nella popolazione è <span class="math-span">\( 0.5\%\)</span>, qual è la probabilità che un individuo scelto a caso risulti positivo al test?     <br/>     Per calcolare questa probabilità, consideriamo di partizionare la popolazione in     <ul class="list-container"><li class="list-item"><span class="math-span">\( H_1 = \)</span> "individuo malato", da cui <span class="math-span">\( P(H_1) = 0.005\)</span>;         </li><li class="list-item"><span class="math-span">\( H_2 = \)</span> "individuo sano", da cui <span class="math-span">\( P(H_2) = (1 - 0.005) = 0.995\)</span>;     </li></ul>     Considerando l'evento     <span class="math-block">\[         E = \text{"Il test è positivo"}       \]</span>     si ha che:     <ul class="list-container"><li class="list-item">se un individuo è malato, la probabilità che il test sia positivo è <span class="math-span">\( 0.7\)</span>, ovvero         <span class="math-block">\[             P(E \mid H_1) = 0.7           \]</span>         </li><li class="list-item">se un individuo è sano, la probabilità che il test sia positivo è <span class="math-span">\( 0.02\)</span>, ovvero         <span class="math-block">\[             P(E \mid H_2) = 0.02           \]</span>     </li></ul>     Grazie al teorema delle probabilità totali, è quindi possibile calcolare <span class="math-span">\( P(E)\)</span>, in quanto     <span class="math-block">\[         \begin{array}{cll}             P(E) &amp; = &amp; P(E \mid H_1) \cdot P(H_1) + P(E \mid H_2) \cdot P(H_2) \\             &amp; = &amp; 0.7 \cdot 0.005 + 0.02 \cdot 0.995 \\             &amp; = &amp; 0.0234         \end{array}     \]</span> </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="demonstration environment" id="dem1-8"><h2 class="environment-title">Dimostrazione - Relazione tra eventi disgiunti ed eventi indipendenti</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Considerando due eventi <span class="math-span">\( E, F \subset S\)</span> disgiunti (ovvero <span class="math-span">\( P(E \cap F) = \varnothing\)</span>), essi <strong>sono indipendenti</strong>, ovvero         <span class="math-block">\[             P(E \cap F) = P(E) \cdot P(F)         \]</span>         solo se <strong>almeno uno tra i due eventi ha probabilità nulla</strong>.     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione consideriamo la definizione di eventi disgiunti, ovvero che         <span class="math-block">\[             P(E \cap F) = \varnothing           \]</span>         da cui, sempre per definizione di probabilità, si ha che         <span class="math-block">\[             P(\varnothing) = 0             \]</span>         Si può quindi dedurre che         <span class="math-block">\[             P(E \cap F) = 0         \]</span>         Consideriamo ora la definizione di eventi indipendenti         <span class="math-block">\begin{aligned}             &amp; P(E \cap F) = P(E) \cdot P(F) &amp; \iff          \end{aligned}</span>         sostituendo il risultato ottenuto in precedenza, si ha che         <span class="math-block">\begin{aligned}             &amp; P(\varnothing) = P(E) \cdot P(F) &amp; \iff \\             &amp; 0 = P(E) \cdot P(F) &amp;         \end{aligned}</span>         da cui è possibile dedurre che tale relazione vale solamente se uno dei due eventi ha probabilità nulla.     </div></div> </div></div><div class="demonstration environment" id="dem1-9"><h2 class="environment-title">Dimostrazione - Teorema di Bayes</h2><div class="environment-body">     Dato il teorema     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato uno spazio campione <span class="math-span">\( S\)</span>, un evento <span class="math-span">\( E \subseteq S\)</span> (con <span class="math-span">\( P(E) \neq 0\)</span>) e una partizione di <span class="math-span">\( S\)</span> <span class="math-span">\( \{ H_1, \ldots, H_n \}\)</span>, allora si ha che         <span class="math-block">\[             P(H_j \mid E) = \frac{P(E \mid H_j) \cdot P(H_j)}{\sum_{k = 1}^n P(E \mid H_k) \cdot P(H_k)} \qquad \text{con} \ j \in \{ 1, \ldots, n\}         \]</span>         Per il teorema della probabilità totali, si ha che          <span class="math-block">\[             \sum_{k = 1}^n P(E \mid H_k) \cdot P(H_k) = P(E)         \]</span>         e quindi         <span class="math-block">\[             P(H_j \mid E) = \frac{P(E \mid H_j) \cdot P(H_j)}{P(E)} \qquad \text{con} \ j \in \{ 1, \ldots, n\}         \]</span>     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questo teorema, consideriamo la probabilità dell'intersezione tra <span class="math-span">\( E\)</span> e <span class="math-span">\( H_j\)</span> dalla definizione di probabilità condizionata         <span class="math-block">\[             P(E \cap H_j) =  P(E \mid H_j) \cdot P(H_j)         \]</span>         che è tuttavia uguale a         <span class="math-block">\[             P(E \cap H_j) =  P(H_j \mid E) \cdot P(E)         \]</span>         Uguagliando i termini si avrebbe che         <span class="math-block">\begin{aligned}             &amp; P(H_j \mid E) \cdot P(E) = P(E \mid H_j) \cdot P(H_j) &amp; \iff \\             &amp; P(H_j \mid E) = \frac{P(E \mid H_j) \cdot P(H_j)}{P(E)} &amp; \iff           \end{aligned}</span>         che per la formula delle probabilità totali         <span class="math-block">\[             P(H_j \mid E) = \frac{P(E \mid H_j) \cdot P(H_j)}{\sum_{k = 1}^n P(E \mid H_k) \cdot P(H_k)} \qquad \text{con} \ j \in \{ 1, \ldots, n\}         \]</span>     </div></div> </div></div><div class="myexample environment" id="example10"><h2 class="environment-title">Esempio - Teorema di Bayes - "Paradosso" delle scatole di Bertrand</h2><div class="environment-body collapsed">     Considerando tre scatole esternamente uguali così formate:     <ul class="list-container"><li class="list-item">la prima scatola contiene due monete d'oro;         </li><li class="list-item">la seconda scatola contiene una moneta d'oro e una moneta d'argento;         </li><li class="list-item">la terza scatola contiene due monete d'argente.     </li></ul>     Estraendo una moneta d'oro da una scatola a caso, qual è la probabilità di avere scelto la scatola con due monete d'oro?     <br/>     Consideriamo l'evento di scelta di una certa scatola, si avrà che è una partizione per lo spazio campione, in particolare     <span class="math-block">\[         H_i = \text{"Scelta della scatola $i$"} \qquad \text{con} \ i = 1,2,3     \]</span>     Si avrà che <span class="math-span">\( P(H_i) = \frac{1}{3}\)</span>.     <br/>     Consideriamo ora l'evento     <span class="math-block">\[         O = \text{"Estrazione di una moneta d'oro"}     \]</span>     Si ha che, per il teorema di Bayes     <span class="math-block">\[         P(H_1 \mid O) = \frac{P(O \mid H_1) \cdot P(H_1)}{P(O)}     \]</span>     e dato che     <ul class="list-container"><li class="list-item"><span class="math-span">\( P(O \mid H_1) = 1\)</span>, in quanto si possono pescare solo monete oro dalla scatola <span class="math-span">\( 1\)</span>;         </li><li class="list-item"><span class="math-span">\( P(H_1) = \frac{1}{3}\)</span>, in quanto si sceglie la scatola casualmente;         </li><li class="list-item"><span class="math-span">\( P(O) = \frac{1}{2}\)</span>, in quanto sono presenti <span class="math-span">\( 3\)</span> monete d'oro su <span class="math-span">\( 6\)</span>.     </li></ul>     si ha che     <span class="math-block">\[         P(H_1 \mid O) = \frac{1 \cdot \frac{1}{3}}{\frac{1}{2}} = \frac{2}{3}     \]</span> </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="definition environment" id="def1-22"><h2 class="environment-title">Definizione - Problema della rovina del giocatore</h2><div class="environment-body">     Considerando     <ul class="list-container"><li class="list-item">due giocatori <span class="math-span">\( A\)</span> e <span class="math-span">\( B\)</span>;         </li><li class="list-item">e <span class="math-span">\( n\)</span> monete distribuite dandone <span class="math-span">\( j\)</span> ad <span class="math-span">\( A\)</span> (con <span class="math-span">\( 0 \lt j \lt n\)</span>)  e <span class="math-span">\( n - j\)</span> a <span class="math-span">\( B\)</span>.     </li></ul>     Al lancio di una moneta, nel caso esca testa il giocatore <span class="math-span">\( B\)</span> cede ad <span class="math-span">\( A\)</span> una moneta, altrimenti sarà il giocatore <span class="math-span">\( A\)</span> a cederla.     <br/>     Si ripete tale procedimento fino a che un giocatore non termina le monete: il vincitore è colui che rimane con le <span class="math-span">\( n\)</span> monete.     <strong>Qual è la probabilità della vittoria di <span class="math-span">\( A\)</span>?</strong>     <h3 class="inner-title">Modello del problema e strategia risolutiva</h3>     Per risolvere questo problema, è evidente che è impossibile considerare ogni possibile caso, in quanto ipoteticamente si potrebbe raggiungere una situazione di stallo che proseguirebbe per un numero infinito di turni.      Per questo motivo, consideriamo     <ul class="list-container"><li class="list-item">con <span class="math-span">\( V\)</span> l'evento         <span class="math-block">\[             V = \text{”A vince"}           \]</span>         </li><li class="list-item">con <span class="math-span">\( P_k\)</span> (con <span class="math-span">\( k \in \{ 0, \ldots, n \}\)</span>), la probabilità di vittoria di <span class="math-span">\( A\)</span> con <span class="math-span">\( k\)</span> monete.     </li></ul>     Consideriamo innanzitutto i due casi limite, ovvero     <ul class="list-container"><li class="list-item">il caso in cui <span class="math-span">\( A\)</span> possegga <span class="math-span">\( 0\)</span> monete, in cui è certa la sconfitta. Ciò implica         <span class="math-block">\[             P_0 = 0         \]</span>         </li><li class="list-item">il caso in cui <span class="math-span">\( A\)</span> possegga tutte le <span class="math-span">\( n\)</span> monete, in cui è certa la vittoria. Ciò implica         <span class="math-block">\[             P_n = 1           \]</span>     </li></ul>     e concentriamoci sul primo lancio (che deve avvenire, altrimenti il gioco sarebbe terminato) in cui si possono verificare solo due casi:     <ul class="list-container"><li class="list-item">esce testa (evento <span class="math-span">\( T\)</span>), quindi <span class="math-span">\( A\)</span> ha una moneta in più (ovvero avrà probabilità di vittoria <span class="math-span">\( P_{k + 1}\)</span>);         </li><li class="list-item">esce croce (evento <span class="math-span">\( C\)</span>), quindi <span class="math-span">\( A\)</span> ha una moneta in meno (ovvero avrà probabilità di vittoria <span class="math-span">\( P_{k - 1}\)</span>).     </li></ul>     Si ha quindi che con <span class="math-span">\( k\)</span> monete, si avrà probabilità di vittoria <span class="math-span">\( P_k\)</span>: è quindi possibile scrivere la probabilità di vittoria (secondo la formula delle probabilità totali) come      <span class="math-block">\[         P(V) = P(V \mid T) \cdot P(T) + P(V \mid C) \cdot P(C)       \]</span>     che equivale a scrivere, rinominando <span class="math-span">\( P(T) = t\)</span> e <span class="math-span">\( P(C) = c\)</span>, che     <span class="math-block">\begin{aligned}         &amp; P_k = P_{k + 1} \cdot t + P_{k - 1} \cdot c &amp; \iff     \end{aligned}</span>     che è una relazione ricorsiva.     <br/>     Dato che conosciamo già il valore di <span class="math-span">\( P_0\)</span> (uguale a <span class="math-span">\( 0\)</span>), al fine di trovare ogni valore occorre calcolare il valore di <span class="math-span">\( P_1\)</span>.      <br/>     Si ha ciò perchè, dato che è una relazione ricorsiva, si ha che     <span class="math-block">\begin{aligned}         &amp; P_k = P_{k + 1} \cdot t + P_{k - 1} \cdot c &amp; \iff \\         &amp; - P_{k + 1} \cdot t = - P_k + P_{k - 1} \cdot c &amp; \iff \\         &amp; P_{k + 1} = \frac{P_k + P_{k - 1} \cdot c}{t} &amp;      \end{aligned}</span>     ovvero è possibile calcolare <span class="math-span">\( P_{k + 1}\)</span> dai due valori precedenti.     <h3 class="inner-title">Determinare il valore di <span class="math-span">\( P_1\)</span></h3>     Per determinare il valore di <span class="math-span">\( P_1\)</span>, consideriamo che per ipotesi si ha <span class="math-span">\( (t + c) = 1\)</span>, allora è possibile riscrivere la relazione ottenuta in precedenza come     <span class="math-block">\begin{aligned}         &amp; P_k = P_{k + 1} \cdot t + P_{k - 1} \cdot c &amp; \iff \\          &amp; (t + c) \cdot P_k = P_{k + 1} \cdot t + P_{k - 1} \cdot c &amp; \iff \\         &amp; t \cdot P_k + c \cdot P_k = P_{k + 1} \cdot t + P_{k - 1} \cdot c &amp; \iff \\         &amp; c \cdot P_k - c \cdot P_{k - 1}  = t \cdot P_{k + 1} - t \cdot P_k &amp; \iff \\         &amp; c \cdot (P_k - P_{k - 1}) = t \cdot (P_{k + 1} - P_k ) &amp; \iff \\         &amp; t \cdot (P_{k + 1} - P_k ) = c \cdot (P_k - P_{k - 1})  &amp; \iff \\         &amp; P_{k + 1} - P_k = \frac{c}{t} \cdot (P_k - P_{k - 1})  &amp;     \end{aligned}</span>     Considerando questa relazione, è ora possibile valutare il caso <span class="math-span">\( k = 1\)</span>     <span class="math-block">\begin{aligned}         &amp; \begin{array}{lcl}             P_2 - P_1 &amp; = &amp; \frac{c}{t} \cdot (P_1 - P_0) \\             &amp; = &amp; \frac{c}{t} \cdot P_1         \end{array}          &amp; k = 1        \end{aligned}</span>     e valutando i casi successivi è possibile sostituire ricorsivamente i valori     <span class="math-block">\begin{aligned}         &amp; P_3 - P_2 = \frac{c}{t} \cdot \overbrace{(P_2 - P_1)}^{\frac{c}{t} \cdot P_1}  &amp; k = 2 \\         &amp; P_4 - P_3 = \frac{c}{t} \cdot \overbrace{(P_3 - P_2)}^{\left(\frac{c}{t}\right)^2 \cdot P_1}  &amp; k = 3 \\         &amp; \vdots &amp; \\         &amp; P_n - P_{n - 1} = \underbrace{\frac{c}{t} \cdot \overbrace{(P_{n - 1} - P_{n - 2})}^{\left(\frac{c}{t}\right)^{n - 2} \cdot P_1}}_{\left( \frac{c}{n} \right)^{n - 1} \cdot P_1}  &amp; k = n - 1      \end{aligned}</span>     Sommando ora tutte queste relazioni (per ogni <span class="math-span">\( k \in \left\{ 1, \ldots, n - 1 \right\}\)</span>) si ottiene     <span class="math-block">\begin{aligned}         &amp; (P_2 - P_1) + \ldots + (P_n - P_{n - 1}) = \sum_{k = 1}^{n - 1} \left( \frac{c}{t} \right)^{k} \cdot P_1 &amp; \iff \\         &amp; P_n - P_1 = \sum_{k = 1}^{n - 1} \left( \frac{c}{t} \right)^{k} \cdot P_1 &amp;           \end{aligned}</span>     in quanto termini uguali si sottraggono.      <br/>     Ricordando che <span class="math-span">\( P_n = 1\)</span>, si ottiene     <span class="math-block">\begin{aligned}         &amp; 1 - P_1 = \sum_{k = 1}^{n - 1} \left( \frac{c}{t} \right)^{k} \cdot P_1 &amp; \iff \\         &amp; 1 = \sum_{k = 1}^{n - 1} \left( \frac{c}{t} \right)^{k} \cdot P_1 + P_1 &amp; \iff \\         &amp; P_1 = \sum_{k = 0}^{n - 1} \left( \frac{c}{t} \right)^{k} \cdot P_1 &amp; \iff \\         &amp; 1 = P_1 \cdot \sum_{k = 0}^{n - 1} \left( \frac{c}{t} \right)^{k}  &amp; \iff \\         &amp; \frac{1}{\sum_{k = 0}^{n - 1} \left( \frac{c}{t} \right)^{k}} = P_1 &amp; \iff \\         &amp; P_1 = \frac{1}{1 + \left( \frac{c}{t} \right)^1 + \ldots + \left( \frac{c}{t} \right)^{n - 1}}     \end{aligned}</span>     da cui è poi possibile ottenere ogni <span class="math-span">\( P_k\)</span>.     <h3 class="inner-title">Caso di una moneta equilibrata</h3>     Considerando quindi che la moneta sia equilibrata, ovvero <span class="math-span">\( c = t = \frac{1}{2}\)</span> è semplice calcolare <span class="math-span">\( P_1\)</span>     <span class="math-block">\[         P_1 = \underbrace{\frac{1}{1 + 1 + \ldots + 1}}_{\text{$n$ volte}} = \frac{1}{n}     \]</span>     ed un generico <span class="math-span">\( P_k\)</span>     <span class="math-block">\[         P_k = \frac{k}{n}     \]</span>     <h3 class="inner-title">Caso di una moneta non equilibrata</h3>     Considerando invece il caso in cui la moneta non sia equilibrata, ovvero <span class="math-span">\( c \neq t\)</span>, riconsideriamo la formula per calcolare <span class="math-span">\( P_1\)</span> e moltiplichiamo al numeratore e al denominatore per <span class="math-span">\( 1 - \frac{c}{t}\)</span>, ovvero     <span class="math-block">\begin{aligned}         &amp; P_1 = \frac{1}{1 + \left( \frac{c}{t} \right)^1 + \ldots + \left( \frac{c}{t} \right)^{n - 1}} &amp; \iff \\         &amp; P_1 = \frac{1}{1 + \left( \frac{c}{t} \right)^1 + \ldots + \left( \frac{c}{t} \right)^{n - 1}} \cdot \frac{1 - \frac{c}{t}}{1 - \frac{c}{t}} &amp; \iff      \end{aligned}</span>     ricordando che vale il prodotto notevole      <span class="math-block">\[         \left( 1 + \left( \frac{c}{t} \right)^1 + \ldots + \left( \frac{c}{t} \right)^{n - 1} \right) \cdot \left( 1 - \frac{c}{t} \right) = 1 - \left( \frac{c}{t} \right)^n     \]</span>     si ottiene      <span class="math-block">\begin{aligned}         &amp; P_1 = \frac{1 - \frac{c}{t}}{1 - \left( \frac{c}{t} \right)^n} &amp; \iff     \end{aligned}</span>     da cui è possibile dedurre     <span class="math-block">\[         P_k = \frac{1 - \left( \frac{c}{t} \right)^k}{1 - \left( \frac{c}{t} \right)^n}       \]</span> </div></div><div class="demonstration environment" id="dem1-10"><h2 class="environment-title">Dimostrazione - Indipendenza degli eventi complementari di eventi indipendenti</h2><div class="environment-body">     Dato il teorema     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Dato uno spazio campione <span class="math-span">\( S\)</span> e due eventi <span class="math-span">\( E, F \subset S\)</span> indipendenti, allora si ha che         <span class="math-block">\[             P(E^c \cap F^c) = P(E^c) \cdot P(F^c)          \]</span>         ovvero che gli eventi complementari di eventi indipendenti, sono anch'essi indipendenti.     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostare questo teorema consideriamo che per ipotesi di indipendenza si ha          <span class="math-block">\[             P(E \cap F) = P(E) \cdot P(F)           \]</span>         Consideriamo quindi la tesi         <span class="math-block">\begin{aligned}             &amp; P(E^c \cap F^c) = P(E^c) \cdot P(F^c) &amp; \iff                 \end{aligned}</span>         e che         <ul class="list-container"><li class="list-item"><span class="math-span">\( E^c \cap F^c = (E \cup F)^c\)</span>;             </li><li class="list-item">considerando un generico evento <span class="math-span">\( A\)</span> si ha che <span class="math-span">\( P(A^c) = 1 - P(A)\)</span>;         </li></ul>         allora         <span class="math-block">\begin{aligned}             &amp; P(E^c \cap F^c) = P(E^c) \cdot P(F^c) &amp; \iff \\             &amp; P\left((E \cup F)^c\right) = P(E^c) \cdot P(F^c) &amp; \iff \\             &amp; P\left( (E \cup F)^c \right) = \left( 1 - P(E) \right) \cdot \left( 1 - P(F) \right)&amp; \iff \\             &amp; 1 - P\left( E \cup F\right) = \left( 1 - P(E) \right) \cdot \left( 1 - P(F) \right)&amp; \iff \\             &amp; 1 - P\left( E \cup F\right) = 1 - P(E) - P(F) + P(E) \cdot P(F) &amp; \iff \\             &amp; P\left( E \cup F\right) = - 1 +  P(E) + P(F) - P(E) \cdot P(F) + 1 &amp; \iff \\             &amp; P\left( E \cup F \right) = P(E) + P(F) - P(E) \cdot P(F) &amp; \iff         \end{aligned}</span>         che è esattamente la definizione di probabilità dell'unione di due eventi, da cui          <span class="math-block">\begin{aligned}             &amp; P\left( (E \cup F)^c \right) = \left( 1 - P(E) \right) \cdot \left( 1 - P(F) \right)&amp; \iff \\             &amp; 1 - P\left( E \cup F\right) = \left( 1 - P(E) \right) \cdot \left( 1 - P(F) \right)&amp; \iff \\             &amp; 1 - P\left( E \cup F\right) = 1 - P(E) - P(F) + P(E) \cdot P(F) &amp; \iff \\             &amp; P\left( E \cup F\right) = - 1 +  P(E) + P(F) - P(E) \cdot P(F) + 1 &amp; \iff \\             &amp; P\left( E \cup F \right) = P\left( E \cup F \right) &amp;         \end{aligned}</span>         che dimostra il teorema.     </div></div> </div></div><div class="definition environment" id="def1-23"><h2 class="environment-title">Definizione - Problemi con dispositivi in serie e in parallelo</h2><div class="environment-body">     Due tipici problemi di probabilità discreta sono i <strong>problemi di funzionamento con dispositivi in serie ed in parallelo</strong>.     <h3 class="inner-title">Dispositivi in serie</h3>     Nel caso di <span class="math-span">\( n\)</span> dispositivi in serie     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/dispositivi-serie.png"/></div></div>     si ha che il sistema funziona se e solo se tutti i dispositivi funzionano, ovvero, considerando l'evento     <span class="math-block">\[         D_k = \text{"il $k$-esimo dispositivo funziona"}     \]</span>     si ha che il sistema funziona se si verifica l'evento     <span class="math-block">\[         D_1 \cap D_2 \cap \ldots \cap D_n         \]</span>     Si ha quindi che, considerando l'indipendenza dei dispositivi, la probabilità di funzionamento sarà data da     <span class="math-block">\[         \begin{array}{ccl}             P(\text{"Sistema funziona"}) &amp; = &amp; P(D_1) \cdot P(D_2) \cdot \ldots \cdot P(D_n) \\             &amp; = &amp; \prod_{j = 1}^{n} P(D_j) \\         \end{array}     \]</span>     <h3 class="inner-title">Dispositivi in parallelo</h3>     Nel caso si abbiano invece <span class="math-span">\( n\)</span> dispositivi in parallelo     <div class="image-environment"><div class="image-wrapper spaced-30"><img alt="Immagine" src="../resources/dispositivi-parallelo.png"/></div></div>     si ha che il sistema funziona anche se solo uno dei dispositivi funziona, ovvero se si verifica l'evento     <span class="math-block">\[         D_1 \cup D_2 \cup \ldots \cup D_n         \]</span>     Per calcolare la probabilità di funzionamento, è conveniente considerare l'evento complementare all'unione (ovvero il complementare dell'intersezione) e considerando l'indipendenza degli eventi, si ha che     <span class="math-block">\[         \begin{array}{ccl}             P(\text{"Sistema funziona"}) &amp; = &amp; P(D_1 \cup D_2 \cup \ldots \cap D_n) \\             &amp; = &amp; 1 - P((D_1 \cup D_2 \cup \ldots \cap D_n)^c) \\             &amp; = &amp; 1 - P(D_1^c \cap D_2^c \cap \ldots \cap D_n^c) \\             &amp; = &amp; 1 - \prod_{j = 1}^{n} P(D_j^c) \\             &amp; = &amp; 1 - \prod_{j = 1}^{n} (1 - P(D_j))         \end{array}     \]</span> </div></div>
            </article>
            <nav class="buttons-container content-width">
                <a class="navigation-button previous" href="calcolo-combinatorio.html" rel="nofollow"><span>Calcolo combinatorio</span></a>
                <a class="navigation-button next" href="../variabili-casuali/variabili-casuali-o-aleatorie.html" rel="nofollow"><span>Variabili casuali (o aleatorie)</span></a>
            </nav>
        </section>
        <div class="scroll-to-bottom-button" onclick="scroll_to_bottom()">
            <span class="material-symbols-outlined">
                keyboard_double_arrow_down
            </span>
        </div>
            <footer class="footer-wrapper">
                <div class="copyright-wrapper">
                    <span> &copy; Copyright 2024</span> /
                    <span>made by <a href="https://github.com/lorenzoarlo" rel="nofollow">lorenzoarlo</a></span>
                </div>
                /
                <div class="privacy-wrapper">
                    <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/" rel="nofollow">Pannello preferenze
                            cookie</a></span> /
                    <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/privacy-policy.html" rel="nofollow"
                            target="_blank">Privacy Policy</a></span>
                </div>
            </footer>
    </div>
</body>
</html>