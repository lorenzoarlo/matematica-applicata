<!DOCTYPE html>
<html lang="IT">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="stylesheet" href="../styles/style.css" />
    <link rel="stylesheet" href="../styles/index-style.css" />
    <link rel="stylesheet" href="../styles/content-style.css" />
    <link rel="icon" type="image/x-icon" href="../resources/favicon.ico">
    <meta name="application-name" content="Matematica applicata" />
    <meta name="apple-mobile-web-app-title" content="Matematica applicata" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="#E34234" />
    <link rel="apple-touch-icon" href="../resources/favicon.png" />
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-78NHLXDQD8"></script>
    <script src="../scripts/script.js"></script>
    <style>:root { --bg-clr: #E34234; --fg-clr: #262626; }</style>
    <meta name="theme-color" content="#E34234" />
    <meta name="keywords" content="matematica applicata" />
    <meta name="description" content="Il seguente sito contiene gli appunti e le definizioni del corso 'Matematica applicata'.">
    <meta name="robots" content="index">
    <script defer async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <title>Matematica applicata - Variabili casuali - Modelli di variabili casuali continue</title>
</head>
<body>
    <div class="container">
        <header class="header-wrapper">
            <div class="title-wrapper">
                <span class="title">
                    Matematica applicata
                </span>
                <span class="subtitle">
                    by lorenzoarlo
                </span>
            </div>
            <span class="page-title">
                Variabili casuali
            </span>
        </header>
        <aside class="sidebar">
            <h2 class="sidebar-title">Matematica applicata</h2>
            <div class="index-container">
                <ul class="parent-ul"><li class="section-li"><a href="../index.html">Indice</a></li><li class="section-li "><a href="../probabilità-discreta/calcolo-combinatorio.html">Probabilità discreta</a><ul><li class="subsection-li "><a href="../probabilità-discreta/calcolo-combinatorio.html">Calcolo combinatorio</a></li><li class="subsection-li "><a href="../probabilità-discreta/statistica.html">Statistica</a></li></ul></li><li class="section-li current">Variabili casuali<ul><li class="subsection-li "><a href="variabili-casuali-o-aleatorie.html">Variabili casuali (o aleatorie)</a></li><li class="subsection-li "><a href="coppia-di-variabili-casuali-discrete.html">Coppia di variabili casuali discrete</a></li><li class="subsection-li "><a href="coppia-di-variabili-casuali-congiuntamente-continue.html">Coppia di variabili casuali congiuntamente continue</a></li><li class="subsection-li "><a href="indipendenza-di-variabili-casuali.html">Indipendenza di variabili casuali</a></li><li class="subsection-li "><a href="valore-atteso.html">Valore atteso</a></li><li class="subsection-li "><a href="varianza.html">Varianza</a></li><li class="subsection-li "><a href="covarianza.html">Covarianza</a></li><li class="subsection-li "><a href="funzione-generatrice-di-momenti.html">Funzione generatrice di momenti</a></li><li class="subsection-li "><a href="modelli-di-variabili-casuali-discrete.html">Modelli di variabili casuali discrete</a></li><li class="subsection-li current">Modelli di variabili casuali continue<ul><li class="definition-li"><a href="#def2-35">Variabile casuale uniforme</a></li><li class="myexample-li"><a href="#example30">Utilizzo di una v. c. uniforme</a></li><li class="definition-li"><a href="#def2-36">Problemi sulla probabilità che un sistema in serie e parallelo funzioni fino ad un istante \( a\)</a></li><li class="definition-li"><a href="#def2-37">Coppia di variabili casuali uniformi e probabilità di appartenenza ad un sottoinsieme di \( \mathbb{R}^2\)</a></li><li class="definition-li"><a href="#def2-38">Variabile casuale esponenziale</a></li><li class="definition-li"><a href="#def2-39">Probabilità di funzionamento di sistemi in serie e parallelo fino ad un istante \( a\) utilizzando v. c. esponenziali</a></li><li class="demonstration-li"><a href="#dem2-11">Variabile casuale esponenziale moltiplicata per uno scalare</a></li><li class="demonstration-li"><a href="#dem2-12">Mancanza di memoria per variabili casuali esponenziali</a></li><li class="definition-li"><a href="#def2-40">Variabile casuale gaussiana (o normale)</a></li><li class="demonstration-li"><a href="#dem2-13">Trasformazione lineare di una v. c. gaussiana</a></li><li class="definition-li"><a href="#def2-41">Variabile casuale gaussiana standard</a></li><li class="definition-li"><a href="#def2-42">Utilizzare la funzione di ripartizione di una v. c. gaussiana standard per il calcolo della funzione di ripartizione di una qualsiasi v. c. gaussiana</a></li><li class="myexample-li"><a href="#example31">Utilizzo della funzione di ripartizione per v. c. gaussiane standard</a></li><li class="demonstration-li"><a href="#dem2-14">Proprietà di riproducibilità di una v. c. gaussiana</a></li><li class="definition-li"><a href="#def2-43">Valore critico di una v. c. gaussiana standard</a></li></ul></li><li class="subsection-li "><a href="funzioni-di-variabili-casuali-continue.html">Funzioni di variabili casuali continue</a></li><li class="subsection-li "><a href="processi-stocastici.html">Processi stocastici</a></li><li class="subsection-li "><a href="legge-dei-grandi-numeri.html">Legge dei grandi numeri</a></li><li class="subsection-li "><a href="teorema-del-limite-centrale.html">Teorema del limite centrale</a></li></ul></li><li class="section-li "><a href="../inferenza-statistica/concetti-introduttivi.html">Inferenza statistica</a><ul><li class="subsection-li "><a href="../inferenza-statistica/concetti-introduttivi.html">Concetti introduttivi</a></li><li class="subsection-li "><a href="../inferenza-statistica/intervalli-di-confidenza.html">Intervalli di confidenza</a></li><li class="subsection-li "><a href="../inferenza-statistica/regressione.html">Regressione</a></li></ul></li></ul>
            </div>
        </aside>
        <div class="sidebar-button" onclick="toggle_sidebar(this)" role="button" >
            keyboard_double_arrow_right
        </div>
        <section class="content-wrapper">
            <h1 class="section-title content-width">Modelli di variabili casuali continue</h1>
            <article class="content-container content-width">
                <div class="definition environment" id="def2-35"><h2 class="environment-title">Definizione - Variabile casuale uniforme</h2><div class="environment-body">     Una variabile casuale continua <span class="math-span">\( X\)</span> si definisce uniforme di parametri <span class="math-span">\( \alpha\)</span> e <span class="math-span">\( \beta\)</span> (<span class="math-span">\( X \sim U(\alpha, \beta)\)</span> con <span class="math-span">\( \alpha, \beta \in \mathbb{R}\)</span> e <span class="math-span">\( \alpha \lt \beta\)</span>) se, in un certo intervallo <span class="math-span">\( [\alpha, \beta]\)</span> essa assume lo stesso valore di probabilità <span class="math-span">\( k\)</span> e <span class="math-span">\( 0\)</span> altrove, ovvero si ha che la funzione di densità sarà uguale a     <span class="math-block">\[         f(x) = \left\{ \begin{array}{ll}             k &amp; \text{se} \ x \in [\alpha, \beta] \\             0 &amp; \text{altrove}         \end{array} \right.     \]</span>     Affinchè <span class="math-span">\( f\)</span> sia una funzione di densità valida, si ha che     <ul class="list-container"><li class="list-item"><span class="math-span">\( f(x) \geq 0\)</span> per ogni <span class="math-span">\( x \in \mathbb{R}\)</span>, e ciò implica che         <span class="math-block">\[             k \geq 0           \]</span>         </li><li class="list-item">considerando <span class="math-span">\( \mathbb{R}\)</span>, si ha che         <span class="math-block">\[             \int_{-\infty}^{+\infty} f(x) \ dx  = 1                      \]</span>         che implica         <span class="math-block">\begin{aligned}             &amp; \int_{-\infty}^{\alpha} 0 \ dx + \int_\alpha^\beta k \ dx + \int_\beta^{+\infty} 0 \ dx = 1 &amp; \iff \\             &amp; k \cdot (\beta - \alpha) = 1 &amp; \iff \\             &amp; k = \frac{1}{\beta - \alpha}         \end{aligned}</span>     </li></ul>     per cui si ha che      <span class="math-block">\[         f(x) = \left\{ \begin{array}{ll}             \frac{1}{\beta - \alpha} &amp; \text{se} \ x \in [\alpha, \beta] \\             0 &amp; \text{altrove}         \end{array} \right.     \]</span>     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/funzione-densita-vc-uniforme.png"/></div></div>     <span class="inner-title"><span class="math-span">\( P(X \in [c, d])\)</span>, con <span class="math-span">\( [c, d] \subseteq [\alpha, \beta]\)</span></span>     Considerando un intervallo <span class="math-span">\( [c, d]\)</span> sottoinsieme di <span class="math-span">\( [\alpha, \beta]\)</span>, si ha che la probabilità di <span class="math-span">\( X \in [c,d]\)</span> sarà uguale a     <span class="math-block">\[         \begin{array}{ccl}             P(X \in [c, d]) &amp; = &amp; \int_c^d f(x) \ dx \\             &amp; = &amp; \int_c^d \frac{1}{\beta - \alpha} \ dx \\             &amp; = &amp; \frac{1}{\beta - \alpha} \cdot (d - c) \\             &amp; = &amp; \frac{d - c}{\beta - \alpha} \\         \end{array}             \]</span>     ovvero si ha che è dato dal rapporto tra la lunghezza di <span class="math-span">\( [c,d]\)</span> e <span class="math-span">\( [\alpha, \beta]\)</span>.     <span class="inner-title">Valore atteso</span>     Il valore atteso di una v. c. uniforme  di parametri <span class="math-span">\( \alpha\)</span> e <span class="math-span">\( \beta\)</span> è uguale a     <span class="math-block">\[         \begin{array}{ccl}             E[X] &amp; = &amp; \int_{-\infty}^{+\infty} x \cdot f(x) \ dx \\             &amp; = &amp; \int_{\alpha}^{\beta} x \cdot \frac{1}{\beta - \alpha} \ dx \\             &amp; = &amp; \frac{1}{\beta - \alpha} \cdot \left[ \frac{x^2}{2} \right]^\beta_\alpha \\             &amp; = &amp; \frac{\beta^2 - \alpha^2}{2 \cdot (\beta - \alpha)} \\             &amp; = &amp; \frac{\beta + \alpha}{2}                     \end{array}     \]</span>      <span class="inner-title">Varianza</span>     La varianza di una v. c. uniforme di parametri <span class="math-span">\( \alpha\)</span> e <span class="math-span">\( \beta\)</span> è calcolabile come     <span class="math-block">\[         Var(X) = E\left[X^2\right] - \left( E[X] \right)^2       \]</span>     È necessario calcolare quindi <span class="math-span">\( E\left[X^2\right]\)</span> che è uguale a      <span class="math-block">\[         \begin{array}{ccl}             E\left[X^2\right] &amp; = &amp; \int_{-\infty}^{+\infty} x^2 \cdot f(x) \ dx \\             &amp; = &amp; \int_\alpha^\beta \frac{x^2}{\beta - \alpha} \ dx \\             &amp; = &amp; \frac{1}{\beta - \alpha} \cdot \left[ \frac{x^3}{3} \right]^\beta_\alpha \\             &amp; = &amp; \frac{1}{\beta - \alpha} \cdot \frac{\beta^3 - \alpha^3}{3} \\             &amp; = &amp; \frac{\beta^3 - \alpha^3}{3 \cdot (\beta - \alpha)} \\             &amp; = &amp; \frac{(\beta - \alpha) \cdot (\alpha^2 + \beta^2 + \alpha \cdot \beta)}{3 \cdot (\beta - \alpha)} \\             &amp; = &amp; \frac{\alpha^2 + \beta^2 + \alpha \cdot \beta}{3}         \end{array}         \]</span>     È ora possibile calcolare la varianza, ovvero      <span class="math-block">\[         \begin{array}{ccl}             Var(X) &amp; = &amp; E\left[X^2\right] - \left( E[X] \right)^2 \\             &amp; = &amp; \frac{\alpha^2 + \beta^2 + \alpha \cdot \beta}{3} - \left( \frac{\beta + \alpha}{2} \right)^2 \\             &amp; = &amp; \frac{\alpha^2 + \beta^2 + \alpha \cdot \beta}{3} - \frac{\beta^2 + \alpha^2 + 2 \cdot \alpha \cdot \beta}{4} \\             &amp; = &amp; \frac{\alpha^2 + \beta^2 - 2 \cdot \alpha \cdot \beta }{12} \\             &amp; = &amp; \frac{(\beta - \alpha)^2}{12}         \end{array}        \]</span>     <span class="inner-title">Funzione di ripartizione</span>     La funzione di ripartizione per una v. c. uniforme di parametri <span class="math-span">\( \alpha\)</span> e <span class="math-span">\( \beta\)</span> è calcolabile come     <span class="math-block">\[         \begin{array}{ccl}             F(a) &amp; = &amp; P(X \leq a) \\             &amp; = &amp; \int_{-\infty}^a f(x) \ dx  \\             &amp; = &amp;  \left\{                 \begin{array}{ll}                     \int_{-\infty}^a 0 \ dx &amp; \text{se} \ a \lt \alpha \\                     \int_{-\infty}^\alpha 0 \ dx + \int_{\alpha}^a \frac{1}{\beta - \alpha} \ dx &amp; \text{se} \ \alpha \leq a \leq \beta \\                     \int_{-\infty}^\alpha 0 \ dx + \int_{\alpha}^{\beta} \frac{1}{\beta - \alpha} \ dx + \int_{\beta}^{a} 0 \ dx &amp; \text{se} \ a \gt \beta                 \end{array}             \right. \\             &amp; = &amp;  \left\{                 \begin{array}{ll}                     0 &amp; \text{se} \ a \lt \alpha \\                     \frac{a - \alpha}{\beta - \alpha} \ dx &amp; \text{se} \ \alpha \leq a \leq \beta \\                     1 &amp; \text{se} \ a \gt \beta                 \end{array}             \right.         \end{array}     \]</span>     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/funzione-ripartizione-vc-uniforme.png"/></div></div> </div></div><div class="myexample environment" id="example30"><h2 class="environment-title">Esempio - Utilizzo di una v. c. uniforme</h2><div class="environment-body collapsed">     Considerando un autobus che passa in un istante casuale tra le <span class="mono">6:50 AM</span> e le <span class="mono">7:20 AM</span>, calcolare     <ul class="list-container"><li class="list-item">la probabilità che l'autobus passi dalle <span class="mono">7:00 AM</span> in poi;         </li><li class="list-item">la probabilità che l'autobus passi dalle <span class="mono">7:05 AM</span> in poi;         </li><li class="list-item">la probabilità che l'autobus passi alle <span class="mono">7:00 AM</span>.     </li></ul>     <span class="inner-title">Modello</span>     Per risolvere questo problema, è possibile considerare la v. c. uniforme <span class="math-span">\( X\)</span> di parametri <span class="math-span">\( 0\)</span> e <span class="math-span">\( 30\)</span> che indica i minuti passati all'arrivo del bus dalle <span class="mono">6:50 AM</span>, ovvero     <span class="math-block">\[         X \sim U(0, 30)       \]</span>     in quanto l'intervallo tra le <span class="mono">6:50 AM</span> e le <span class="mono">7:20 AM</span> ha questa durata.     <span class="inner-title"><span class="math-span">\( P(X \geq 10)\)</span></span>     Calcolare la probabilità che l'autobus arrivi dalle <span class="mono">7:00 AM</span> in poi, equivale a calcolare <span class="math-span">\( P(X \geq 10)\)</span>, ovvero che <span class="math-span">\( P(X \in [10, 30])\)</span>     <span class="math-block">\[         \begin{array}{ccl}             P(X \in [10, 30]) &amp; = &amp; \frac{d - c}{\beta - \alpha} \\             &amp; = &amp; \frac{30 - 10}{30 - 0} \\             &amp; = &amp; \frac{2}{3}         \end{array}      \]</span>     <span class="inner-title"><span class="math-span">\( P(X \geq 15)\)</span></span>     Calcolare la probabilità che l'autobus arrivi dalle <span class="mono">7:00 AM</span> in poi, equivale a calcolare <span class="math-span">\( P(X \geq 15)\)</span>, ovvero che <span class="math-span">\( P(X \in [15, 30])\)</span>     <span class="math-block">\[         \begin{array}{ccl}             P(X \in [15, 30]) &amp; = &amp; \frac{d - c}{\beta - \alpha} \\             &amp; = &amp; \frac{30 - 15}{30 - 0} \\             &amp; = &amp; \frac{1}{2}         \end{array}      \]</span>     <span class="inner-title"><span class="math-span">\( P(X = 10)\)</span></span>     Calcolare la probabilità che l'autobus arrivi <span class="mono">7:00 AM</span>, equivale a calcolare <span class="math-span">\( P(X = 10)\)</span> che è uguale a <span class="math-span">\( 0\)</span> in quanto stiamo trattando variabili casuali continue. Nonostante la probabilità sia nulla, ciò non significa che l'evento sia impossibile. </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="definition environment" id="def2-36"><h2 class="environment-title">Definizione - Problemi sulla probabilità che un sistema in serie e parallelo funzioni fino ad un istante <span class="math-span">\( a\)</span></h2><div class="environment-body">     Utilizzando le variabili casuali continue, è possibile descrivere meglio il funzionamento di dispositivi in serie ed in parallelo, descrivendo la probabilità di funzionamento fino ad un certo istante.     <span class="inner-title">Dispositivi in serie</span>     Nel caso di <span class="math-span">\( n\)</span> dispositivi in serie, caratterizzati da <span class="math-span">\( n\)</span> variabili casuali continue che descrivono la probabilità di funzionamento allo scorrere del tempo <span class="math-span">\( X_1, \ldots, X_n\)</span>     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/dispositivi-serie-tempi-funzionamento.png"/></div></div>     si ha che il sistema funziona fino a quando ogni dispositivo funziona, ovvero si ha che     <span class="math-block">\[         T = \text{"Tempo di funzionamento del sistema"}       \]</span>     è uguale al minimo tra tutti i tempi di funzionamento, ovvero     <span class="math-block">\[        T = min(X_1, \ldots, X_n)     \]</span>     Si avrà quindi che la probabilità che il sistema funzioni fino ad un istante <span class="math-span">\( a\)</span> è data dalla funzione     <span class="math-block">\begin{aligned}         &amp; P(T \leq a) = P(min(X_1, \ldots, X_n) \leq a)  &amp;  \iff     \end{aligned}</span>     Ora, è possibile quindi considerare tale relazione in funzione del complementare della probabilità, ovvero     <span class="math-block">\begin{aligned}         &amp; P(T \leq a) = 1 - P(min(X_1, \ldots, X_n) \gt a) &amp; \iff     \end{aligned}</span>     Ora, il fatto che il minimo tra i tempi è maggiore di <span class="math-span">\( a\)</span> implica che ogni tempo sia maggiore di <span class="math-span">\( a\)</span>, ovvero     <span class="math-block">\begin{aligned}         &amp; P(T \leq a) = 1 - P(X_1 \gt a \ \cap \ \ldots \ \cap \ X_n \gt a) &amp; \iff     \end{aligned}</span>     e data l'indipendenza del funzionamento dei dispositivi     <span class="math-block">\begin{aligned}         &amp; P(T \leq a) = 1 - P(X_1 \gt a) \cdot \ldots \cdot P(X_n \gt a) &amp;     \end{aligned}</span>     che è decisamente pià semplice da calcolare.     <span class="inner-title">Dispositivi in parallelo</span>     Nel caso si abbiano invece <span class="math-span">\( n\)</span> dispositivi in parallelo caratterizzati da <span class="math-span">\( n\)</span> variabili casuali continue che descrivono la probabilità di funzionamento allo scorrere del tempo <span class="math-span">\( X_1, \ldots, X_n\)</span>     <div class="image-environment"><div class="image-wrapper spaced-30"><img alt="Immagine" src="../resources/dispositivi-parallelo-tempi-funzionamento.png"/></div></div>     si ha che il sistema funziona fino a quando anche solo uno dei dispositivi funziona, ovvero si ha      <span class="math-block">\[         T = \text{"Tempo di funzionamento del sistema"}       \]</span>     è uguale al massimo tra tutti i tempi di funzionamento, ovvero     <span class="math-block">\[        T = max(X_1, \ldots, X_n)     \]</span>     Si avrà quindi che la probabilità che il sistema funzioni fino ad un istante <span class="math-span">\( a\)</span> è data dalla funzione     <span class="math-block">\begin{aligned}         &amp; P(T \leq a) = P(max(X_1, \ldots, X_n) \leq a)  &amp;  \iff     \end{aligned}</span>     Ora, il fatto che il massima tra i tempi è maggiore o uguale ad <span class="math-span">\( a\)</span> implica che ogni tempo sia minore o uguale di <span class="math-span">\( a\)</span>, ovvero     <span class="math-block">\begin{aligned}         &amp; P(T \leq a) = P(X_1 \leq a \ \cap \ \ldots \ \cap \ X_n \leq a) &amp; \iff     \end{aligned}</span>     e data l'indipendenza del funzionamento dei dispositivi     <span class="math-block">\begin{aligned}         &amp; P(T \leq a) = P(X_1 \leq a) \cdot \ldots \cdot P(X_n \leq a) &amp; \iff \\         &amp; P(T \leq a) = F_{X_1}(a) \cdot \ldots \cdot F_{X_n}(a) &amp;       \end{aligned}</span>     che è decisamente pià semplice da calcolare. </div></div><div class="definition environment" id="def2-37"><h2 class="environment-title">Definizione - Coppia di variabili casuali uniformi e probabilità di appartenenza ad un sottoinsieme di <span class="math-span">\( \mathbb{R}^2\)</span></h2><div class="environment-body">     Considerando due variabili casuali continue uniformi indipendenti tali che     <span class="math-block">\[         X \sim U(\alpha, \beta)  \qquad \text{con} \ \alpha, \beta \in \mathbb{R} \ \text{e} \ \alpha \lt \beta     \]</span>     e      <span class="math-block">\[         Y \sim U(\gamma, \delta)  \qquad \text{con} \ \gamma, \delta \in \mathbb{R} \ \text{e} \ \gamma \lt \delta     \]</span>     è possibile definire l'insieme <span class="math-span">\( R\)</span>, detto anche "<strong>rettangolo di definizione di <span class="math-span">\( (X, Y)\)</span></strong>"     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/rettangolo-definizione.png"/></div></div>     È possibile domandarsi la probabilità che la coppia <span class="math-span">\( (X, Y)\)</span> appartenga ad un certo insieme <span class="math-span">\( D\)</span> sottoinsieme di <span class="math-span">\( \mathbb{R}^2\)</span>, graficamente     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/rettangolo-definizione-inters-sottoinsieme.png"/></div></div>     Per calcolare il valore di <span class="math-span">\( P(X \in D)\)</span>, è necessario calcolare     <span class="math-block">\begin{aligned}         &amp; P(X \in D) = \underset{D}{\int \int} f(x, y) \ dx \ dy  &amp; \iff     \end{aligned}</span>     Tuttavia, considerando che <span class="math-span">\( (X, Y)\)</span> appartiene solo a <span class="math-span">\( R\)</span>, si ha che è uguale a      <span class="math-block">\begin{aligned}         &amp; P(X \in D) = \underset{D \cap R}{\int \int} f(x, y) \ dx \ dy &amp; \iff     \end{aligned}</span>     e considerando l'indipendenza delle due variabili casuali, si ha che     <span class="math-block">\begin{aligned}         &amp; P(X \in D) = \underset{D \cap R}{\int \int} f_X(x) \cdot f_Y(y) \ dx \ dy &amp; \iff \\         &amp; P(X \in D) = \underset{D \cap R}{\int \int} \frac{1}{\beta - \alpha} \cdot \frac{1}{\delta - \gamma} \ dx \ dy &amp; \iff \\         &amp; P(X \in D) = \frac{1}{\beta - \alpha} \cdot \frac{1}{\delta - \gamma} \cdot \underset{D \cap R}{\int \int} 1 \ dx \ dy &amp; \iff     \end{aligned}</span>     Ora, considerando che <span class="math-span">\( \underset{D \cap R}{\int \int} 1 \ dx \ dy\)</span> equivale all'area di <span class="math-span">\( D \cap R\)</span> e che <span class="math-span">\( (\beta - \alpha) \cdot (\delta - \gamma)\)</span> è l'area del rettangolo <span class="math-span">\( R\)</span>, si ha che     <span class="math-block">\[         P(X \in D) = \frac{\text{Area di $D \cap R$}}{\text{Area di $R$}}       \]</span> </div></div><div class="definition environment" id="def2-38"><h2 class="environment-title">Definizione - Variabile casuale esponenziale</h2><div class="environment-body">     Una variabile casuale continua <span class="math-span">\( X\)</span> si definisce esponenziale di parametro <span class="math-span">\( \lambda\)</span> (<span class="math-span">\( X \sim E(\lambda)\)</span> con <span class="math-span">\( \lambda \in \mathbb{R}^+\)</span>) se rappresenta il tempo intercorso tra due "eventi rari" che avvengono in maniera indipendente e continua ad un tasso medio di <span class="math-span">\( \lambda\)</span>. Essa è caratterizzata dalla funzione di densità uguale a     <span class="math-block">\[         f(x) = \left\{ \begin{array}{ll}             \lambda \cdot \mathrm{e}^{-\lambda \cdot x} &amp; \text{se} \ x \geq 0 \\             0 &amp; \text{altrove}         \end{array} \right.     \]</span>     <span class="inner-title">Funzione di ripartizione</span>     La funzione di ripartizione <span class="math-span">\( F(a)\)</span> di una variabile casuale esponenziale sarà uguale a     <span class="math-block">\[         \begin{array}{ccl}             F(a) &amp; = &amp; \int_{-\infty}^{a} f(x) \ dx \\              &amp; = &amp; \left\{ \begin{array}{ll}                 \int_{-\infty}^0 0 \ dx + \int_0^a \lambda \cdot \mathrm{e}^{-\lambda \cdot x} \ dx &amp; \text{se} \ a \geq 0 \\                 \int_{-\infty}^a 0 \ dx &amp; \text{se} \ a \lt 0             \end{array} \right.  \\              &amp; = &amp; \left\{ \begin{array}{ll}                 \int_0^a \lambda \cdot \mathrm{e}^{-\lambda \cdot x} \ dx &amp; \text{se} \ a \geq 0 \\                 0 &amp; \text{se} \ a \lt 0             \end{array} \right.              \end{array}       \]</span>     che è quindi uguale a     <span class="math-block">\begin{aligned}         &amp; =  \int_0^a \lambda \cdot \mathrm{e}^{-\lambda \cdot x} \ dx &amp; = \\         &amp; =  -1 \cdot \int_0^a -\lambda \cdot \mathrm{e}^{-\lambda \cdot x} \ dx &amp; = \\         &amp; = \left[ \mathrm{e}^{-\lambda \cdot x} \right]^a_0 &amp; = \\         &amp; = - (\mathrm{e}^{-\lambda \cdot a} - 1) &amp; = \\         &amp; = 1 - \mathrm{e}^{-\lambda \cdot a}     \end{aligned}</span>     Riassumendo si ha che <span class="math-span">\( F(a) = 1 - \mathrm{e}^{-\lambda \cdot a}\)</span> per <span class="math-span">\( a \geq 0\)</span>.     <span class="inner-title">Funzione generatrice dei momenti</span>     La funzione generatrice dei momenti di una v. c. esponenziale di parametro <span class="math-span">\( \lambda\)</span> è uguale a     <span class="math-block">\[         \begin{array}{ccl}             \phi(t) &amp; = &amp; E\left[ \mathrm{e}^{t \cdot X} \right] \\             &amp; = &amp; \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot x} \cdot f(x) \ dx \\             &amp; = &amp; \int_{-\infty}^{0} \mathrm{e}^{t \cdot x} \cdot 0 \ dx +  \int_{0}^{+\infty} \mathrm{e}^{t \cdot x} \cdot \lambda \cdot \mathrm{e}^{-\lambda \cdot x} \ dx \\             &amp; = &amp; \lambda \cdot \int_{0}^{+\infty} \mathrm{e}^{t \cdot x} \cdot \mathrm{e}^{-\lambda \cdot x} \ dx \\             &amp; = &amp; \lambda \cdot \int_{0}^{+\infty} \mathrm{e}^{t \cdot x - \lambda \cdot x} \ dx \\             &amp; = &amp; \lambda \cdot \int_{0}^{+\infty} \mathrm{e}^{x \cdot (t - \lambda)} \ dx \\         \end{array}     \]</span>     da ciò, si ha che se <span class="math-span">\( t - \lambda \gt 0 \implies t \gt \lambda\)</span> l'integrale diverge mentre se <span class="math-span">\( t \leq \lambda\)</span> si avrà     <span class="math-block">\[         \begin{array}{ccl}             \phi(t) &amp; = &amp; \lambda \cdot \int_{0}^{+\infty} \mathrm{e}^{x \cdot (t - \lambda)} \ dx \\             &amp; = &amp; \lambda \cdot \frac{1}{t - \lambda} \cdot \left[ \mathrm{e}^{x \cdot (t - \lambda)} \right]_0^{+\infty} \\             &amp; = &amp; \frac{\lambda}{t - \lambda} \cdot (0 - 1) \\             &amp; = &amp; \frac{\lambda}{\lambda - t}         \end{array}     \]</span>     Ovvero si ha che <span class="math-span">\( \phi(t) = \frac{\lambda}{\lambda - t}\)</span> per <span class="math-span">\( t \leq \lambda\)</span>.     <span class="inner-title">Valore atteso</span>     Il valore atteso per una variabile casuale esponenziale di parametro <span class="math-span">\( \lambda\)</span> è calcolabile come     <span class="math-block">\[         \begin{array}{ccl}             E[X] &amp; = &amp; \frac{\partial}{\partial t} \phi(t) \mid_{t = 0}   \\             &amp; = &amp; \frac{\partial}{\partial t} \left( \frac{\lambda}{\lambda - t} \right) \mid_{t = 0} \\             &amp; = &amp; \lambda \cdot \frac{\partial}{\partial t} \left( \lambda - t \right)^{-1} \mid_{t = 0} \\             &amp; = &amp; \lambda \cdot (-1) \cdot (-1) \frac{1}{(\lambda - t)^2} \mid_{t = 0} \\             &amp; = &amp; \frac{\lambda}{(\lambda - t)^2} \mid_{t = 0} \\             &amp; = &amp; \frac{1}{\lambda}         \end{array}     \]</span>     <span class="inner-title">Varianza</span>     La varianza di una v. c. esponenziale di parametro <span class="math-span">\( \lambda\)</span> è calcolabile come     <span class="math-block">\[         Var(X) = E\left[X^2\right] - (E[X])^2     \]</span>     È necessario calcolare quindi <span class="math-span">\( E\left[X^2\right]\)</span> che è uguale a     <span class="math-block">\[         \begin{array}{ccl}             E\left[X^2\right] &amp; = &amp; \frac{\partial^2}{\partial^2 t} \phi(t) \mid_{t = 0}   \\             &amp; = &amp; \frac{\partial}{\partial t} \left( \frac{\lambda}{(\lambda - t)^2} \right) \mid_{t = 0} \\             &amp; = &amp; \lambda \cdot \frac{\partial}{\partial t} \left( \lambda - t \right)^{-2} \mid_{t = 0} \\             &amp; = &amp; \lambda \cdot (-1) \cdot (-2) \frac{1}{(\lambda - t)^3} \mid_{t = 0} \\             &amp; = &amp; \frac{2 \cdot \lambda}{(\lambda - t)^3} \mid_{t = 0} \\             &amp; = &amp; \frac{2}{\lambda^2}         \end{array}     \]</span>     È ora possibile calcolare la varianza, ovvero     <span class="math-block">\[         \begin{array}{ccl}             Var(X) &amp; = &amp; E\left[X^2\right] - (E[X])^2 \\             &amp; = &amp; \frac{2}{\lambda^2} - \frac{1}{\lambda^2} \\             &amp; = &amp; \frac{1}{\lambda^2}         \end{array}       \]</span> </div></div><div class="definition environment" id="def2-39"><h2 class="environment-title">Definizione - Probabilità di funzionamento di sistemi in serie e parallelo fino ad un istante <span class="math-span">\( a\)</span> utilizzando v. c. esponenziali</h2><div class="environment-body">     Un sottogruppo di problemi relativi alla probabilità di funzionamento dopo un certo tempo <span class="math-span">\( a\)</span> è quello di modellare ogni dispositivo con una variabile casuale esponenziale (<span class="math-span">\( X_i \sim E(\lambda_i)\)</span> per <span class="math-span">\( i \in \{ 1, \ldots, n\}\)</span>).     <span class="inner-title">Dispositivi in serie</span>     Considerando un generico caso, avevamo ottenuto che per <span class="math-span">\( n\)</span> dispositivi in serie la probabilità che il sistema <span class="math-span">\( T\)</span> funzionasse fino ad un istante <span class="math-span">\( a\)</span> fosse     <span class="math-block">\[         P(T \leq a) = 1 - P(X_1 \gt a) \cdot \ldots \cdot P(X_n \gt a)       \]</span>      Considerando ora che stiamo trattando variabili esponenziali la cui funzione di ripartizione è uguale a      <span class="math-block">\[         F_{X_i}(a) = \left\{ \begin{array}{ll}             1 - \mathrm{e}^{-\lambda_i \cdot a} &amp; \text{se} \ a \geq 0 \\             0 &amp; \text{se} \ a \lt 0          \end{array} \right.     \]</span>     e che     <span class="math-block">\[         P(X_i \gt a) = 1 - P(X_i \leq a) = 1 - F_{X_i}(a)      \]</span>     si ha che     <span class="math-block">\[         \begin{array}{ccl}             P(T \leq a) &amp; = &amp; 1 - (1 - F_{X_1}(a)) \cdot \ldots \cdot (1 - F_{X_n}(a)) \\             &amp; = &amp; 1 -              \left\{ \begin{array}{ll}                 \mathrm{e}^{-\lambda_1 \cdot a} &amp; \text{se} \ a \geq 0 \\                 1 &amp; \text{se} \ a \lt 0              \end{array} \right.              \cdot \ldots \cdot              \left\{ \begin{array}{ll}                 \mathrm{e}^{-\lambda_n \cdot a} &amp; \text{se} \ a \geq 0 \\                 1 &amp; \text{se} \ a \lt 0              \end{array} \right. \\             &amp; = &amp; 1 - \left\{ \begin{array}{ll}                 \mathrm{e}^{-(\lambda_1 + \ldots + \lambda_n) \cdot a } &amp; \text{se} \ a \geq 0 \\                 1 &amp; \text{se} \ a \lt 0              \end{array} \right. \\             &amp; = &amp; \left\{ \begin{array}{ll}                 1 - \mathrm{e}^{-(\lambda_1 + \ldots + \lambda_n) \cdot a } &amp; \text{se} \ a \geq 0 \\                 0 &amp; \text{se} \ a \lt 0              \end{array} \right. \\         \end{array}     \]</span>     Da cui è possibile dedurre che anche <span class="math-span">\( T\)</span> è una variabile casuale esponenziale, ovvero     <span class="math-block">\[         T \sim E(\lambda_1 + \ldots + \lambda_n)       \]</span>     <span class="inner-title">Dispositivi in parallelo</span>     Considerando un generico caso, avevamo ottenuto che per <span class="math-span">\( n\)</span> dispositivi in parallelo la probabilità che il sistema <span class="math-span">\( T\)</span> funzionasse fino ad un istante <span class="math-span">\( a\)</span> fosse     <span class="math-block">\[         P(T \leq a) = F_{X_1}(a) \cdot \ldots \cdot F_{X_n}(a)       \]</span>      Considerando ora che stiamo trattando variabili esponenziali la cui funzione di ripartizione è uguale a      <span class="math-block">\[         F_{X_i}(a) = \left\{ \begin{array}{ll}             1 - \mathrm{e}^{-\lambda_i \cdot a} &amp; \text{se} \ a \geq 0 \\             0 &amp; \text{se} \ a \lt 0          \end{array} \right.     \]</span>     si ha che     <span class="math-block">\[         \begin{array}{ccl}             P(T \leq a) &amp; = &amp; F_{X_1}(a) \cdot \ldots \cdot  F_{X_n}(a) \\             &amp; = &amp;              \left\{ \begin{array}{ll}                 1 - \mathrm{e}^{-\lambda_1 \cdot a} &amp; \text{se} \ a \geq 0 \\                 0 &amp; \text{se} \ a \lt 0              \end{array} \right.              \cdot \ldots \cdot              \left\{ \begin{array}{ll}                 1 - \mathrm{e}^{-\lambda_n \cdot a} &amp; \text{se} \ a \geq 0 \\                 0 &amp; \text{se} \ a \lt 0              \end{array} \right. \\             &amp; = &amp; \left\{ \begin{array}{ll}                 \prod_{k = 1}^n \left( 1 - \mathrm{e}^{-\lambda_k \cdot a } \right) &amp; \text{se} \ a \geq 0 \\                 0 &amp; \text{se} \ a \lt 0              \end{array} \right. \\         \end{array}     \]</span> </div></div><div class="demonstration environment" id="dem2-11"><h2 class="environment-title">Dimostrazione - Variabile casuale esponenziale moltiplicata per uno scalare</h2><div class="environment-body">     Data la proposizione      <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Considerando una v. c. esponenziale <span class="math-span">\( X \sim E(\lambda)\)</span>, se <span class="math-span">\( Y = c \cdot X\)</span> (con <span class="math-span">\( c \in \mathbb{R}^+\)</span>), si ha che <span class="math-span">\( Y \sim E(\frac{\lambda}{c})\)</span>.     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione consideriamo di calcolare la funzione generatrice dei momenti di <span class="math-span">\( Y\)</span>, ovvero         <span class="math-block">\[             \begin{array}{ccl}                 \phi_Y(t) &amp; = &amp; E[\mathrm{e^{t \cdot Y}}] \\                 &amp; \underset{Y = c \cdot X}{=} &amp; E[\mathrm{e^{t \cdot c \cdot X}}]             \end{array}           \]</span>         Dato ciò, è ora possibile considerare tale funzione come la funzione generatrice dei momenti di <span class="math-span">\( X\)</span> in <span class="math-span">\( t \cdot c\)</span>, ovvero         <span class="math-block">\[             \begin{array}{ccl}                 \phi_Y(t) &amp; = &amp; E[\mathrm{e^{t \cdot c \cdot X}}] \\                 &amp; = &amp; \phi_X(t \cdot c)              \end{array}           \]</span>         Si ha tuttavia che conosciamo <span class="math-span">\( \phi_X(t) = \frac{\lambda}{\lambda - t}\)</span> (in quanto è una v. c. esponenziale), per cui sappiamo che         <span class="math-block">\[             \begin{array}{ccl}                 \phi_Y(t) &amp; = &amp; \phi_X(t \cdot c) \\                 &amp; = &amp; \frac{\lambda}{\lambda - t \cdot c} \\                 &amp; = &amp; \frac{\lambda}{\lambda - t \cdot c} \cdot \frac{\frac{1}{c}}{\frac{1}{c}} \\                 &amp; = &amp; \frac{\frac{\lambda}{c}}{\frac{\lambda - t \cdot c}{c}} \\                 &amp; = &amp; \frac{\frac{\lambda}{c}}{\frac{\lambda}{c} - t}             \end{array}           \]</span>         che è esattamente la funzione generatrice di una variabile esponenziale di parametro <span class="math-span">\( \frac{\lambda}{c}\)</span>.          Si è quindi dimostrata la proposizione.     </div></div> </div></div><div class="demonstration environment" id="dem2-12"><h2 class="environment-title">Dimostrazione - Mancanza di memoria per variabili casuali esponenziali</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Considerando una variabile casuale <span class="math-span">\( X \sim E(\lambda)\)</span>, si ha che è caratterizzata dalla "mancanza della memoria", ovvero si ha che considerando <span class="math-span">\( a, b \in \mathbb{R}^+\)</span> vale          <span class="math-block">\[             P(X \gt a + b \mid X \gt a) = P(x \gt b)           \]</span>     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione, consideriamo la definizione di probabilità condizionata         <span class="math-block">\begin{aligned}             &amp; P(X \gt a + b \mid X \gt a) = \frac{P(X \gt a + b \cap X \gt a)}{P(X \gt a)} &amp; \iff         \end{aligned}</span>         Dato ciò, si ha che l'intersezione degli eventi <span class="math-span">\( X \gt a + b\)</span> e <span class="math-span">\( X \gt a\)</span> avviene quando <span class="math-span">\( X \gt a + b\)</span>, ovvero         <span class="math-block">\begin{aligned}             &amp; P(X \gt a + b \mid X \gt a) = \frac{P(X \gt a + b)}{P(X \gt a)} &amp; \iff         \end{aligned}</span>         e, dato ciò, è possibile considerare che          <span class="math-block">\[             P(X \gt a + b) = 1 - P(X \leq a + b) = 1 - F(a + b)         \]</span>         e, considerando la funzione di ripartizione di una v. c. esponenziale, ovvero         <span class="math-block">\[             F(a) = 1 - \mathrm{e}^{-\lambda \cdot a}           \]</span>         si ha che è possibile sostituire all'uguaglianza precedente i valori         <span class="math-block">\begin{aligned}             &amp; P(X \gt a + b \mid X \gt a) = \frac{ 1 - 1 + \mathrm{e}^{-\lambda \cdot (a + b)}}{1 - 1 + \mathrm{e}^{-\lambda \cdot a}} &amp; \iff \\             &amp; P(X \gt a + b \mid X \gt a) = \frac{ \mathrm{e}^{-\lambda \cdot a} \cdot \mathrm{e}^{-\lambda \cdot b}}{\mathrm{e}^{-\lambda \cdot a}} &amp; \iff \\             &amp; P(X \gt a + b \mid X \gt a) = \mathrm{e}^{-\lambda \cdot b} &amp; \iff \\             &amp; P(X \gt a + b \mid X \gt a) = P(x \gt b) &amp;          \end{aligned}</span>         che dimostra la proposizione.     </div></div> </div></div><div class="definition environment" id="def2-40"><h2 class="environment-title">Definizione - Variabile casuale gaussiana (o normale)</h2><div class="environment-body">     Una variabile casuale continua <span class="math-span">\( X\)</span> si definisce gaussiana (o normale) di parametri <span class="math-span">\( \mu\)</span> e <span class="math-span">\( \sigma\)</span> (<span class="math-span">\( X \sim N(\mu, \sigma)\)</span>) se è ha valore atteso <span class="math-span">\( \mu\)</span> (con <span class="math-span">\( \mu \in \mathbb{R}\)</span>) e deviazione standard <span class="math-span">\( \sigma\)</span> (con <span class="math-span">\( \sigma \in \mathbb{R}^+\)</span>) ed è caratterizzata dalla funzione di densità      <span class="math-block">\[         f(x) = \frac{1}{\sigma \cdot \sqrt{2 \pi}} \cdot \mathrm{e}^{-\frac{(x - \mu)^2}{2\sigma^2}}       \]</span>     <span class="inner-title">Funzione generatrice dei momenti</span>     La funzione generatrice dei momenti di una variabile casuale gaussiana di parametri <span class="math-span">\( \mu\)</span> e <span class="math-span">\( \sigma\)</span> è uguale a     <span class="math-block">\[         \begin{array}{ccl}             \phi(t) &amp; = &amp; E\left[\mathrm{e}^{t \cdot X}\right] \\             &amp; = &amp; \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot x} \cdot f(x) \ dx \\             &amp; = &amp; \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot x} \cdot \frac{1}{\sigma \cdot \sqrt{2 \pi}} \cdot \mathrm{e}^{-\frac{(x - \mu)^2}{2\sigma}}   \ dx \\         \end{array}     \]</span>       considerando ora     <span class="math-block">\[         z = \frac{x - \mu}{\sigma}       \]</span>     che implica      <span class="math-block">\begin{aligned}         &amp; x = z \cdot \sigma + \mu &amp; \\         &amp; dx = \underbrace{\ \sigma \ dz \ }_{\frac{d}{dz} (z \cdot \sigma + \mu) \ dz } &amp;     \end{aligned}</span>     si ha che     <span class="math-block">\[         \begin{array}{ccl}             \phi(t) &amp; = &amp; \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot x} \cdot \frac{1}{\sigma \cdot \sqrt{2 \pi}} \cdot \mathrm{e}^{-\frac{(x - \mu)^2}{2\sigma^2}}   \ dx \\             &amp; = &amp; \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot (z \cdot \sigma + \mu)} \cdot \frac{1}{\sigma \cdot \sqrt{2 \pi}} \cdot \mathrm{e}^{-\frac{z^2}{2}} \cdot \sigma \ dz \\             &amp; = &amp; \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot (z \cdot \sigma + \mu)} \cdot \frac{1}{\sqrt{2 \pi}} \cdot \mathrm{e}^{-\frac{z^2}{2}}\ dz \\             &amp; = &amp; \frac{1}{\sqrt{2 \pi}} \cdot  \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot (z \cdot \sigma + \mu)} \cdot \mathrm{e}^{-\frac{z^2}{2}}\ dz \\             &amp; = &amp; \frac{1}{\sqrt{2 \pi}} \cdot  \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot (z \cdot \sigma)} \cdot \mathrm{e}^{t \cdot \mu} \cdot \mathrm{e}^{-\frac{z^2}{2}}\ dz \\             &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot  \int_{-\infty}^{+\infty} \mathrm{e}^{t \cdot (z \cdot \sigma) - \frac{z^2}{2}}\ dz \\             &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot  \int_{-\infty}^{+\infty} \mathrm{e}^{\frac{2 \cdot t \cdot z \cdot \sigma - z^2}{2}}\ dz \\         \end{array}     \]</span>       Moltiplicando per <span class="math-span">\( 1 = \mathrm{e}^{\frac{t^2 \cdot \sigma^2 - t^2 \cdot \sigma^2}{2}}\)</span>, si ottiene     <span class="math-block">\[         \begin{array}{ccl}             \phi(t) &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot  \int_{-\infty}^{+\infty} \mathrm{e}^{\frac{2 \cdot t \cdot z \cdot \sigma - z^2}{2}}\ dz \\             &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot  \int_{-\infty}^{+\infty} \mathrm{e}^{\frac{2 \cdot t \cdot z \cdot \sigma - z^2}{2}} \cdot \mathrm{e}^{\frac{t^2 \cdot \sigma^2 - t^2 \cdot \sigma^2}{2}} \ dz \\             &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot  \int_{-\infty}^{+\infty} \mathrm{e}^{\frac{2 \cdot t \cdot z \cdot \sigma - z^2 - \cdot t^2 \cdot \sigma^2}{2}} \cdot \mathrm{e}^{\frac{t^2 \cdot \sigma^2}{2}} \ dz \\             &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot \mathrm{e}^{\frac{t^2 \cdot \sigma^2}{2}} \cdot \int_{-\infty}^{+\infty} \mathrm{e}^{-\frac{-2 \cdot t \cdot z \cdot \sigma + z^2 + t^2 \cdot \sigma^2}{2}} \ dz \\             &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot \mathrm{e}^{\frac{t^2 \cdot \sigma^2}{2}} \cdot \int_{-\infty}^{+\infty} \mathrm{e}^{-\frac{(z - t \cdot \sigma)^2}{2}} \ dz          \end{array}     \]</span>       Consideriamo ora     <span class="math-block">\[         y = z - t \cdot \sigma     \]</span>     che implica     <span class="math-block">\begin{aligned}         &amp; z = y + t \cdot \sigma &amp; \\         &amp; dz = \underbrace{\ 1 \ dy \ }_{\frac{d}{dy} (y + t \cdot \sigma) \ dy } &amp;     \end{aligned}</span>     si otterrà     <span class="math-block">\[         \begin{array}{ccl}             \phi(t) &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot \mathrm{e}^{\frac{t^2 \cdot \sigma^2}{2}} \cdot \int_{-\infty}^{+\infty} \mathrm{e}^{-\frac{(z - t \cdot \sigma)^2}{2}} \ dz \\             &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot \mathrm{e}^{\frac{t^2 \cdot \sigma^2}{2}} \cdot \int_{-\infty}^{+\infty} \mathrm{e}^{-\frac{y^2}{2}} \ dy         \end{array}     \]</span>      Ora, dato che      <span class="math-block">\[         \int_{-\infty}^{+\infty} \mathrm{e}^{-\frac{y^2}{2}} \ dy = \sqrt{2 \pi}     \]</span>     in quanto integrale notevole, è possibile calcolare     <span class="math-block">\[         \begin{array}{ccl}             \phi(t) &amp; = &amp; \frac{\mathrm{e}^{t \cdot \mu}}{\sqrt{2 \pi}} \cdot \mathrm{e}^{\frac{t^2 \cdot \sigma^2}{2}} \cdot \sqrt{2 \pi} \\             &amp; = &amp; \mathrm{e}^{t \cdot \mu} \cdot \mathrm{e}^{\frac{t^2 \cdot \sigma^2}{2}} \\             &amp; = &amp; \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}}         \end{array}     \]</span>      ovvero si ha che <span class="math-span">\( \phi(t) = \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}}\)</span>.     <span class="inner-title">Valore atteso</span>     Il valore atteso di una variabile casuale gaussiana di parametri <span class="math-span">\( \mu\)</span> e <span class="math-span">\( \sigma\)</span> è calcolabile come     <span class="math-block">\[         \begin{array}{ccl}             E[X] &amp; = &amp; \frac{\partial}{\partial t} \phi(t) \mid_{t = 0} \\             &amp; = &amp; \frac{\partial}{\partial t} \left( \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}} \right) \mid_{t = 0} \\             &amp; = &amp; ( \mu + \frac{1}{2} \cdot 2t \cdot \sigma^2) \cdot \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}} \mid_{t = 0} \\             &amp; = &amp; ( \mu + t \cdot \sigma^2) \cdot \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}} \mid_{t = 0} \\             &amp; = &amp; \mu          \end{array}         \]</span>     <span class="inner-title">Varianza</span>     La varianza di una v. c. gaussiana di parametri <span class="math-span">\( \mu\)</span> e <span class="math-span">\( \sigma\)</span> è calcolabile come     <span class="math-block">\[         Var(X) = E\left[X^2\right] - (E[X])^2     \]</span>     È necessario calcolare quindi <span class="math-span">\( E\left[X^2\right]\)</span> che è uguale a     <span class="math-block">\[         \begin{array}{ccl}             E\left[X^2\right] &amp; = &amp; \frac{\partial^2}{\partial^2 t} \phi(t) \mid_{t = 0}   \\             &amp; = &amp; \frac{\partial}{\partial t} \left( (\mu + t \cdot \sigma^2) \cdot \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}} \right) \mid_{t = 0} \\             &amp; = &amp; \sigma^2 \cdot \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}} + (\mu + t \cdot \sigma^2)^2 \cdot \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}} \\             &amp; = &amp; \lambda \cdot (-1) \cdot (-2) \frac{1}{(\lambda - t)^3} \mid_{t = 0} \\             &amp; = &amp; \sigma^2 + \mu^2         \end{array}     \]</span>     È ora possibile calcolare la varianza, ovvero     <span class="math-block">\[         \begin{array}{ccl}             Var(X) &amp; = &amp; E\left[X^2\right] - (E[X])^2 \\             &amp; = &amp; \sigma^2 + \mu^2 - \mu^2 \\             &amp; = &amp; \sigma^2         \end{array}       \]</span>     <span class="inner-title">Effetto della variazione dei parametri sulla funzione di densità</span>     Considerando la funzione di densità     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/funz-densita-gaussiana.png"/></div></div>     si ha che è caratterizzata dal massimo in corrispondenza del valore atteso <span class="math-span">\( \mu\)</span>, punto in cui ha probabilità <span class="math-span">\( \frac{1}{\sigma \cdot \sqrt{2 \pi}}\)</span> e punto in cui è la funzione è simmetrica.     <br/>     Al variare di <span class="math-span">\( \mu\)</span> (considerando fisso <span class="math-span">\( \sigma\)</span>), si ottiene una traslazione orizzontale rigida della curva, ovvero     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/variazione-valore-atteso-gaussiana.png"/></div></div>     Al variare invece di <span class="math-span">\( \sigma\)</span> (considerando fisso <span class="math-span">\( \mu\)</span>), si ottiene un cambiamento sul valore del picco (in modo inversamente proporzionale, ovvero al crescere di <span class="math-span">\( \sigma\)</span> il valore del picco diminuisce e viceversa), ovvero     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/variazione-deviazione-gaussiana.png"/></div></div>     <span class="inner-title">Funzione di ripartizione</span>     La funzione di ripartizione di probabilità per una variabile gaussiana di parametri <span class="math-span">\( \mu\)</span> e <span class="math-span">\( \sigma\)</span> sarebbe calcolabile come     <span class="math-block">\[         \begin{array}{ccl}             F(a) &amp; = &amp; P(X \leq a) \\             &amp; = &amp; \int_{-\infty}^a f(x) \ dx \\             &amp; = &amp; \int_{-\infty}^a \frac{1}{\sigma \cdot \sqrt{2 \pi}} \cdot \mathrm{e}^{-\frac{(x - \mu)^2}{2\sigma^2}} \ dx \\          \end{array}     \]</span>     che è un integrale convergente, ma che tuttavia non presenta una primitiva esprimibile analiticamente. Per effettuare i calcoli, è quindi necessario utilizzare apposite tabelle. </div></div><div class="demonstration environment" id="dem2-13"><h2 class="environment-title">Dimostrazione - Trasformazione lineare di una v. c. gaussiana</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Considerando una variabile causale gaussiana <span class="math-span">\( X\)</span> di parametri <span class="math-span">\( \mu\)</span> e <span class="math-span">\( \sigma\)</span> (ovvero <span class="math-span">\( X \sim N(\mu, \sigma)\)</span>), allora considerando la variabile casuale <span class="math-span">\( Y = \alpha \cdot X + \beta\)</span>, si avrà che <span class="math-span">\( Y\)</span> è una v. c. gaussiana di parametri <span class="math-span">\( \alpha \cdot \mu + \beta\)</span> e <span class="math-span">\( \left| \alpha \right| \cdot \sigma\)</span>, ovvero         <span class="math-block">\[             Y \sim N(\alpha \cdot \mu + \beta, \left| \alpha \right| \cdot \sigma)             \]</span>      </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione, calcoliamo la funzione generatrice dei momenti di <span class="math-span">\( Y\)</span>, ovvero         <span class="math-block">\[             \begin{array}{ccl}                 \phi_Y(t) &amp; = &amp; E\left[ \mathrm{e}^{t \cdot Y} \right] \\                 &amp; = &amp; E\left[ \mathrm{e}^{t \cdot (\alpha \cdot X + \beta)} \right] \\                 &amp; = &amp; E\left[ \mathrm{e}^{t \alpha \cdot X + t \cdot \beta} \right] \\                 &amp; = &amp; \mathrm{e}^{t \cdot \beta} \cdot \underbrace{E\left[ \mathrm{e}^{t \alpha \cdot X} \right]}_{\phi_X(\alpha \cdot t)} \\                 &amp; = &amp; \mathrm{e}^{t \cdot \beta} \cdot \phi_X(\alpha \cdot t)                           \end{array}         \]</span>         Tuttavia, si ha che conosciamo già la funzione generatrice di <span class="math-span">\( X\)</span> ovvero         <span class="math-block">\[             \phi_X(t) = \mathrm{e}^{t \cdot \mu + \frac{t^2 \cdot \sigma^2}{2}}         \]</span>         e sostituendo è possibile ottenere         <span class="math-block">\[             \begin{array}{ccl}                 \phi_Y(t) &amp; = &amp; \mathrm{e}^{t \cdot \beta} \cdot \phi_X(\alpha \cdot t) \\                 &amp; = &amp; \mathrm{e}^{t \cdot \beta} \cdot \mathrm{e}^{(\alpha \cdot t) \cdot \mu + \frac{(\alpha \cdot t)^2 \cdot \sigma^2}{2}} \\                 &amp; = &amp; \mathrm{e}^{(\alpha \cdot t) \cdot \mu + \frac{(\alpha \cdot t)^2 \cdot \sigma^2}{2} + t \cdot \beta} \\                 &amp; = &amp; \mathrm{e}^{t \cdot (\alpha \mu + \beta) + \frac{t^2 \cdot (\alpha^2 \sigma^2)}{2}}              \end{array}         \]</span>         che è esattamente la funzione generatrice di una variabile casuale gaussiana di parametri <span class="math-span">\( \alpha \cdot \mu + \beta\)</span> e <span class="math-span">\( \mid \alpha \mid \cdot \sigma\)</span>, dimostrando la proposizione.     </div></div> </div></div><div class="definition environment" id="def2-41"><h2 class="environment-title">Definizione - Variabile casuale gaussiana standard</h2><div class="environment-body">     Una variabile causale gaussiana si definisce standard se è di parametri <span class="math-span">\( 0\)</span> e <span class="math-span">\( 1\)</span>, ovvero      <span class="math-block">\[         X \sim N(0, 1)       \]</span>     <span class="inner-title">Ricondurre una qualsiasi v. c. gaussiana alla v. c. gaussiana standard</span>     Consideriamo una variabile casuale gaussiana     <span class="math-block">\[         X \sim N(\mu, \sigma)     \]</span>       e consideriamo la variabile casuale <span class="math-span">\( Z\)</span>      <span class="math-block">\[         Z = \frac{X - \mu}{\sigma} = \frac{1}{\sigma} \cdot X - \frac{\mu}{\sigma}     \]</span>     Considerando quindi la proprietà di una trasformazione lineare di una v. c. gaussiana, si ha che anche <span class="math-span">\( Z\)</span> è una v. c. gaussiana (con <span class="math-span">\( \alpha = \frac{1}{\sigma}\)</span> e <span class="math-span">\( \beta = -\frac{\mu}{\sigma}\)</span>) ovvero     <span class="math-block">\[         Z \sim N\left(\frac{\mu}{\sigma} - \frac{\mu}{\sigma}, \left| \frac{1}{\sigma} \right| \cdot \sigma \right)       \]</span>     ed eseguendo i calcoli si ottiene     <span class="math-block">\[         Z \sim N(0, 1)         \]</span> </div></div><div class="definition environment" id="def2-42"><h2 class="environment-title">Definizione - Utilizzare la funzione di ripartizione di una v. c. gaussiana standard per il calcolo della funzione di ripartizione di una qualsiasi v. c. gaussiana</h2><div class="environment-body">     Consideriamo tuttavia <span class="math-span">\( X \sim N(\mu, \sigma)\)</span> e si ha che la sua funzione di ripartizione è uguale a     <span class="math-block">\begin{aligned}         &amp; F_X(a) = P(X \leq a) &amp; \iff     \end{aligned}</span>     e sottraendo da entrambe le parti <span class="math-span">\( \mu\)</span> si ottiene     <span class="math-block">\begin{aligned}         &amp; F_X(a) = P(X - \mu \leq a - \mu) &amp; \iff     \end{aligned}</span>     e dividendo per <span class="math-span">\( \sigma\)</span>     <span class="math-block">\begin{aligned}         &amp; F_X(a) = P\left(\frac{X - \mu}{\sigma} \leq \frac{a - \mu}{\sigma} \right) &amp; \iff     \end{aligned}</span>     Ora, considerando la sostituzione di una qualsiasi v. c. gaussiana con la v. c. gaussiana standard, si ha che <span class="math-span">\( \frac{X - \mu}{\sigma} = Z \sim N(0, 1)\)</span>, ovvero     <span class="math-block">\begin{aligned}         &amp; F_X(a) = P\left(Z \leq \frac{a - \mu}{\sigma} \right) &amp; \iff \\         &amp; F_X(a) = F_Z\left(\frac{a - \mu}{\sigma} \right) &amp;     \end{aligned}</span>     ovvero è possibile ricondursi alla funzione di ripartizione della v. c. gaussiana standard considerando qualsiasi v. c. gaussiana.      <div class="mynote environment"><h3 class="environment-title">Nota bene - Why?</h3><div class="environment-body">         Tale metodo è utile in quanto è possibile calcolare il valore della funzione di ripartizione in un qualsiasi punto per una qualsiasi variabile casuale gaussiana avendo tuttavia sottomano solamente i valori della funzione di ripartizione della gaussiana standard.     </div></div> </div></div><div class="myexample environment" id="example31"><h2 class="environment-title">Esempio - Utilizzo della funzione di ripartizione per v. c. gaussiane standard</h2><div class="environment-body collapsed">     Per trasmettere un messaggio binario (ovvero le cifre <span class="math-span">\( 0\)</span> o <span class="math-span">\( 1\)</span>) tramite un filo elettrico, si invia un segnale di <span class="math-span">\( 2 \mathrm{ \, Volt }\)</span> per indicare la cifra <span class="math-span">\( 1\)</span> e di <span class="math-span">\( -2 \mathrm{ \, Volt }\)</span> per indicare la cifra <span class="math-span">\( 0\)</span>.     A causa di disturbi sul canale, se la sorgente invia il segnale <span class="math-span">\( x\)</span> (con <span class="math-span">\( x \in \{ -2, 2 \}\)</span>) <span class="math-span">\( \mathrm{ \, Volt }\)</span>, il destinatario riceve il segnale <span class="math-span">\( R = x + N \mathrm{ \, Volt }\)</span> con <span class="math-span">\( N \sim N(0, 1)\)</span>.     Alla ricezione del segnale si avrà che il messaggio sarà interpretato come <span class="math-span">\( 1\)</span> se <span class="math-span">\( R \geq 0.5 \mathrm{ \, Volt }\)</span>, altrimenti se <span class="math-span">\( R \lt 0.5 \mathrm{ \, Volt }\)</span> sarà interpretato come <span class="math-span">\( 0\)</span>.     <br/>     Considerando che la funzione di ripartizione di una v. c. gaussiana standard in <span class="math-span">\( -1.5\)</span> è uguale a     <span class="math-block">\[         F(-1.5) = 0.0668       \]</span>     e in <span class="math-span">\( 2.5\)</span> è uguale a       <span class="math-block">\[         F(2.5) = 0.9938       \]</span>     determinare la probabilità che sia decodificato <span class="math-span">\( 0\)</span> se si è inviato <span class="math-span">\( 1\)</span> e viceversa.     <span class="inner-title">Probabilità di decodificare <span class="math-span">\( 0\)</span> se si è inviato <span class="math-span">\( 1\)</span></span>     Per calcolare ciò, consideriamo che vogliamo calcolare la probabilità dell'evento     <span class="math-block">\[         P(R \lt 0.5 \mid x = 2)     \]</span>     ovvero la probabilità di ricevere <span class="math-span">\( R \lt 0.5\)</span> dato che si è inviato <span class="math-span">\( x = 2\)</span>.     <br/>     Considerando ciò, si ha che calcolare tale probabilità è uguale a calcolare      <span class="math-block">\begin{aligned}         &amp; P(R \lt 0.5 \mid x = 2) &amp; \iff \\         &amp; P(x + N \lt 0.5 \mid x = 2) &amp; \iff \\         &amp; P(2 + N \lt 0.5) &amp; \iff \\          &amp; P(N \lt -1.5) = 0.0668 &amp;     \end{aligned}</span>     <span class="inner-title">Probabilità di decodificare <span class="math-span">\( 1\)</span> se si è inviato <span class="math-span">\( 0\)</span></span>     Per calcolare ciò, consideriamo che vogliamo calcolare la probabilità dell'evento     <span class="math-block">\[         P(R \geq 0.5 \mid x = -2)     \]</span>     ovvero la probabilità di ricevere <span class="math-span">\( R \geq 0.5\)</span> dato che si è inviato <span class="math-span">\( x = -2\)</span>.     <br/>     Considerando ciò, si ha che calcolare tale probabilità è uguale a calcolare      <span class="math-block">\begin{aligned}         &amp; P(R \geq 0.5 \mid x = -2) &amp; \iff \\         &amp; 1 - P(R \lt 0.5 \mid x = -2) &amp; \iff \\         &amp; 1 - P(x + N \lt 0.5 \mid x = -2) &amp; \iff \\         &amp; 1 - P(-2 + N \lt 0.5) &amp; \iff \\         &amp; 1 - P(N \lt 2.5) &amp; \iff \\         &amp; 1 - P(N \lt 2.5) = 1 - 0.9938 = 0.0062  &amp;     \end{aligned}</span> </div><div class="environment-tail"><span class="material-symbols-outlined body-visibility-icon" onclick="expand_environment(event)">expand_more</span></div></div><div class="demonstration environment" id="dem2-14"><h2 class="environment-title">Dimostrazione - Proprietà di riproducibilità di una v. c. gaussiana</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Considerando due variabili casuali gaussiane indipendenti <span class="math-span">\( X\)</span> e <span class="math-span">\( Y\)</span>, tali che <span class="math-span">\( X \sim N(\mu_1, \sigma_1)\)</span> e <span class="math-span">\( Y \sim B(\mu_2, \sigma_2)\)</span> si ha che         <span class="math-block">\[             X + Y \sim N(\mu_1 + \mu_2, \sigma_1 + \sigma_2)            \]</span>     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione, considerando le funzioni generatrici dei momenti, si dovrebbe avere che         <span class="math-block">\[             \phi_{X + Y}(t) = \mathrm{e}^{t \cdot (\mu_1 + \mu_2) + \frac{t^2 \cdot (\sigma_1 + \sigma_2)^2}{2}}         \]</span>         Considerando la definizione, si ha che         <span class="math-block">\begin{aligned}             &amp; \phi_{X + Y}(t) = E\left[ \mathrm{e}^{t \cdot (X + Y)} \right] &amp; \iff \\             &amp; \phi_{X + Y}(t) = E\left[ \mathrm{e}^{t \cdot X + t \cdot Y} \right] &amp; \iff \\             &amp; \phi_{X + Y}(t) = E\left[ \mathrm{e}^{t \cdot X} \cdot \mathrm{e}^{t \cdot Y} \right] &amp; \iff         \end{aligned}</span>         e per l'indipendenza delle variabili, si ha che         <span class="math-block">\begin{aligned}             &amp; \phi_{X + Y}(t) = E\left[ \mathrm{e}^{t \cdot X} \right] \cdot E\left[ \mathrm{e}^{t \cdot Y} \right] &amp; \iff \\             &amp; \phi_{X + Y}(t) = \mathrm{e}^{t \cdot \mu_1 + \frac{t^2 \cdot (\sigma_1)^2}{2}} \cdot \mathrm{e}^{t \cdot \mu_2 + \frac{t^2 \cdot (\sigma_2)^2}{2}} &amp; \iff \\             &amp; \phi_{X + Y}(t) = \mathrm{e}^{t \cdot (\mu_1 + \mu_2) + \frac{t^2 \cdot (\sigma_1 + \sigma_2)^2}{2}} &amp;         \end{aligned}</span>         che dimostra la proposizione.     </div></div> </div></div><div class="definition environment" id="def2-43"><h2 class="environment-title">Definizione - Valore critico di una v. c. gaussiana standard</h2><div class="environment-body">     Considerando una variabile casuale gaussiana standard <span class="math-span">\( X \sim N(0, 1)\)</span>, si definisce valore critico <span class="math-span">\( z_\alpha\)</span> (ovvero <span class="math-span">\( z\)</span> in funzione di <span class="math-span">\( \alpha\)</span>) il valore     <span class="math-block">\[         z_\alpha \ : \ P(Z \gt z_\alpha) = P(Z \lt -z_\alpha) = \alpha       \]</span>     ovvero il valore <span class="math-span">\( z_\alpha\)</span> per cui l'area sottesa alla curva nell'intervallo <span class="math-span">\( [z_\alpha, +\infty)\)</span> e <span class="math-span">\( (-\infty, -z_\alpha]\)</span> (per simmetria) è <span class="math-span">\( \alpha\)</span>.       <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/valori-critici-gaussiana.png"/></div></div>     Ad esempio, si ha che <span class="math-span">\( z_{\frac{1}{2}}\)</span> è logicamente calcolabile: si ha infatti che per definizione l'area sottesa alla funzione è <span class="math-span">\( 1\)</span> e che è simmetrica.      Dato ciò, si ha che l'unico valore che concilia ciò è <span class="math-span">\( 0\)</span> (corrispondente all'asse di simmetria). </div></div>
            </article>
            <nav class="buttons-container content-width">
                <a class="navigation-button previous" href="modelli-di-variabili-casuali-discrete.html" rel="nofollow"><span>Modelli di variabili casuali discrete</span></a>
                <a class="navigation-button next" href="funzioni-di-variabili-casuali-continue.html" rel="nofollow"><span>Funzioni di variabili casuali continue</span></a>
            </nav>
        </section>
        <div class="scroll-to-bottom-button" onclick="scroll_to_bottom()">
            <span class="material-symbols-outlined">
                keyboard_double_arrow_down
            </span>
        </div>
        <footer class="footer-wrapper">
            <div class="copyright-wrapper">
                <span> &copy; Copyright 2023</span> /
                <span>made by lorenzoarlo</span>
            </div>
            /
            <div class="privacy-wrapper">
                <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/" rel="nofollow">Pannello preferenze cookie</a></span> /
                <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/privacy-policy.html" rel="nofollow" target="_blank" >Privacy Policy</a></span>
            </div>
        </footer>
    </div>
</body>
</html>