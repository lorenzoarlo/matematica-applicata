<!DOCTYPE html>
<html lang="IT">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="stylesheet" href="../styles/style.css" />
    <link rel="stylesheet" href="../styles/index-style.css" />
    <link rel="stylesheet" href="../styles/content-style.css" />
    <link rel="icon" type="image/x-icon" href="../resources/favicon.ico">
    <meta name="application-name" content="Matematica applicata" />
    <meta name="apple-mobile-web-app-title" content="Matematica applicata" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="#E34234" />
    <link rel="apple-touch-icon" href="../resources/favicon.png" />
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-78NHLXDQD8"></script>
    <script src="../scripts/script.js"></script>
    <style>:root { --bg-clr: #E34234; --fg-clr: #262626; }</style>
    <meta name="theme-color" content="#E34234" />
    <meta name="keywords" content="matematica applicata" />
    <meta name="description" content="Il seguente sito contiene gli appunti e le definizioni del corso 'Matematica applicata'.">
    <meta name="robots" content="index">
    <script defer async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <title>Matematica applicata - Variabili casuali - Teorema del limite centrale</title>
</head>
<body>
    <div class="container">
        <header class="header-wrapper">
            <div class="title-wrapper">
                <span class="title">
                    Matematica applicata
                </span>
                <span class="subtitle">
                    by lorenzoarlo
                </span>
            </div>
            <span class="page-title">
                Variabili casuali
            </span>
        </header>
        <aside class="sidebar">
            <h2 class="sidebar-title">Matematica applicata</h2>
            <div class="index-container">
                <ul class="parent-ul"><li class="section-li"><a href="../index.html">Indice</a></li><li class="section-li "><a href="../probabilità-discreta/calcolo-combinatorio.html">Probabilità discreta</a><ul><li class="subsection-li "><a href="../probabilità-discreta/calcolo-combinatorio.html">Calcolo combinatorio</a></li><li class="subsection-li "><a href="../probabilità-discreta/statistica.html">Statistica</a></li></ul></li><li class="section-li current">Variabili casuali<ul><li class="subsection-li "><a href="variabili-casuali-o-aleatorie.html">Variabili casuali (o aleatorie)</a></li><li class="subsection-li "><a href="coppia-di-variabili-casuali-discrete.html">Coppia di variabili casuali discrete</a></li><li class="subsection-li "><a href="coppia-di-variabili-casuali-congiuntamente-continue.html">Coppia di variabili casuali congiuntamente continue</a></li><li class="subsection-li "><a href="indipendenza-di-variabili-casuali.html">Indipendenza di variabili casuali</a></li><li class="subsection-li "><a href="valore-atteso.html">Valore atteso</a></li><li class="subsection-li "><a href="varianza.html">Varianza</a></li><li class="subsection-li "><a href="covarianza.html">Covarianza</a></li><li class="subsection-li "><a href="funzione-generatrice-di-momenti.html">Funzione generatrice di momenti</a></li><li class="subsection-li "><a href="modelli-di-variabili-casuali-discrete.html">Modelli di variabili casuali discrete</a></li><li class="subsection-li "><a href="modelli-di-variabili-casuali-continue.html">Modelli di variabili casuali continue</a></li><li class="subsection-li "><a href="funzioni-di-variabili-casuali-continue.html">Funzioni di variabili casuali continue</a></li><li class="subsection-li "><a href="processi-stocastici.html">Processi stocastici</a></li><li class="subsection-li "><a href="legge-dei-grandi-numeri.html">Legge dei grandi numeri</a></li><li class="subsection-li current">Teorema del limite centrale<ul><li class="demonstration-li"><a href="#dem2-22">Teorema del limite centrale</a></li><li class="definition-li"><a href="#def2-56">Valore atteso del limite centrale</a></li><li class="definition-li"><a href="#def2-57">Varianza del limite centrale</a></li><li class="definition-li"><a href="#def2-58">Conseguenza del limite centrale - Approssimazione di v. c. binomiali</a></li><li class="definition-li"><a href="#def2-59">Approssimazione alla continuità (o correzione di continuità)</a></li><li class="definition-li"><a href="#def2-60">Conseguenza del limite centrale - Approssimazione della somma di v. c.</a></li><li class="definition-li"><a href="#def2-61">Conseguenza del limite centrale - Approssimazione della media campionaria di v. c.</a></li><li class="definition-li"><a href="#def2-62">Variabile casuale chi-quadro a \( n\) gradi di libertà</a></li><li class="definition-li"><a href="#def2-63">Variabile casuale \( t\) di Student</a></li></ul></li></ul></li><li class="section-li "><a href="../inferenza-statistica/concetti-introduttivi.html">Inferenza statistica</a><ul><li class="subsection-li "><a href="../inferenza-statistica/concetti-introduttivi.html">Concetti introduttivi</a></li><li class="subsection-li "><a href="../inferenza-statistica/intervalli-di-confidenza.html">Intervalli di confidenza</a></li><li class="subsection-li "><a href="../inferenza-statistica/regressione.html">Regressione</a></li></ul></li></ul>
            </div>
        </aside>
        <div class="sidebar-button" onclick="toggle_sidebar(this)" role="button" >
            keyboard_double_arrow_right
        </div>
        <section class="content-wrapper">
            <h1 class="section-title content-width">Teorema del limite centrale</h1>
            <article class="content-container content-width">
                <div class="demonstration environment" id="dem2-22"><h2 class="environment-title">Dimostrazione - Teorema del limite centrale</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato:</h3><div class="environment-body">         Considerando una successione di variabili casuali identicamente distribuite e indipendenti <span class="math-span">\( X_1, \ldots, X_n\)</span> di valore atteso <span class="math-span">\( \mu\)</span> e varianza <span class="math-span">\( \sigma^2\)</span>, si ha che la variabile casuale         <span class="math-block">\[             T_n = \frac{X_1 + \ldots + X_n - n \cdot \mu}{\sigma \cdot \sqrt{n}}         \]</span>         tende in distribuzione, per <span class="math-span">\( n \to +\infty\)</span>, ad una variabile causale gaussiana standard ovvero         <span class="math-block">\[             P(T_n \leq a) \xrightarrow[n \to +\infty]{} F_Z(a) \qquad \forall a \in \mathbb{R} \ \text{e} \ Z \sim N(0, 1)             \]</span>     </div></div>     <div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questo teorema, ipotizziamo che il valore atteso delle v. c. sia <span class="math-span">\( 0\)</span> e la deviazione standard sia <span class="math-span">\( 1\)</span> (per semplificare alcuni passaggi) e, dato che le v. c. <span class="math-span">\( X_i\)</span> sono indipendenti e identicamente distribuite, si ha che         <span class="math-block">\[             \phi_{X_1}(t) = \ldots = \phi_{X_n}(t)            \]</span>         <span class="inner-title">Funzione logaritmo della funzione generatrice</span>         Consideriamo quindi di definire la funzione         <span class="math-block">\[             L(t) = \ln \left( \phi_{X_1}(t) \right)           \]</span>         (considerando <span class="math-span">\( X_1\)</span>, ma valido per ognuna delle altre v. c.).         <br/>         Allora si ha che         <span class="math-block">\[             \begin{array}{ccl}                 L(0) &amp; = &amp; \ln \left( \phi_{X_1}(0) \right) \\                 &amp; = &amp; \ln \left( E\left[ \mathrm{e}^{0 \cdot X_1} \right] \right) \\                 &amp; = &amp; \ln \left( E\left[ 1 \right] \right) \\                 &amp; = &amp; \ln \left( 1 \right) \\                 &amp; = &amp; 0             \end{array}         \]</span>         Considerando anche la derivata prima in <span class="math-span">\( t = 0\)</span> si ha che          <span class="math-block">\[             \begin{array}{ccl}                 \frac{d}{dt} L(0) &amp; = &amp; \frac{d}{dt} \ln \left( \phi_{X_1}(t) \right) \mid_{t = 0} \\                 &amp; \underset{\text{deriv. comp.}}{=} &amp; \frac{d}{dt} \phi_{X_1}(t) \cdot \frac{1}{\phi_{X_1}(t)} \mid_{t = 0} \\                 &amp; = &amp; \frac{d}{dt} \phi_{X_1}(0) \cdot \frac{1}{E\left[ \mathrm{e}^{0 \cdot X_1} \right]} \\                 &amp; = &amp; \frac{d}{dt} \phi_{X_1}(0) \cdot \frac{1}{1} \\                 &amp; = &amp; \frac{d}{dt} \phi_{X_1}(0) \\                 &amp; \underset{\text{mom. di ord. 1}}{=} &amp; E[X_1] \\                 &amp; = &amp; \mu \\                 &amp; = &amp; 0             \end{array}         \]</span>         e la derivata seconda in <span class="math-span">\( t = 0\)</span> si ha che          <span class="math-block">\[             \begin{array}{ccl}                 \frac{d^2}{dt^2} L(0) &amp; = &amp; \frac{d}{dt} \left( \frac{d}{dt} L(t) \right) \mid_{t = 0} \\                 &amp; = &amp; \frac{d}{dt} \left( \frac{d}{dt} \phi_{X_1}(t) \cdot \frac{1}{\phi_{X_1}(t)} \right) \mid_{t = 0} \\                 &amp; = &amp; \frac{d}{dt} \left( \frac{d}{dt} \phi_{X_1}(t) \cdot \left( \phi_{X_1}(t) \right)^{-1} \right) \mid_{t = 0} \\                 &amp; \underset{\text{deriv. prod.}}{=} &amp; \underbrace{\frac{d^2}{dt^2} \phi_{X_1}(t)}_{E\left[(X_1)^2\right]} \cdot \underbrace{\left( \phi_{X_1}(t) \right)^{-1}}_{1} - \underbrace{\left( \phi_{X_1}(t) \right)^{-2}}_1 \cdot \underbrace{ \left( \frac{d}{dt} \phi_{X_1}(t) \right)^2}_{\left( E[X_1] \right)^2} \mid_{t = 0} \\                 &amp; = &amp; E\left[(X_1)^2\right] - \left( E[X_1] \right)^2 \\                 &amp; = &amp; Var(X_1) \\                 &amp; = &amp; 1             \end{array}         \]</span>         <span class="inner-title">Considerazioni su cosa dimostrare</span>         Considerando         <span class="math-block">\[             T_n = \frac{X_1 + \ldots + X_n}{\sqrt{n}}           \]</span>          si vuole dimostrare che         <span class="math-block">\begin{aligned}             &amp; \lim_{n \to +\infty} P(T_n \leq a) = F_Z(a) &amp; \iff \\             &amp; \lim_{n \to +\infty} F_{T_n}(a) = F_Z(a) &amp; \iff \\             &amp; \lim_{n \to +\infty} \phi_{T_n}(t) = \phi_{Z}(t) &amp; \iff \\             &amp; \lim_{n \to +\infty} \phi_{T_n}(t) = \mathrm{e}^{\frac{t^2}{2}} &amp; \iff \\             &amp; \lim_{n \to +\infty} \ln (\phi_{T_n}(t)) = \frac{t^2}{2} &amp;         \end{aligned}</span>         <span class="inner-title">Funzione generatrice di <span class="math-span">\( T_n\)</span></span>         Considerando la variabile <span class="math-span">\( T_n\)</span>, calcolare funzione generatrice di <span class="math-span">\( T_n\)</span> equivale a         <span class="math-block">\[             \begin{array}{ccl}                 \phi_{T_n}(t) &amp; = &amp; \phi_{\sum_{k = 1}^n \frac{X_k}{\sqrt{n}}}(t) \\                 &amp; \underset{\text{indip.}}{=} &amp; \phi_{\frac{X_1}{\sqrt{n}}}(t) \cdot \ldots \cdot \phi_{\frac{X_n}{\sqrt{n}}}(t) \\                 &amp; \underset{\text{ident. distr.}}{=} &amp; \left( \phi_{\frac{X_1}{\sqrt{n}}}(t) \right)^n \\                 &amp; = &amp; \left( E\left[ \mathrm{e}^{t \cdot \frac{X_1}{\sqrt{n}}} \right] \right)^n \\                 &amp; = &amp; \left( E\left[ \mathrm{e}^{\frac{t}{\sqrt{n}} \cdot X_1} \right] \right)^n \\                 &amp; = &amp; \left( \phi_{X_1}\left(\frac{t}{\sqrt{n}}\right) \right)^n             \end{array}         \]</span>         <span class="inner-title">Considerazioni finali</span>         Considerando cosa si vuole dimostrare, ovvero che         <span class="math-block">\begin{aligned}             &amp; \lim_{n \to +\infty} \ln (\phi_{T_n}(t)) = \frac{t^2}{2} &amp;         \end{aligned}</span>         è ora possibile sostituire a <span class="math-span">\( \phi_{T_n}(t)\)</span> il risultato precedente, ovvero         <span class="math-block">\[             \begin{array}{ccl}                 \lim_{n \to +\infty} \ln (\phi_{T_n}(t)) &amp; = &amp; \lim_{n \to +\infty} \ln \left( \left( \phi_{X_1}\left(\frac{t}{\sqrt{n}}\right) \right)^n \right) \\                 &amp; = &amp; \lim_{n \to +\infty} n \cdot \ln \left(\phi_{X_1}\left(\frac{t}{\sqrt{n}}\right) \right) \\                 &amp; = &amp; \lim_{n \to +\infty} n \cdot L\left(\frac{t}{\sqrt{n}}\right)             \end{array}         \]</span>         Ricordando che <span class="math-span">\( L(0) = 0\)</span>, trasformiamo il prodotto in una forma indeterminata <span class="math-span">\( \frac{0}{0}\)</span>, ovvero         <span class="math-block">\begin{aligned}             = \quad &amp; \lim_{n \to +\infty} \frac{L\left(\frac{t}{\sqrt{n}}\right)}{n^{-1}} &amp; =         \end{aligned}</span>         a cui è possibile applicare De l'Hopital, ovvero         <span class="math-block">\[             \begin{array}{ccl}                 \lim_{n \to +\infty} \ln (\phi_{T_n}(t)) &amp; = &amp; \lim_{n \to +\infty} \ln \left( \left( \phi_{X_1}\left(\frac{t}{\sqrt{n}}\right) \right)^n \right) \\                 &amp; = &amp; \lim_{n \to +\infty} \frac{\frac{d}{dn} L\left(\frac{t}{\sqrt{n}}\right)}{\frac{d}{dn} n^{-1}} \\                 &amp; = &amp; \lim_{n \to +\infty} \frac{L'\left(\frac{t}{\sqrt{n}}\right) \cdot t \cdot \left(- \frac{1}{2} \right) \cdot n^{-\frac{3}{2}}}{-n^{-2}}  \\                 &amp; = &amp; \lim_{n \to +\infty} \frac{L'\left(\frac{t}{\sqrt{n}}\right) \cdot \frac{t}{2}}{n^{-\frac{1}{2}}}              \end{array}         \]</span>         che è anch'essa una forma indeterminata <span class="math-span">\( \frac{0}{0}\)</span> per cui è possibile applicare nuovamente De l'Hopital, ovvero         <span class="math-block">\[             \begin{array}{ccl}                 \lim_{n \to +\infty} \ln (\phi_{T_n}(t)) &amp; = &amp; \lim_{n \to +\infty} \frac{\frac{d}{dn} \left( L'\left(\frac{t}{\sqrt{n}}\right) \cdot \frac{t}{2} \right)}{\frac{d}{dn} \left( n^{-\frac{1}{2}} \right) } \\                 &amp; = &amp; \lim_{n \to +\infty} \frac{\frac{t}{2} \cdot L''\left(\frac{t}{\sqrt{n}}\right) \cdot t \cdot \left( - \frac{1}{2} \right) \cdot n^{-\frac{3}{2}}}{ -\frac{1}{2} \cdot n^{-\frac{3}{2}}  } \\                 &amp; = &amp; \lim_{n \to +\infty} \frac{t}{2} \cdot L''\left(\frac{t}{\sqrt{n}}\right) \cdot t \\                 &amp; = &amp; \lim_{n \to +\infty} \frac{t^2}{2} \cdot L''\left(\frac{t}{\sqrt{n}}\right)  \\                 &amp; = &amp; \frac{t^2}{2} \cdot \underbrace{L''(0)}_1 \\                 &amp; = &amp; \frac{t^2}{2}             \end{array}          \]</span>         che dimostra il teorema.     </div></div> </div></div><div class="definition environment" id="def2-56"><h2 class="environment-title">Definizione - Valore atteso del limite centrale</h2><div class="environment-body">     Considerando la variabile casuale      <span class="math-block">\[         T_n = \frac{X_1 + \ldots + X_n - n \cdot \mu}{\sigma \cdot \sqrt{n}}     \]</span>     del limite centrale, si ha che per calcolare il valore atteso di <span class="math-span">\( T_n\)</span>, è possibile dividerlo in      <span class="math-block">\[         \begin{array}{ccl}             E[T_n] &amp; = &amp; E\left[ \frac{X_1 + \ldots + X_n - n \cdot \mu}{\sigma \cdot \sqrt{n}} \right] \\             &amp; = &amp; \frac{1}{\sigma \cdot \sqrt{n}} \cdot E\left[ X_1 + \ldots + X_n - n \cdot \mu \right] \\             &amp; = &amp; \frac{E\left[ X_1 + \ldots + X_n \right] - n \cdot \mu}{\sigma \cdot \sqrt{n}}          \end{array}       \]</span>     È ora necessario calcolare il valore atteso di <span class="math-span">\( X_1 + \ldots + X_n\)</span>, ovvero     <span class="math-block">\[         \begin{array}{ccl}             E[X_1 + \ldots + X_n] &amp; = &amp; E\left[ \sum_{i = 1}^n X_i \right] \\             &amp; = &amp; \sum_{i = 1}^{n} E[X_i] \\             &amp; = &amp; \sum_{i = 1}^{n} \mu \\             &amp; = &amp; n \cdot \mu         \end{array}       \]</span>     Sostituendo tale valore al calcolo precedente si ottiene      <span class="math-block">\[         \begin{array}{ccl}             E[T_n] &amp; = &amp; \frac{E\left[ X_1 + \ldots + X_n \right] - n \cdot \mu}{\sigma \cdot \sqrt{n}} \\             &amp; = &amp; \frac{n \cdot \mu - n \cdot \mu}{\sigma \cdot \sqrt{n}} \\             &amp; = &amp; 0         \end{array}       \]</span> </div></div><div class="definition environment" id="def2-57"><h2 class="environment-title">Definizione - Varianza del limite centrale</h2><div class="environment-body">     Per calcolare la varianza di <span class="math-span">\( T_n\)</span>, consideriamo     <span class="math-block">\[         \begin{array}{ccl}             Var(T_n) &amp; = &amp; Var\left( \frac{X_1 + \ldots + X_n - n \cdot \mu}{\sigma \cdot \sqrt{n}} \right) \\             &amp; = &amp; \frac{1}{\sigma^2 \cdot n} \cdot Var\left( X_1 + \ldots + X_n \right)         \end{array}       \]</span>     dato che     <span class="math-block">\[         Var(\alpha \cdot X + \beta) = \alpha^2 \cdot Var(X)       \]</span>     e     <span class="math-block">\[         \begin{array}{ccl}             Var(T_n) &amp; = &amp; \frac{1}{\sigma^2 \cdot n} \cdot Var\left( X_1 + \ldots + X_n \right) \\             &amp; \underset{\text{indip.}}{=} &amp; \frac{1}{\sigma^2 \cdot n} \cdot \sum_{i = 1}^n Var(X_i) \\             &amp; = &amp; \frac{1}{\sigma^2 \cdot n} \cdot n \cdot \sigma^2 \\             &amp; = &amp; 1         \end{array}       \]</span> </div></div><div class="definition environment" id="def2-58"><h2 class="environment-title">Definizione - Conseguenza del limite centrale - Approssimazione di v. c. binomiali</h2><div class="environment-body">     Considerando una variabile casuale binomiale di parametri <span class="math-span">\( n\)</span> e <span class="math-span">\( p\)</span> (con <span class="math-span">\( n\)</span> "molto maggiori" di <span class="math-span">\( 1\)</span>)     <span class="math-block">\[         Y \sim B(n, p)       \]</span>     si ha che è possibile vederla come somma di <span class="math-span">\( n\)</span> variabili casuali di Bernoulli indipendenti, ovvero     <span class="math-block">\[         Y = \sum_{i = 1}^n X_i \qquad \text{con} \ X_i \sim Be(p)      \]</span>     che, in quanto variabili di Bernoulli di parametro <span class="math-span">\( p\)</span>, avranno tutte valore atteso pari a <span class="math-span">\( p\)</span> e varianza pari a <span class="math-span">\( p \cdot q\)</span>.     <br/>     Considerando ora il teorema del limite centrale, si ha che     <span class="math-block">\[         \frac{Y - n \cdot p}{\sqrt{p \cdot q} \cdot \sqrt{n}}  \underset{n \to +\infty}{\sim} N(0, 1)     \]</span>     Ricordando però le regole per ricondursi alla gaussiana standard (ovvero data <span class="math-span">\( G \sim N(\mu, \sigma)\)</span>, si ha che <span class="math-span">\( \frac{G - \mu}{\sigma} \sim N(0, 1)\)</span>) si ha che è possibile dire che per <span class="math-span">\( n\)</span> "abbastanza grandi" è valida l'approssimazione      <span class="math-block">\[         Y \sim B(n, p) \sim N(n \cdot p, \sqrt{n \cdot p \cdot q})       \]</span>      <div class="mynote environment"><h3 class="environment-title">Nota bene - <span class="math-span">\( n\)</span> "abbastanza grandi" per casi pratici</h3><div class="environment-body">         Nei casi pratici, l'approssimazione della binomiale è valida per <span class="math-span">\( n\)</span> maggiori uguali a <span class="math-span">\( 30\)</span>.     </div></div> </div></div><div class="definition environment" id="def2-59"><h2 class="environment-title">Definizione - Approssimazione alla continuità (o correzione di continuità)</h2><div class="environment-body">     Consideriamo le v. c. <span class="math-span">\( D \sim B(n, p)\)</span> (con <span class="math-span">\( n\)</span> "abbastanza grande") e <span class="math-span">\( M \sim N(n \cdot p, \sqrt{n \cdot p \cdot q})\)</span> (ovvero è possibile approssimare <span class="math-span">\( D\)</span> con <span class="math-span">\( M\)</span>) e consideriamo di voler calcolare la probabilità che assumano un certo valore <span class="math-span">\( k\)</span>.      <br/>     Nel caso della v. c. <span class="math-span">\( D\)</span> varrà     <span class="math-block">\[         P(D = k) = C_{n, k} \cdot p^k \cdot q^{n - k}     \]</span>     mentre per <span class="math-span">\( M\)</span> si avrà     <span class="math-block">\[         P(M = k) = \int_k^k f_M(x) \ dx = 0       \]</span>     Un'idea per "recuperare" questa differenza può essere seguire le seguenti regole di approssimazione:     <ul class="list-container"><li class="list-item">per calcolare la probabilità che <span class="math-span">\( D\)</span> assuma un certo valore <span class="math-span">\( k\)</span>, consideriamo di calcolare la probabilità che <span class="math-span">\( M\)</span> sia compresa tra <span class="math-span">\( k - \frac{1}{2}\)</span> e <span class="math-span">\( k + \frac{1}{2}\)</span>, ovvero         <span class="math-block">\[             P(D = k) = P\left(k - \frac{1}{2} \lt M \leq k + \frac{1}{2}\right)           \]</span>         </li><li class="list-item">per calcolare la probabilità che <span class="math-span">\( D\)</span> sia minore o uguale a <span class="math-span">\( k\)</span>, consideriamo di calcolare la probabilità che <span class="math-span">\( M\)</span> sia minore o uguale di <span class="math-span">\( k + \frac{1}{2}\)</span>, ovvero         <span class="math-block">\[             P(D \leq k) = P(M \leq k + \frac{1}{2})           \]</span>         </li><li class="list-item">per calcolare la probabilità che <span class="math-span">\( D\)</span> sia minore a <span class="math-span">\( k\)</span>, consideriamo di calcolare la probabilità che <span class="math-span">\( M\)</span> sia minore o uguale di <span class="math-span">\( k - \frac{1}{2}\)</span>, ovvero         <span class="math-block">\[             P(D \lt k) = P(M \leq k - \frac{1}{2})           \]</span>         </li><li class="list-item">per calcolare la probabilità che <span class="math-span">\( D\)</span> sia maggiore o uguale a <span class="math-span">\( k\)</span>, consideriamo di calcolare la probabilità che <span class="math-span">\( M\)</span> sia maggiore o uguale di <span class="math-span">\( k - \frac{1}{2}\)</span>, ovvero         <span class="math-block">\[             P(D \geq k) = P(M \geq k - \frac{1}{2})           \]</span>         </li><li class="list-item">per calcolare la probabilità che <span class="math-span">\( D\)</span> sia maggiore a <span class="math-span">\( k\)</span>, consideriamo di calcolare la probabilità che <span class="math-span">\( M\)</span> sia maggiore o uguale di <span class="math-span">\( k + \frac{1}{2}\)</span>, ovvero         <span class="math-block">\[             P(D \gt k) = P(M \geq k + \frac{1}{2})           \]</span>     </li></ul> </div></div><div class="definition environment" id="def2-60"><h2 class="environment-title">Definizione - Conseguenza del limite centrale - Approssimazione della somma di v. c. </h2><div class="environment-body">     Considerando la somma di <span class="math-span">\( n\)</span> variabili casuali indipendenti di valore atteso <span class="math-span">\( \mu\)</span> e varianza <span class="math-span">\( \sigma^2\)</span>     <span class="math-block">\[         S_n = X_1 + \ldots + X_n       \]</span>     (il cui valore atteso è <span class="math-span">\( n \cdot \mu\)</span> e la dev. standard è <span class="math-span">\( \sqrt{n} \cdot \sigma\)</span>) per il teorema del limite centrale, si ha che     <span class="math-block">\[         \frac{S_n - n \cdot \mu}{\sigma \cdot \sqrt{n}}  \underset{n \to +\infty}{\sim} N(0, 1)     \]</span>     Ricordando però le regole per ricondursi alla gaussiana standard (ovvero data <span class="math-span">\( G \sim N(\mu, \sigma)\)</span>, si ha che <span class="math-span">\( \frac{G - \mu}{\sigma} \sim N(0, 1)\)</span>) si ha che è possibile dire che per <span class="math-span">\( n\)</span> "abbastanza grandi" è valida l'approssimazione      <span class="math-block">\[         S_n \sim N(n \cdot \mu, \sigma \cdot \sqrt{n})       \]</span> </div></div><div class="definition environment" id="def2-61"><h2 class="environment-title">Definizione - Conseguenza del limite centrale - Approssimazione della media campionaria di v. c.</h2><div class="environment-body">     Considerando la media di <span class="math-span">\( n\)</span> variabili casuali indipendenti di valore atteso <span class="math-span">\( \mu\)</span> e varianza <span class="math-span">\( \sigma^2\)</span>     <span class="math-block">\[         \overline{X} = \frac{X_1 + \ldots + X_n}{n}        \]</span>     è possibile calcolare il valore atteso di <span class="math-span">\( \overline{X}\)</span>, ovvero     <span class="math-block">\[         \begin{array}{ccl}             E[\overline{X}] &amp; = &amp; E\left[ \frac{X_1 + \ldots + X_n}{n} \right] \\             &amp; = &amp; \frac{1}{n} \cdot E[X_1 + \ldots + X_n] \\             &amp; = &amp; \frac{1}{n} \cdot n \cdot \mu \\             &amp; = &amp; \mu         \end{array}         \]</span>     e la varianza è uguale a      <span class="math-block">\[         \begin{array}{ccl}             Var(\overline{X}) &amp; = &amp; Var\left( \frac{X_1 + \ldots + X_n}{n} \right) \\             &amp; = &amp; \frac{1}{n^2} \cdot Var(X_1 + \ldots + X_n) \\              &amp; = &amp; \frac{1}{n^2} \cdot n \cdot \sigma^2 \\             &amp; = &amp; \frac{\sigma^2}{n}         \end{array}       \]</span>     Considerando ora il teorema del limite centrale, si ha che     <span class="math-block">\begin{aligned}         &amp; \frac{X_1 + \ldots + X_n - n \cdot \mu}{\sigma \cdot \sqrt{n}}  \underset{n \to +\infty}{\sim} N(0, 1) &amp; \iff \\         &amp; \frac{\frac{1}{n}}{\frac{1}{n}} \cdot \frac{X_1 + \ldots + X_n - n \cdot \mu}{\sigma \cdot \sqrt{n}}  \underset{n \to +\infty}{\sim} N(0, 1) &amp; \iff \\         &amp; \frac{\frac{X_1 + \ldots + X_n}{n} - \mu}{\sigma \cdot \frac{1}{\sqrt{n}}}  \underset{n \to +\infty}{\sim} N(0, 1) &amp; \iff      \end{aligned}</span>     Ricordando però le regole per ricondursi alla gaussiana standard (ovvero data <span class="math-span">\( G \sim N(\mu, \sigma)\)</span>, si ha che <span class="math-span">\( \frac{G - \mu}{\sigma} \sim N(0, 1)\)</span>) si ha che è possibile dire che per <span class="math-span">\( n\)</span> "abbastanza grandi" è valida l'approssimazione      <span class="math-block">\[         \overline{X} \sim N(\mu, \frac{\sigma}{\sqrt{n}})       \]</span> </div></div><div class="definition environment" id="def2-62"><h2 class="environment-title">Definizione - Variabile casuale chi-quadro a <span class="math-span">\( n\)</span> gradi di libertà</h2><div class="environment-body">     Una variabile casuale continua <span class="math-span">\( X\)</span>, si definisce chi-quadro ad <span class="math-span">\( n\)</span> gradi di libertà (ovvero <span class="math-span">\( X \sim X^2_n\)</span>) se è la somma di <span class="math-span">\( n\)</span> variabili casuali normali standard elevate al quadrato, ovvero     <span class="math-block">\[         X = \sum_{k = 1}^n ( Z_k )^2  \qquad \text{con} \ Z_k \sim N(0, 1) \ \text{indipendenti}     \]</span>     <span class="inner-title">Funzione di densità</span>     La funzione di densità di questa variabile casuale risulta essere particolarmente complicata.      <br/>     Oltre al fatto che è maggiore o uguale a <span class="math-span">\( 0\)</span>, ovvero      <span class="math-block">\[         X^2_n \geq 0        \]</span>     essa è caratterizzata dal seguente grafico     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/funz-dens-chi-quadro.png"/></div></div>     <span class="inner-title">Valore atteso</span>     Il valore atteso di una variabile casuale chi-quadro a <span class="math-span">\( n\)</span> gradi di libertà è calcolabile come     <span class="math-block">\[         \begin{array}{ccl}             E[X] &amp; = &amp; E\left[ \sum_{k = 1}^n ( Z_k )^2 \right] \\             &amp; = &amp; \sum_{k = 1}^n E\left[ ( Z_k )^2 \right] \\              &amp; = &amp; \sum_{k = 1}^n \underbrace{Var(Z_k)}_{1} + ( \underbrace{E[Z_k]}_0 )^2 \\             &amp; = &amp; \sum_{k = 1}^n 1 \\             &amp; = &amp; n         \end{array}         \]</span>     <span class="inner-title">Varianza</span>     La varianza di una variabile casuale chi-quadro a <span class="math-span">\( n\)</span> gradi di libertà è calcolabile come     <span class="math-block">\[         \begin{array}{ccl}             Var(X) &amp; = &amp; Var\left( \sum_{k = 1}^n ( Z_k )^2 \right) \\             &amp; \underset{\text{indip.}}{=} &amp; \sum_{k = 1}^n Var\left( (Z_k)^2 \right)         \end{array}        \]</span>     Occorre quindi calcolare la varianza di <span class="math-span">\( (Z_k)^2\)</span>, ovvero     <span class="math-block">\[         \begin{array}{ccl}             Var\left( (Z_k)^2 \right) &amp; = &amp; E\left[ \left( (Z_k )^2 \right)^2 \right] - \underbrace{\left( E\left[ (Z_k )^2 \right] \right)^2}_{1^2} \\             &amp; = &amp; E\left[ (Z_k )^4 \right] - 1 \\             &amp; = &amp; \frac{d^4}{dt^4} \phi_{Z_k}(t) \mid_{t = 0} - 1 \\             &amp; = &amp; \frac{d^4}{dt^4} \left( \mathrm{e}^{\frac{t^2}{2}} \right) \mid_{t = 0} - 1 \\             &amp; = &amp; \frac{d^3}{dt^3} \left( t \cdot \mathrm{e}^{\frac{t^2}{2}} \right) \mid_{t = 0} - 1 \\             &amp; = &amp; \frac{d^2}{dt^2} \left( \mathrm{e}^{\frac{t^2}{2}} + t^2 \cdot \mathrm{e}^{\frac{t^2}{2}} \right) \mid_{t = 0} - 1 \\             &amp; = &amp; \frac{d}{dt} \left( t \cdot \mathrm{e}^{\frac{t^2}{2}} + 2 \cdot t \cdot \mathrm{e}^{\frac{t^2}{2}} + t^3 \cdot \mathrm{e}^{\frac{t^2}{2}} \right) \mid_{t = 0} - 1 \\             &amp; = &amp; \frac{d}{dt} \left( 3t \cdot \mathrm{e}^{\frac{t^2}{2}} + t^3 \cdot \mathrm{e}^{\frac{t^2}{2}} \right) \mid_{t = 0} - 1 \\             &amp; = &amp; \left( 3 \cdot \mathrm{e}^{\frac{t^2}{2}} + 3t^2 \cdot \mathrm{e}^{\frac{t^2}{2}} + 3 t^2 \cdot \mathrm{e}^{\frac{t^2}{2}} + t^4 \cdot \mathrm{e}^{\frac{t^2}{2}} \right) \mid_{t = 0} - 1 \\             &amp; = &amp; 3 - 1 \\             &amp; = &amp; 2         \end{array}       \]</span>     Sostituendo tale valore al calcolo per la varianza di <span class="math-span">\( X\)</span> si ottiene     <span class="math-block">\[         \begin{array}{ccl}             Var(X) &amp; = &amp; \sum_{k = 1}^n Var\left( (Z_k)^2 \right) \\             &amp; = &amp; \sum_{k = 1}^n 2 \\             &amp; = &amp; 2 \cdot n         \end{array}     \]</span>     <span class="inner-title">Proprietà di riproducibilità</span>     Considerando due variabili chi-quadro indipendenti <span class="math-span">\( X_1\)</span> e <span class="math-span">\( X_2\)</span>, tali che <span class="math-span">\( X_1 \sim X_n\)</span> e <span class="math-span">\( X_2 \sim X_m\)</span>, si ha che     <span class="math-block">\[         X_1 + X_2 \sim X^2_{n + m}     \]</span>     <span class="inner-title">Approssimazione ad una v. c. normale standard</span>     Considerando <span class="math-span">\( n \to +\infty\)</span>, è possibile approssimare una variabile casuale chi-quadro ad una v. c. normale standard grazie al teorema del limite centrale. </div></div><div class="definition environment" id="def2-63"><h2 class="environment-title">Definizione - Variabile casuale <span class="math-span">\( t\)</span> di Student</h2><div class="environment-body">     Una variabile casuale continua <span class="math-span">\( X\)</span>, si definisce <span class="math-span">\( t\)</span> di Student a <span class="math-span">\( n\)</span> gradi di libertà (ovvero <span class="math-span">\( X \sim T_n\)</span>) se considerando <span class="math-span">\( Z \sim N(0, 1)\)</span> e <span class="math-span">\( C_n \sim X^2_n\)</span> indipendenti, si ha che     <span class="math-block">\[         X = \frac{Z}{\sqrt{\frac{C_n}{n}}}       \]</span>     secondo il teorema del limite centrale.     <span class="inner-title">Funzione di densità</span>     La funzione di densità di questa variabile casuale risulta essere particolarmente incomprensibile.      Oltre al fatto che è maggiore o uguale a <span class="math-span">\( 0\)</span>, ovvero      <span class="math-block">\[         X^2_k \geq 0        \]</span>     essa è caratterizzata dal seguente grafico     <div class="image-environment"><div class="image-wrapper spaced-50"><img alt="Immagine" src="../resources/funz-dens-t-student.png"/></div></div>     <span class="inner-title">Approssimazione ad una v. c. normale standard</span>     Considerando <span class="math-span">\( n \to +\infty\)</span>, è possibile approssimare una variabile casuale <span class="math-span">\( t\)</span> di Student ad una v. c. normale standard grazie al teorema del limite centrale. </div></div>
            </article>
            <nav class="buttons-container content-width">
                <a class="navigation-button previous" href="legge-dei-grandi-numeri.html" rel="nofollow"><span>Legge dei grandi numeri</span></a>
                <a class="navigation-button next" href="../inferenza-statistica/concetti-introduttivi.html" rel="nofollow"><span>Concetti introduttivi</span></a>
            </nav>
        </section>
        <div class="scroll-to-bottom-button" onclick="scroll_to_bottom()">
            <span class="material-symbols-outlined">
                keyboard_double_arrow_down
            </span>
        </div>
        <footer class="footer-wrapper">
            <div class="copyright-wrapper">
                <span> &copy; Copyright 2023</span> /
                <span>made by lorenzoarlo</span>
            </div>
            /
            <div class="privacy-wrapper">
                <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/" rel="nofollow">Pannello preferenze cookie</a></span> /
                <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/privacy-policy.html" rel="nofollow" target="_blank" >Privacy Policy</a></span>
            </div>
        </footer>
    </div>
</body>
</html>